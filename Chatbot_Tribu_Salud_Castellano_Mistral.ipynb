{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4RAc_uEg-QM"
   },
   "source": [
    "# ğŸ¦´ğŸŒ¿ Chatbot \"Tribu Salud\" â€“ Salud Evolutiva con IA ğŸ‹ï¸â€â™‚ï¸ğŸ”¥\n",
    "\n",
    "## ğŸ¯ Objetivo  \n",
    "Desarrollar un **chatbot especializado en salud evolutiva** llamado **Tribu Salud**, utilizando **Mistral-7B-Instruct-v0.2**, con capacidades de comprensiÃ³n y generaciÃ³n de respuestas basadas en principios ancestrales de alimentaciÃ³n, entrenamiento y bienestar.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ TecnologÃ­as y MetodologÃ­a  \n",
    "\n",
    "### ğŸ”¹ 1. Modelo de Lenguaje  \n",
    "Se utiliza el modelo **Mistral-7B-Instruct-v0.2**, optimizado para respuestas conversacionales en espaÃ±ol y otras lenguas.\n",
    "\n",
    "### ğŸ”¹ 2. Entrenamiento y Fine-Tuning  \n",
    "- Se usa el dataset **MLQA** (*MultiLingual Question Answering*) para entrenamiento inicial.  \n",
    "- Se aplica **fine-tuning** con datos especÃ­ficos de salud evolutiva.  \n",
    "\n",
    "### ğŸ”¹ 3. RAG (Retrieval-Augmented Generation)  \n",
    "Para mejorar la precisiÃ³n de las respuestas, se implementa **RAG**, combinando el modelo generativo con una base de conocimiento extraÃ­da de:  \n",
    "- **Documentos PDF** relevantes.  \n",
    "- **Transcripciones de YouTube** de **Fitness Revolucionario**, obtenidas con `youtube-transcript-api`.  \n",
    "\n",
    "### ğŸ”¹ 4. Indexado con FAISS  \n",
    "- Se mejora el **Ã­ndice FAISS** para permitir **bÃºsquedas rÃ¡pidas y eficientes** en la base de conocimiento.  \n",
    "- Esto permite respuestas basadas en informaciÃ³n real y verificada.  \n",
    "\n",
    "### ğŸ”¹ 5. Despliegue con Gradio  \n",
    "- Se utiliza **Gradio** para desplegar el chatbot con una interfaz accesible y fÃ¡cil de usar.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Estado y PrÃ³ximos Pasos  \n",
    "âœ… Modelo Mixtral-8x22B cargado y configurado.  \n",
    "âœ… Dataset MLQA procesado y adaptado.  \n",
    "âœ… ImplementaciÃ³n de Fine-Tuning.  \n",
    "âœ… ExtracciÃ³n de informaciÃ³n de PDFs y YouTube.  \n",
    "âœ… OptimizaciÃ³n de FAISS para bÃºsqueda rÃ¡pida.  \n",
    "ğŸ”œ Despliegue final y pruebas en Gradio.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ ConclusiÃ³n  \n",
    "**Tribu Salud** serÃ¡ un chatbot avanzado que proporcionarÃ¡ informaciÃ³n precisa y confiable sobre **salud evolutiva, alimentaciÃ³n y entrenamiento funcional**, integrando un **modelo de IA con recuperaciÃ³n de informaciÃ³n relevante**.  \n",
    "\n",
    "ğŸ“¢ **Â¡Pronto estarÃ¡ disponible para consulta y uso!** ğŸš€ğŸ”¥  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-m4NnYy8SQf",
    "outputId": "ddbcb54f-21b1-416a-a198-8bde4bf11495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWjSHwbG8iUu",
    "outputId": "14e9eb3f-b5e3-495d-c378-6412faf3ea05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.16 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.16)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.32)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (0.3.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading marshmallow-3.26.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.16 marshmallow-3.26.0 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ok2xo29c80n2",
    "outputId": "8d3dcedd-6885-4010-dfaf-aaf28bfbd4d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube_transcript_api\n",
      "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (0.7.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2024.12.14)\n",
      "Downloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: youtube_transcript_api\n",
      "Successfully installed youtube_transcript_api-0.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nevZXah-DnTR",
    "outputId": "c2905edf-ef93-40fb-ea2e-40909f700054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4cVDP44MwE5",
    "outputId": "65981be3-b157-4f1c-ebc8-f39cfe8b24f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.14.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.7.0 (from gradio)\n",
      "  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.9.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.9.0)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.17.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-5.14.0-py3-none-any.whl (57.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.7/57.7 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.9.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "Successfully installed aiofiles-23.2.1 fastapi-0.115.8 ffmpy-0.5.0 gradio-5.14.0 gradio-client-1.7.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.4 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6f6rZKW1pGq",
    "outputId": "6f45690f-d49f-4928-8f4a-585665c958db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: torch~=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (2024.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch~=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch~=2.0->bitsandbytes) (2.1.5)\n",
      "Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m252.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m268.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m262.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m280.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m325.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m320.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed bitsandbytes-0.45.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y bitsandbytes\n",
    "!pip install --no-cache-dir -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGs5qxQ7It0P",
    "outputId": "7e9fd76a-73a1-4f94-a955-66e4c3f79c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.5.1+cu124)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.47.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.2.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.27.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8WnSblPg0Hh",
    "outputId": "9e5934db-6eb7-4e6f-dceb-fc041e3e821c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHk6LhMYhoUt",
    "outputId": "436ea079-25a9-4470-ce44-5b080b6228a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMYNQayI-LoV",
    "outputId": "5885f6bb-4dde-4cce-cd14-7181deaa76f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45.1\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "print(bnb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lF7rEqeG-t4w",
    "outputId": "9340b6fc-d410-4814-b48a-ae9c100e92ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Debe devolver True\n",
    "print(torch.cuda.get_device_name())  # Debe listar la A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XVeg6YyMg_N9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import json\n",
    "import pdfplumber\n",
    "import requests\n",
    "import io\n",
    "import faiss\n",
    "import pickle\n",
    "import zipfile\n",
    "import gradio as gr\n",
    "from datasets import load_dataset\n",
    "from transformers import (TrainingArguments, Trainer, AutoTokenizer, AutoModelForCausalLM,\n",
    "                          DataCollatorForLanguageModeling, BitsAndBytesConfig, pipeline)\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "from google.colab import files\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "e7a7fa1f53794d19a13c821e0c364c2c",
      "c32ec26d0b684d848e983c68dd6b0f44",
      "d09e6f64a97b46b781c7ec4339e6abd6",
      "87f5015d8f484ed89c2a38d4e1aa66b4",
      "b6f9ae880b6441afa5594c77a4c4a923",
      "f4c67dc430ed4747a609488fbf836451",
      "37cbb50c77cc4f379f0376b78aa48a97",
      "a5caa46479a549aba4a03550cda037cd",
      "94f16b272ebe49129e8522fe26130207",
      "88607457723c4321a579c1fe4ea8c8ff",
      "b2a07dbddfc94431aaa49c23601d2b1c",
      "a16dd9a2ca654acb8d1d9cc6a5c979da",
      "edd73cfb50a84abfbbf8a768f801acf7",
      "f75e3b66c0e94667b8967316a2ec2b29",
      "203ba928597744d4b434bc4c51da2686",
      "4d96c9b0da5b48f3a2a4aaec038adf5d",
      "2d3c3b8a09104907b09641015b1d7811",
      "1218f8dc876142edb845680a4cd3e898",
      "ce9c64ba0a9f42b59b663b4dedacc6e9",
      "54f7d1b5b7b241ccb07c74f2183ca80a"
     ]
    },
    "id": "xTs_C9F_j1xL",
    "outputId": "29f343c5-b514-4fd6-b4e4-3af108097ce1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a7fa1f53794d19a13c821e0c364c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AutenticaciÃ³n en Hugging Face\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "a8b3bbf3a9214c71895fde194787177c",
      "c47caa6a608f4c298546086761da96f4",
      "77afef2ffa4644408dbb5f7c7cb80c12",
      "2cdb14fa8b0a4e85b7c1294c7d8457e3",
      "75a5efb8abd7455abdaa7de3134c633c",
      "2b3233b5ce904b4fa7becaa768afb522",
      "a21ac5c7c1fa4f5c8e72bd78390a8864",
      "599d554c870347278ebe0ec17774540e",
      "d0728b20953e4273895fece85d5c4811",
      "76faa3bbeb4a48b8abd606eae88a3e41",
      "807212eec6df460291516d71792bac63"
     ]
    },
    "id": "hMVNXjPShEqG",
    "outputId": "0abeff88-f919-4d34-9f03-2fda3d6b7bec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b3bbf3a9214c71895fde194787177c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar modelo Mistral-7B-Instruct\n",
    "# ConfiguraciÃ³n\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# CuantizaciÃ³n en 4-bit\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # Usa bfloat16 en A100\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Cargar modelo con offloading y LoRA\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Preparar modelo para fine-tuning en 4-bit\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Configurar LoRA (aÃ±adir adaptadores en capas clave)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # TamaÃ±o del cuello de botella de LoRA (ajustar segÃºn RAM disponible)\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Aplicar LoRA solo en capas clave\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"  # Tipo de tarea para el modelo\n",
    ")\n",
    "\n",
    "# Aplicar LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Cargar tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Evitar errores con padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBtByHE7gm6z",
    "outputId": "212a6263-c793-424c-fa10-6554c436fab3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] \n",
      "ğŸ¦´ğŸŒ¿ Â¡Bienvenido a Tribu Salud! ğŸ‹ï¸â€â™‚ï¸ğŸ”¥\n",
      "\n",
      "Hola, soy tu asistente en salud evolutiva, aquÃ­ para ayudarte a optimizar tu bienestar con un enfoque basado en la biologÃ­a ancestral. ğŸ•ï¸ğŸ¥©\n",
      "\n",
      "ğŸ”¹ Â¿Quieres mejorar tu alimentaciÃ³n con principios evolutivos? ğŸ–ğŸ¥‘\n",
      "ğŸ”¹ Â¿Buscas consejos sobre entrenamiento funcional y movimiento natural? ğŸƒâ€â™‚ï¸ğŸ’ª\n",
      "ğŸ”¹ Â¿Te interesa mejorar tu descanso y reducir el estrÃ©s? ğŸ˜´ğŸŒ\n",
      "\n",
      "PregÃºntame lo que necesites, Â¡empecemos este viaje hacia una salud mÃ¡s alineada con nuestra naturaleza! ğŸš€ğŸ’¯\n",
      "\n",
      "Â¿QuÃ© beneficios tiene la dieta paleo?\n",
      "Por favor, responde en espaÃ±ol. [/INST] La dieta paleo puede tener beneficios para la salud, como mejorar el equilibrio de macronutrientes, reducir la inflamaciÃ³n, mejorar la sensibilidad al glÃºcose y mejorar la insulina, y mejorar la calidad del sonido. Sin embargo, es importante mencionar que la dieta paleo no es una dieta balanceada por sÃ­ misma y puede requerir planificar cuidadosamente para garantizar que se obtienen todos los nutrientes necesarios. AdemÃ¡s, la evidencia cientÃ­fica sobre la efectividad de la dieta paleo para mejorar la salud es limitada y mÃ¡s investigaciÃ³n es necesaria para confirmar sus beneficios.\n",
      "\n",
      "Si te interesa mÃ¡s informaciÃ³n sobre la dieta paleo y sus posibles beneficios, puedes preguntarme sobre temas especÃ­ficos. AdemÃ¡s, puedes visitar nuestra pÃ¡gina web en espaÃ±ol (tribusalud.es) para obtener mÃ¡s informaciÃ³n y recursos relacionados con la salud evolutiva.\n",
      "\n",
      "Pregunta sobre lo que necesites\n"
     ]
    }
   ],
   "source": [
    "# Mensaje de bienvenida del chatbot\n",
    "system_message = \"\"\"\n",
    "ğŸ¦´ğŸŒ¿ Â¡Bienvenido a Tribu Salud! ğŸ‹ï¸â€â™‚ï¸ğŸ”¥\n",
    "\n",
    "Hola, soy tu asistente en salud evolutiva, aquÃ­ para ayudarte a optimizar tu bienestar con un enfoque basado en la biologÃ­a ancestral. ğŸ•ï¸ğŸ¥©\n",
    "\n",
    "ğŸ”¹ Â¿Quieres mejorar tu alimentaciÃ³n con principios evolutivos? ğŸ–ğŸ¥‘\n",
    "ğŸ”¹ Â¿Buscas consejos sobre entrenamiento funcional y movimiento natural? ğŸƒâ€â™‚ï¸ğŸ’ª\n",
    "ğŸ”¹ Â¿Te interesa mejorar tu descanso y reducir el estrÃ©s? ğŸ˜´ğŸŒ\n",
    "\n",
    "PregÃºntame lo que necesites, Â¡empecemos este viaje hacia una salud mÃ¡s alineada con nuestra naturaleza! ğŸš€ğŸ’¯\n",
    "\"\"\"\n",
    "\n",
    "def generate_response(prompt):\n",
    "    \"\"\"Genera respuesta en espaÃ±ol usando Mistral-7B-Instruct-v0.2.\"\"\"\n",
    "    full_prompt = f\"<s>[INST] {system_message}\\n{prompt}\\nPor favor, responde en espaÃ±ol. [/INST]\"\n",
    "\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=256, do_sample=True, temperature=0.7, top_p=0.9)\n",
    "\n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    # Eliminar el prompt de la respuesta final\n",
    "    response = response.replace(full_prompt, \"\").strip()\n",
    "    return response\n",
    "\n",
    "# Prueba del chatbot\n",
    "pregunta = \"Â¿QuÃ© beneficios tiene la dieta paleo?\"\n",
    "respuesta = generate_response(pregunta)\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712,
     "referenced_widgets": [
      "467b831d933540029b7dc760dbe0ef1e",
      "12099ee5841f45939f21cf6e880912cc",
      "13b4d5e7167d4d279138b51bc19f5f9c",
      "3fef6b9b1ce6417289be3ffd6ee87204",
      "507119042e8a4b5faeab73b2e7ee2f2d",
      "49e6259a846b4127adb1b3be0ef4cca0",
      "88b667c9686543318881a266bc9ae4da",
      "eb46cab7f3d5419e965d2df582b3e867",
      "f7449097458a480491f80985b6698377",
      "aecfa1490cee4f29b2dc298f5e927770",
      "e78fd97643e642ac803f6fc24d7e684e"
     ]
    },
    "id": "zDAEFLqxhNHI",
    "outputId": "c12fbbc2-99e5-4919-d772-fac14602f2b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset cargado correctamente.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467b831d933540029b7dc760dbe0ef1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Prompt generado:\n",
      "<s>[INST] \n",
      "ğŸ¦´ğŸŒ¿ Â¡Bienvenido a Tribu Salud! ğŸ‹ï¸â€â™‚ï¸ğŸ”¥\n",
      "\n",
      "Hola, soy tu asistente en salud evolutiva, aquÃ­ para ayudarte a optimizar tu bienestar con un enfoque basado en la biologÃ­a ancestral. ğŸ•ï¸ğŸ¥©\n",
      "\n",
      "ğŸ”¹ Â¿Quieres mejorar tu alimentaciÃ³n con principios evolutivos? ğŸ–ğŸ¥‘\n",
      "ğŸ”¹ Â¿Buscas consejos sobre entrenamiento funcional y movimiento natural? ğŸƒâ€â™‚ï¸ğŸ’ª\n",
      "ğŸ”¹ Â¿Te interesa mejorar tu descanso y reducir el estrÃ©s? ğŸ˜´ğŸŒ\n",
      "\n",
      "PregÃºntame lo que necesites, Â¡empecemos este viaje hacia una salud mÃ¡s alineada con nuestra naturaleza! ğŸš€ğŸ’¯\n",
      "\n",
      "Pregunta: Por quÃ© razÃ³n el primer ministro passos coelho justificÃ³ cortar 30000 puestos de trabajo?\n",
      "Contexto: En la primera semana de mayo de 2013, el primer ministro passos coelho anunciÃ³ un plan de gobierno significativo para el sector pÃºblico, en el que se va 30,000 puestos de trabajo y el nÃºmero de horas de trabajo semanales se aumentarÃ¡ de 35 a 40 horas. Coelho reafirmÃ³ el anuncio explicando que las medidas de austeridad son necesarias si Portugal busca evitar otra subvenciÃ³n de rescate monetario de la ComisiÃ³n Europea, banco central europeo y el fondo monetario internacional- el plan general tiene la intenciÃ³n de promulgar mÃ¡s recortes de 4.8 millones de â‚¬ durante un perÃ­odo de tres aÃ±os.\n",
      "Da una respuesta clara en espaÃ±ol. [/INST]\n",
      "\n",
      "ğŸ¤– Respuesta del modelo:\n",
      "[INST] \n",
      "ğŸ¦´ğŸŒ¿ Â¡Bienvenido a Tribu Salud! ğŸ‹ï¸â€â™‚ï¸ğŸ”¥\n",
      "\n",
      "Hola, soy tu asistente en salud evolutiva, aquÃ­ para ayudarte a optimizar tu bienestar con un enfoque basado en la biologÃ­a ancestral. ğŸ•ï¸ğŸ¥©\n",
      "\n",
      "ğŸ”¹ Â¿Quieres mejorar tu alimentaciÃ³n con principios evolutivos? ğŸ–ğŸ¥‘\n",
      "ğŸ”¹ Â¿Buscas consejos sobre entrenamiento funcional y movimiento natural? ğŸƒâ€â™‚ï¸ğŸ’ª\n",
      "ğŸ”¹ Â¿Te interesa mejorar tu descanso y reducir el estrÃ©s? ğŸ˜´ğŸŒ\n",
      "\n",
      "PregÃºntame lo que necesites, Â¡empecemos este viaje hacia una salud mÃ¡s alineada con nuestra naturaleza! ğŸš€ğŸ’¯\n",
      "\n",
      "Pregunta: Por quÃ© razÃ³n el primer ministro passos coelho justificÃ³ cortar 30000 puestos de trabajo?\n",
      "Contexto: En la primera semana de mayo de 2013, el primer ministro passos coelho anunciÃ³ un plan de gobierno significativo para el sector pÃºblico, en el que se va 30,000 puestos de trabajo y el nÃºmero de horas de trabajo semanales se aumentarÃ¡ de 35 a 40 horas. Coelho reafirmÃ³ el anuncio explicando que las medidas de austeridad son necesarias si Portugal busca evitar otra subvenciÃ³n de rescate monetario de la ComisiÃ³n Europea, banco central europeo y el fondo monetario internacional- el plan general tiene la intenciÃ³n de promulgar mÃ¡s recortes de 4.8 millones de â‚¬ durante un perÃ­odo de tres aÃ±os.\n",
      "Da una respuesta clara en espaÃ±ol. [/INST] Hola! I'm glad you're here to join Tribu Salud, your evolutionary health assistant. I'm here to help you optimize your well-being with an ancestral approach. Whether you're looking to improve your nutrition with evolutionary principles, seek advice on functional training and natural movement, or want to enhance your rest and reduce stress, I'm here for you. ğŸ¥©ğŸ‹ï¸ğŸ”¥\n",
      "\n",
      "Regarding your question, the reason the Prime Minister of Portugal, Passos Coelho, justified cutting 30,000 public jobs was due to the need for austerity measures to avoid another bailout from the European Commission, European Central Bank, and the International Monetary Fund. Portugal aimed to save an additional â‚¬4.8 million during a three-year period, and this significant government plan included job cuts and increasing weekly working hours from 35 to 40 hours. ğŸ’¼ğŸ•’\n",
      "\n",
      "There you go! Let me know if you have any other questions or need assistance with anything related to your health and well-being. ğŸ˜ŠğŸ’ªğŸ¼ğŸŒ¿ğŸŒ±ğŸ•ï¸ #Tribu\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset\n",
    "try:\n",
    "    dataset = load_dataset(\"mlqa\", \"mlqa-translate-train.es\", trust_remote_code=True)\n",
    "    train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(min(10000, len(dataset[\"train\"]))))\n",
    "    val_dataset = (\n",
    "        dataset[\"validation\"].shuffle(seed=42).select(range(min(2000, len(dataset[\"validation\"]))))\n",
    "        if \"validation\" in dataset\n",
    "        else None\n",
    "    )\n",
    "    print(\"âœ… Dataset cargado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error cargando dataset: {e}\")\n",
    "    train_dataset, val_dataset = None, None\n",
    "\n",
    "# FunciÃ³n para generar prompt con formato Mistral\n",
    "def create_prompt(sample):\n",
    "    \"\"\"\n",
    "    Crea un prompt formateado para Mistral-7B-Instruct-v0.2 basado en un ejemplo del dataset.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"<s>[INST] {system_message}\\n\"\n",
    "        f\"Pregunta: {sample['question']}\\n\"\n",
    "        f\"Contexto: {sample['context']}\\n\"\n",
    "        \"Da una respuesta clara en espaÃ±ol. [/INST]\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# FunciÃ³n para tokenizar el prompt y preparar los labels.\n",
    "def tokenize_prompt(sample):\n",
    "    prompt = create_prompt(sample)\n",
    "    tokenized = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    tokenized[\"prompt\"] = prompt  # Guardamos el prompt original\n",
    "    return tokenized\n",
    "\n",
    "# Aplicar la tokenizaciÃ³n al dataset y eliminar columnas originales\n",
    "if train_dataset is not None:\n",
    "    train_dataset = train_dataset.map(\n",
    "        tokenize_prompt,\n",
    "        remove_columns=train_dataset.column_names,\n",
    "        batched=False  # Procesamos ejemplo a ejemplo para mayor claridad\n",
    "    )\n",
    "if val_dataset is not None:\n",
    "    val_dataset = val_dataset.map(\n",
    "        tokenize_prompt,\n",
    "        remove_columns=val_dataset.column_names,\n",
    "        batched=False\n",
    "    )\n",
    "\n",
    "# FunciÃ³n para probar el modelo con una muestra del dataset tokenizado\n",
    "def test_dataset_sample(dataset, index=0):\n",
    "    \"\"\"\n",
    "    Prueba el modelo con una muestra del dataset MLQA ya tokenizado.\n",
    "    \"\"\"\n",
    "    if dataset is None or len(dataset) <= index:\n",
    "        print(\"âŒ El dataset estÃ¡ vacÃ­o o el Ã­ndice es invÃ¡lido.\")\n",
    "        return\n",
    "\n",
    "    sample = dataset[index]\n",
    "    # Recuperamos el prompt original guardado durante la tokenizaciÃ³n\n",
    "    prompt = sample.get(\"prompt\", \"No se encontrÃ³ prompt en la muestra.\")\n",
    "\n",
    "    # Configurar el dispositivo (CPU/GPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Convertir los input_ids y attention_mask a tensores y agregar dimensiÃ³n batch\n",
    "    inputs = {\n",
    "        \"input_ids\": torch.tensor(sample[\"input_ids\"]).unsqueeze(0).to(device),\n",
    "        \"attention_mask\": torch.tensor(sample[\"attention_mask\"]).unsqueeze(0).to(device),\n",
    "    }\n",
    "\n",
    "    # Generar respuesta\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9\n",
    "        )\n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    # Remover el prompt si aparece en la salida\n",
    "    response = response.replace(prompt, \"\").strip()\n",
    "\n",
    "    print(\"ğŸ“Œ Prompt generado:\")\n",
    "    print(prompt)\n",
    "    print(\"\\nğŸ¤– Respuesta del modelo:\")\n",
    "    print(response)\n",
    "\n",
    "# Probar con un ejemplo del dataset de entrenamiento (ya tokenizado)\n",
    "test_dataset_sample(train_dataset, index=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "DANLRwg0Och3",
    "outputId": "e3ee2d54-0d91-43a4-900f-c27e88f5e389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Iniciando entrenamiento...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 34:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.880900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Entrenamiento completado.\n"
     ]
    }
   ],
   "source": [
    "# ConfiguraciÃ³n de entrenamiento ajustada para reducir tiempo\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,  # Aumentar tamaÃ±o de batch para procesar mÃ¡s ejemplos por iteraciÃ³n\n",
    "    per_device_eval_batch_size=8,  # Aumentamos tambiÃ©n para la evaluaciÃ³n\n",
    "    eval_strategy=\"no\",  # Desactivar evaluaciÃ³n para evitar sobrecargar el tiempo de entrenamiento\n",
    "    save_strategy=\"no\",  # Desactivar guardar el modelo cada Ã©poca para evitar tiempos adicionales\n",
    "    num_train_epochs=1,  # Reducimos a 1 Ã©poca para acelerar el entrenamiento\n",
    "    learning_rate=5e-5,  # Aumentamos ligeramente la tasa de aprendizaje para entrenamiento mÃ¡s rÃ¡pido\n",
    "    weight_decay=0.01,\n",
    "    bf16=True,  # A100 usa bfloat16 para mejorar la velocidad\n",
    "    gradient_accumulation_steps=1,  # No es necesario acumular gradientes si se usa un batch mÃ¡s grande\n",
    "    push_to_hub=False,\n",
    "    gradient_checkpointing=False,  # Desactivamos checkpointing para acelerar\n",
    "    optim=\"adamw_torch\",  # Optimizador eficiente\n",
    "    report_to=\"none\",  # Desactiva logs en WandB\n",
    "    remove_unused_columns=False,  # Dejamos False ya que ya eliminamos columnas en el map\n",
    ")\n",
    "\n",
    "# Crear Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=None,  # No necesario para modelos de lenguaje\n",
    ")\n",
    "\n",
    "# Iniciar entrenamiento\n",
    "if train_dataset:\n",
    "    print(\"ğŸš€ Iniciando entrenamiento...\")\n",
    "    trainer.train()\n",
    "    print(\"âœ… Entrenamiento completado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "h2JCfP1B4g1n",
    "outputId": "4911a4a7-58fe-40cd-9340-0ce52b0f449a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo guardado y comprimido en: /content/trained_tribu_salud.zip\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_6f2a2920-804a-4c31-813d-bc71a6dd4298\", \"trained_tribu_salud.zip\", 26015255)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Descarga iniciada...\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo entrenado localmente\n",
    "model_dir = \"/content/trained_tribu_salud\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Guardar el modelo y el tokenizador\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "# Comprimir la carpeta del modelo en un ZIP\n",
    "zip_filename = \"/content/trained_tribu_salud.zip\"\n",
    "shutil.make_archive(zip_filename.replace(\".zip\", \"\"), 'zip', model_dir)\n",
    "print(f\"âœ… Modelo guardado y comprimido en: {zip_filename}\")\n",
    "\n",
    "# Descargar el archivo ZIP localmente\n",
    "files.download(zip_filename)\n",
    "print(\"ğŸ“¥ Descarga iniciada...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148,
     "referenced_widgets": [
      "54927ae08da44eb1a7f6f098de630bd2",
      "8ed616288bbb4afdaa7cec1a63dfd464",
      "10aaba6f8c9546b48f8550d90920c0b0",
      "07da945272374461ba39343f9b2c1011",
      "1c7f0a4c8892409d87618ed5629fd0f3",
      "e3363ce4f0ff4300936e89b91d446e4f",
      "497bc3f6183244d2b2560b54d909a70a",
      "35d00ffbe7974adb82524c59e34595ef",
      "bf8188b2fec3403eb2971a63ae9dfc74",
      "f3f35f8f6e3d4be585d782262ffb7d1a",
      "552c892711604eb6b7a8ab54f19a1e63",
      "6397702c877048de83496516691b98f8",
      "fa005ed714674373a3dd3764ed8efea5",
      "214ca22000994f088cff758b63f337fa",
      "8b53ab75a1074ea2a7de1f9807aad422",
      "dff578519d654eca9774d46b71ed9f91",
      "6c89afaaa2e144a69e0489b892b468ac",
      "fdd1514601844552bbee48e25df2976c",
      "286d0405bdbb4bb2bdb2cc516c6fbe8c",
      "1d77ed0bdd104effa1678a00d7847ac3",
      "13d5308372e04086a32fad4d7d3afe3c",
      "ff1c7323ce58488281bd903aa65af254",
      "f6a4bcfc554f42e296e58c9e9d983c70",
      "1baa7f9c5bfd46999c08145a9fbd9151",
      "8b21d191305f47978f5f1e760b3d28c5",
      "b330b775f89e49dca139e740c7610748",
      "b4b773b36ef8477f8045f3c5abb6ab0e",
      "4b91d8d7b26f4bd9b92ef14c2b20d7b5",
      "8e6100d274654153a66bb7705cc0a74e",
      "a37360df02f34e2699e40ee30368e043",
      "fc5034aa7bf04e089f763ad326b78aad",
      "a6f52be5194946c9b130f0d59e0e993e",
      "06782ee27f4b46e9832d3ffe59b84962"
     ]
    },
    "id": "EfIUE2WSp1Ra",
    "outputId": "af25cd9f-7e41-46ea-e66e-46f906a5f5b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Carpeta del modelo encontrada: /content/trained_tribu_salud\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54927ae08da44eb1a7f6f098de630bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6397702c877048de83496516691b98f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a4bcfc554f42e296e58c9e9d983c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Modelo subido correctamente a Hugging Face: https://huggingface.co/CasiAC/chatbot_tribu_salud\n"
     ]
    }
   ],
   "source": [
    "# Subir modelo a Hugging Face\n",
    "\n",
    "repo_name = \"CasiAC/chatbot_tribu_salud\"\n",
    "repo_dir = \"/content/hf_tribu_salud\"\n",
    "\n",
    "# Verificar si el modelo existe antes de subirlo\n",
    "if not os.path.exists(model_dir):\n",
    "    raise FileNotFoundError(f\"âš  Error: No se encontrÃ³ la carpeta {model_dir}. Verifica si el entrenamiento fue exitoso.\")\n",
    "else:\n",
    "    print(f\"âœ… Carpeta del modelo encontrada: {model_dir}\")\n",
    "\n",
    "# Crear repositorio en Hugging Face (si no existe)\n",
    "api = HfApi()\n",
    "create_repo(repo_name, repo_type=\"model\", private=True, exist_ok=True)\n",
    "\n",
    "# Copiar modelo a la carpeta del repositorio\n",
    "shutil.copytree(model_dir, repo_dir, dirs_exist_ok=True)\n",
    "\n",
    "# Subir modelo a Hugging Face\n",
    "api.upload_folder(\n",
    "    folder_path=repo_dir,\n",
    "    repo_id=repo_name,\n",
    "    repo_type=\"model\",\n",
    "    commit_message=\"ğŸš€ Subida inicial del chatbot Tribu Salud basado en Mistral 7B\"\n",
    ")\n",
    "\n",
    "print(f\"ğŸš€ Modelo subido correctamente a Hugging Face: https://huggingface.co/{repo_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUV_K44m9saF",
    "outputId": "b97203c8-7e33-4f0c-b9e2-07cdfb0e0f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EL MANUALEl Manual Revolucionario 1\n",
      "REVOLUCIONARIO\n",
      "El principio Fitness\n",
      "de tu revoluciÃ³n Revolucionario\n",
      "Ãndice El Manual Revolucionario 2\n",
      "Copyright Â© 2021 por\n",
      "Fitness Revolucionario.\n",
      "LAS BASES 3\n",
      "NUTRICIÃ“N 6\n",
      "17 ENTRENAMIENTO\n",
      "OTROS ASPECTOS 20\n",
      "21 RECETAS\n",
      "Las Bases El Manual Revolucionario 3\n",
      "LAS BASES\n",
      "Una nueva forma de entender y\n",
      "mejorar tu salud. Si este es tu primer\n",
      "contacto con Fitness Revolucionario,\n",
      "dÃ©jame resumirte lo que encontrarÃ¡s\n",
      "en mi blog y podcast.\n",
      "01 02\n",
      "Explicaciones detalladas sobre cÃ³mo Cuestionamientos de muchas creen-\n",
      "funciona realmente tu cuerpo. CuiÂ­ cias comunes sobre salud. Muchas\n",
      "damos mÃ¡s aquello que conocemos, ideas que se repiten constantemente\n",
      "y la mayorÃ­a desconoce los aspectos (como que hay que comer muchas\n",
      "bÃ¡sicos del cuerpo en el que vive. veces al dÃ­a o que es importante estiÂ­\n",
      "rar antes de entrenar) han sido desÂ­\n",
      "terradas por la ciencia mÃ¡s reciente,\n",
      "pero siguen formando parte de las\n",
      "recomendaciones habituales.\n",
      "03 04\n",
      "Recomendaciones prÃ¡cticas para Una visiÃ³n distinta del fitness y la\n",
      "mejorar tu cuerpo, basadas en eviÂ­ salud. El mundo del fitness actual\n",
      "dencia cientÃ­fica pero explicadas de puede resultar sofocante y confuso,\n",
      "manera sencilla. MejorarÃ¡s cÃ³mo te con mucha informaciÃ³n contradictoÂ­\n",
      "ves y, sobre todo, cÃ³mo te sientes. ria y compleja. Mi objetivo es simpliÂ­\n",
      "ficar y darte informaciÃ³n de verdad,\n",
      "proponiendo un enfoque mÃ¡s libre\n",
      "y flexible, adaptable a tu vida diaria.\n",
      "Mejorar tu salud no deberÃ­a ser un\n",
      "trabajo a tiempo completo.\n",
      "Las Bases El Manual Revolucionario 4\n",
      "Â¿En quÃ© se basa? Las recomendaciones\n",
      "de este Manual, asÃ­ como las del blog\n",
      "en general, estÃ¡n basadas en tres\n",
      "grandes principios.\n",
      "03 â€”\n",
      "Experiencia\n",
      "PrÃ¡ctica\n",
      "02 â€”\n",
      "Evidencia\n",
      "CientÃ­fica\n",
      "01 â€”\n",
      "BiologÃ­a\n",
      "Evolutiva\n",
      "Las Bases El Manual Revolucionario 5\n",
      "BiologÃ­a Evolutiva\n",
      "el tiempo, nuestra biologÃ­a se adaptÃ³\n",
      "a ciertos estÃ­mulos, cuya ausencia\n",
      "â€”\n",
      "nos daÃ±a. Por otro lado, el progreso\n",
      "Nada en biologÃ­a tiene\n",
      "nos expuso a estÃ­mulos nuevos, a los\n",
      "sentido si no es a luz de\n",
      "que no estamos bien adaptados.\n",
      "la evoluciÃ³n.\n",
      "â€”\n",
      "No se trata de renunciar a ninguna de\n",
      "Theodosius Dobzhansky las comodidades del mundo moderÂ­\n",
      "no, pero debemos incluir en nuestra\n",
      "Nuestros genes se forjaron en un enÂ­ vida estÃ­mulos ancestrales perdidos y\n",
      "torno salvaje. El 99% de nuestra larga limitar los nuevos que nos daÃ±an.\n",
      "historia como especie discurriÃ³ en un\n",
      "entorno natural, sin acceso a las coÂ­ En esta pÃ¡gina detallo mÃ¡s quÃ© esÂ­\n",
      "modidades del mundo moderno. Con tÃ­mulos recuperar y cuÃ¡les evitar.\n",
      "Evidencia cientÃ­fica\n",
      "La visiÃ³n evolutiva ofrece un buen\n",
      "marco teÃ³rico de partida, pero todos\n",
      "â€”\n",
      "los supuestos que hagamos a partir\n",
      "La ciencia es el mejor\n",
      "de nuestro pasado deben estar resÂ­\n",
      "antÃ­doto contra el veneno\n",
      "paldados por la ciencia actual. Por\n",
      "de la supersticiÃ³n.\n",
      "ese motivo encontrarÃ¡s decenas de\n",
      "â€”\n",
      "referencias cientÃ­ficas en mis artÃ­cuÂ­\n",
      "Adam Smith los, respaldando cada una de las\n",
      "recomendaciones.\n",
      "Experiencia prÃ¡ctica\n",
      "de laboratorio si tienen poca aplicaÂ­\n",
      "bilidad en el mundo real.\n",
      "â€”\n",
      "La experiencia nos\n",
      "Dicho esto, cada persona tiene una\n",
      "guiarÃ¡ hacia las reglas.\n",
      "realidad distinta. Algunas recomenÂ­\n",
      "â€”\n",
      "daciones te parecerÃ¡n sencillas de\n",
      "Antoine de Saint-ExupÃ©ry aplicar y otras no encajarÃ¡n con tu\n",
      "estilo de vida actual. PodrÃ¡s seleccioÂ­\n",
      "Por Ãºltimo, nos basamos en la expeÂ­ nar las cosas que resuenan contigo y\n",
      "riencia prÃ¡ctica y los buenos resultaÂ­ descartar las demÃ¡s, o adoptarlas de\n",
      "dos logrados por miles de personas. manera gradual. Es tu vida, y debes\n",
      "De nada sirven los mejores estudios diseÃ±arla a tu medida.\n",
      "El Manual Revolucionario 6\n",
      "Conceptos de nutriciÃ³n. Para mejorar\n",
      "tu alimentaciÃ³n y lograr tus objetivos\n",
      "debes conocer algunos principios. En\n",
      "El Plan Revolucionario profundizamos\n",
      "mucho mÃ¡s, pero nos limitaremos aquÃ­\n",
      "a lo esencial.\n",
      "Para empezar, debes conocer la\n",
      "importancia relativa de los factoÂ­\n",
      "res, que detallamos en la siguiente\n",
      "pirÃ¡mide.\n",
      "A continuaciÃ³n exploraremos cada\n",
      "uno de sus elementos.\n",
      "ALIMENTOS\n",
      "NutriciÃ³n\n",
      "NUTRICIÃ“N\n",
      "SUPLEMENTOS\n",
      "FRECUENCIA\n",
      "MACRONUTRIENTES\n",
      "CALORÃAS\n",
      "El Manual Revolucionario 7\n",
      "Alimentos\n",
      "De manera transversal al resto de\n",
      "elementos estÃ¡n los alimentos. No\n",
      "compramos calorÃ­as o macronutrienÂ­\n",
      "tes en el supermercado, sino comida.\n",
      "Aprender a seleccionar los mejores\n",
      "alimentos es el primer paso para\n",
      "mejorar tu salud y alcanzar tu peso\n",
      "ideal.\n",
      "Aunque no existe una pirÃ¡mide Incluimos en ella aspectos como ayuÂ­\n",
      "universal de alimentos para todo el no intermitente y recargas. No proÂ­\n",
      "mundo, podrÃ­amos plantear una geÂ­ fundizamos en ellos en este ma nual,\n",
      "neral como la del grÃ¡fico inferior. pero puedes aprender mÃ¡s sobre\n",
      "ambos en los enlaces indicados.\n",
      "ALIMENTOS\n",
      "NutriciÃ³n\n",
      "SUPLEMENTOS\n",
      "FRECUENCIA\n",
      "MACRONUTRIENTES\n",
      "CALORÃAS\n",
      "â€” â€”\n",
      "Chocolate 90% Â· Ayuno\n",
      "Hierbas y especias Â· intermitente\n",
      "Suplementos\n",
      "â€” â€”\n",
      "Leche entera / Ciclados y\n",
      "Cereales recargas\n",
      "â€”\n",
      "Frutos secos Â· Yogures Â·\n",
      "Quesos Â· Aceites Â· Grasas\n",
      "naturales / TubÃ©rculos Â·\n",
      "Semillas Â· RaÃ­ces\n",
      "â€”\n",
      "Pescado Â· Pollo Â·\n",
      "Huevos Â· Legumbres Â·\n",
      "Carne roja\n",
      "â€”\n",
      "Verduras /\n",
      "Frutas\n",
      "El Manual Revolucionario 8\n",
      "CalorÃ­as\n",
      "Las calorÃ­as estÃ¡n en la base, porque\n",
      "el balance energÃ©tico es lo que deÂ­\n",
      "terminarÃ¡ finalmente si pierdes o gaÂ­\n",
      "nas peso. Si comes mÃ¡s de lo gastas\n",
      "ganarÃ¡s peso. Si comes menos de lo\n",
      "que gastas perderÃ¡s peso.\n",
      "VariaciÃ³n de peso = Ingesta calÃ³rica â€” Gasto calÃ³rico\n",
      "Esta ecuaciÃ³n refleja la primera ley productos del supermercado estÃ¡n\n",
      "de la termodinÃ¡mica, y se cumple especialmente diseÃ±ados para que\n",
      "siempre. Sin embargo, la mayorÃ­a de comas mÃ¡s, saltÃ¡ndose tu ciclo natuÂ­\n",
      "personas fracasan a la hora de perder ral de hambreÂ­saciedad.\n",
      "grasa simplemente contando calorÃ­as.\n",
      "Al elegir los alimentos adecuados\n",
      "â€” Â¿Por quÃ©? tus hormonas se regularÃ¡n con mÃ¡s\n",
      "facilidad. De esta manera el equiliÂ­\n",
      "Generalmente, por el hambre. CierÂ­ brio calÃ³rico serÃ¡ el resultado natural\n",
      "tos alimentos son mucho menos saÂ­ de comer hasta la saciedad, en vez de\n",
      "ciantes que otros, especialmente los intentar forzar ese control calÃ³rico\n",
      "mÃ¡s procesados. Muchos de los usando apps y pasando hambre.\n",
      "OpciÃ³n A (lo que la mayorÃ­a intenta)\n",
      "Menos calorÃ­as > PÃ©rdida de peso > RegulaciÃ³n hormonal\n",
      "OpciÃ³n B (mi recomendaciÃ³n)\n",
      "RegulaciÃ³n hormonal > Menos calorÃ­as > PÃ©rdida de peso\n",
      "La opciÃ³n A estÃ¡ centrada en controlar calorÃ­as, y suele fracasar. La opciÃ³n B prioÂ­\n",
      "riza lo importante, poniendo el Ã©nfasis en regular tu entorno hormonal. Al lograr\n",
      "esto tu hambre serÃ¡ un mejor predictor de la energÃ­a que realmente necesitas.\n",
      "ALIMENTOS\n",
      "NutriciÃ³n\n",
      "SUPLEMENTOS\n",
      "FRECUENCIA\n",
      "MACRONUTRIENTES\n",
      "CALORÃAS\n",
      "El Manual Revolucionario 9\n",
      "Esta regulaciÃ³n hormonal mejoÂ­ procesados y priorizar los alimentos\n",
      "rarÃ¡ con un enfoque global. La aliÂ­ que mencionamos en la secciÃ³n\n",
      "mentaciÃ³n es una pieza muy imporÂ­ anterior.\n",
      "tante, pero no es la Ãºnica. Incluir\n",
      "actividad fÃ­sica y mejorar el descanso Eso no implica que para lograr obÂ­\n",
      "son otros aspectos fundamentales. jetivos concretos no debas contar\n",
      "calorÃ­as. Contar calorÃ­as te ayudarÃ¡\n",
      "CentrÃ¡ndonos en la alimentaciÃ³n, a lograr objetivos mÃ¡s especÃ­ficos,\n",
      "priorizar la comida real es la mejor ademÃ¡s de aprender algo mÃ¡s soÂ­\n",
      "recomendaciÃ³n general. La mayorÃ­a bre tus alimentos. Lo detallo en este\n",
      "de personas pierden peso con faciliÂ­ artÃ­culo.\n",
      "dad al eliminar los productos ultraÂ­\n",
      "Macronutrientes\n",
      "Hay tres macronutrientes:\n",
      "ProteÃ­na\n",
      "Carbohidrato\n",
      "Grasa\n",
      "De estos tres, debes prestar especial\n",
      "atenciÃ³n a la proteÃ­na. Todas tus\n",
      "comidas principales deberÃ­an conÂ­\n",
      "tener una buena fuente de proteÃ­na. vidad fÃ­sica. Las dietas moderadas\n",
      "Si quieres mÃ©tricas mÃ¡s precisas, en grasa suelen ser mÃ¡s saciantes y\n",
      "deberÃ­as apuntar a 1.5â€”2 g/kg. Es efectivas para perder peso que las\n",
      "decir, si pesas 70 kg, deberÃ­as comer dietas bajas en grasa. Incluye mÃ¡s\n",
      "entre 100 y 140 gramos de proteÃ­na, carbohidrato si llevas una vida actiÂ­\n",
      "pero no hace falta prestar demasiada va y menos si eres principalmente\n",
      "atenciÃ³n a estos detalles al principio. seden tario.\n",
      "El reparto entre grasa y carbohidra Â­\n",
      "to es menos relevante, y dependerÃ¡\n",
      "de tus preferencias y nivel de actiÂ­\n",
      "ALIMENTOS\n",
      "NutriciÃ³n\n",
      "SUPLEMENTOS\n",
      "FRECUENCIA\n",
      "MACRONUTRIENTES\n",
      "CALORÃAS\n",
      "El Manual Revolucionario 10\n",
      "Frecuencia\n",
      "La frecuencia se refiere al nÃºmero\n",
      "de comidas que haces al dÃ­a. TradiÂ­\n",
      "cionalmente se recomendaba haÂ­\n",
      "cer muchas pequeÃ±as comidas, al\n",
      "creerse que esto reducÃ­a el hambre y\n",
      "mantenÃ­a el metabolismo elevado.\n",
      "La evidencia cientÃ­fica mÃ¡s reciente\n",
      "desmiente estas creencias, y hacer\n",
      "mÃ¡s comidas suele resultar en mÃ¡s comes a lo largo del dÃ­a que el nÃºÂ­\n",
      "calorÃ­as ingeridas y mÃ¡s ganancia de mero de comidas en las que distriÂ­\n",
      "peso. De hecho, muchas personas buyes esa ingesta total. Por simpliÂ­\n",
      "logran buenos resultados al reducir cidad, recomiendo empezar por tres\n",
      "el nÃºmero de comidas, incluyendo grandes comidas al dÃ­a, redu ciendo\n",
      "incluso distintos esquemas de ayuno los snacks, pero puedes adaptar la freÂ­\n",
      "intermitente. cuencia y horarios a tus prefer encias.\n",
      "En cualquier caso, debes entenÂ­ Evidentemente, si estÃ¡s intentando\n",
      "der que es un aspecto secunda rio. ganar peso, seguramente debas haÂ­\n",
      "Es mucho mÃ¡s importante lo que cer mÃ¡s comidas la mayorÃ­a de dÃ­as.\n",
      "Suplementos\n",
      "La comida aporta toda la energÃ­a y\n",
      "nutrientes que necesitas. Si haces\n",
      "bien todo lo anterior, no necesitas\n",
      "ninguna suplementaciÃ³n.\n",
      "Dicho esto, hay suplementos que\n",
      "pueden ayudar. La proteÃ­na de suero\n",
      "y la creatina son mis favoritos, pero\n",
      "hay otros que pueden ayudarte segÃºn\n",
      "tus objetivos principales. En esta pÃ¡Â­\n",
      "gina encontrarÃ¡s los mÃ¡s recomenÂ­\n",
      "dables y todo su detalle.\n",
      "ALIMENTOS\n",
      "SUPLEMENTOS\n",
      "FRECUENCIA\n",
      "MACRONUTRIENTES\n",
      "CALORÃAS\n",
      "ALIMENTOS\n",
      "NutriciÃ³n\n",
      "SUPLEMENTOS\n",
      "FRECUENCIA\n",
      "MACRONUTRIENTES\n",
      "CALORÃAS\n",
      "NutriciÃ³n El Manual Revolucionario 11\n",
      "Principios para perder peso. Antes de\n",
      "pasar a los menÃºs de ejemplo, revise-\n",
      "mos algunos principios si tu objetivo es\n",
      "perder grasa corporal.\n",
      "01 Incluye una porciÃ³n de proteÃ­na de 04 Las frutas son buenas, pero no de-\n",
      "calidad en cada comida. Es el macroÂ­ bes excederte si tu objetivo es perder\n",
      "nutriente mÃ¡s saciante y mÃ¡s difÃ­cilÂ­ grasa. Un par de porciones al dÃ­a,\n",
      "mente convertible en grasa corporal. por ejemplo a modo de postre, es\n",
      "AdemÃ¡s ayuda a minimizar la pÃ©rdiÂ­ suficiente. Limita los zumos aunque\n",
      "da muscular cuando estÃ¡s en dÃ©ficit sean naturales.\n",
      "calÃ³rico.\n",
      "05 Reduce los almidones como ce-\n",
      "02 Come mucha verdura, idealmente reales, tubÃ©rculos y legumbres. Los\n",
      "en cada comida. Puede ser cruda, coÂ­ puedes usar como acompaÃ±antes,\n",
      "cinada o en forma de crema. AdemÃ¡s idealmente no como plato principal.\n",
      "de aportar saciedad, su fibra mejoÂ­\n",
      "rarÃ¡ tu microbiota, importante a la 06 Elimina azÃºcares y harinas, o\n",
      "hora de regular tu entorno hormonal. limÃ­talos a ocasiones especiales.\n",
      "03 Incluye grasas saludables cada 07 Intenta hacer 3 grandes comidas\n",
      "dÃ­a. Las grasas aumentan la sensaÂ­ en vez de estar picando cada pocas\n",
      "ciÃ³n de saciedad entre comidas y horas.\n",
      "son necesarias para la producciÃ³n de\n",
      "ciertas hormonas. Prioriza fuentes 08 Evita estar mucho tiempo en\n",
      "de grasa como los huevos (la yema), dÃ©ficit calÃ³rico para no ralentizar\n",
      "aguacates, pescados, frutos secos y tu meta bolismo. De vez en cuando,\n",
      "lÃ¡cteos enteros fermentados. incluye una recarga.\n",
      "09 Eleva la actividad fÃ­sica. El ejerciÂ­\n",
      "cio magnifica el efecto de la dieta.\n",
      "NutriciÃ³n El Manual Revolucionario 12\n",
      "Ejemplos de menÃºs\n",
      "para perder peso\n",
      "DÃ­a 1 DÃ­a 2 DÃ­a 3\n",
      "desa Revuelto de dos Yogur griego con Dos huevos fritos\n",
      "â€”yuno huevos con verdura frutos rojos y nue c es con jamÃ³n\n",
      "â€” â€” â€”\n",
      "CafÃ© / TÃ© con un CafÃ© / TÃ© con un CafÃ© / TÃ© con un\n",
      "chorrito de leche chorrito de leche chorrito de leche\n",
      "â€” â€”\n",
      "Una manzana y Una naranja y\n",
      "6 nueces * 6 avellanas *\n",
      "comida Filete con ensalada y Pechuga de pollo a la Pescado a la plancha\n",
      "media patata cocida plancha con tomate, con ensalada y un\n",
      "â€” pimientos asados y poco de arroz\n",
      "Dos onzas de aguacate â€”\n",
      "chocolate oscuro â€” Un yogur con\n",
      ">80% Una pera y almendras fileteadas\n",
      "6 almendras *\n",
      "cena Ensalada de Ensalada verde con Crema de espinacas\n",
      "espinacas, requesÃ³n atÃºn de lata â€”\n",
      "y salmÃ³n ahumado â€” Un puÃ±ado de frutos\n",
      "â€” Dos onzas de secos\n",
      "Una fruta ** chocolate oscuro\n",
      ">80%\n",
      "* Puedes comer otra fruta que te guste mÃ¡s, lo mismo con los frutos secos.\n",
      "** De vez en cuando puedes reemplazar la fruta o el chocolate oscuro por\n",
      "otro postre, como Pan de plÃ¡tano.\n",
      "NutriciÃ³n El Manual Revolucionario 13\n",
      "Â¿Necesitas un\n",
      "plan de choque?\n",
      "Soy mÃ¡s partidario de los cambios\n",
      "lentos, adoptando gradualmente\n",
      "nuevos hÃ¡bitos de alimentaciÃ³n que\n",
      "puedas mantener a lo largo del tiemÂ­\n",
      "po. Este es precisamente el enfoque\n",
      "de El Plan Revolucionario.\n",
      "Sin embargo, en ciertos casos tiene\n",
      "sentido usar un enfoque mÃ¡s drÃ¡stiÂ­\n",
      "co. AdemÃ¡s, la rÃ¡pida pÃ©rdida de\n",
      "grasa inicial aumenta la motivaciÃ³n,\n",
      "mejorando la adherencia posterior.\n",
      "Para estos casos propongo realizar\n",
      "un ciclo corto de dieta cetogÃ©nica,\n",
      "que ademÃ¡s de potenciar la pÃ©rdida\n",
      "de grasa aporta distintos benefiÂ­\n",
      "cios para la salud. Si te interesa este\n",
      "tema, echa un vistazo al programa\n",
      "De Cero a Ceto.\n",
      "NutriciÃ³n El Manual Revolucionario 14\n",
      "Principios para ganar volumen.\n",
      "Si te interesa ganar volumen o eres un\n",
      "deportista con alto gasto energÃ©tico,\n",
      "tendrÃ¡s sin duda que comer mÃ¡s. Algu-\n",
      "nas recomendaciones para este caso:\n",
      "01 Incluye una buena porciÃ³n de 06 Seguramente deberÃ¡s comer mÃ¡s\n",
      "proteÃ­na en cada comida. de tres veces al dÃ­a, aÃ±adiendo por\n",
      "ejemplo un par de snacks. Igualmente\n",
      "02 Aumenta las grasas saludables. recomiendo realizar algÃºn ayuno inÂ­\n",
      "AÃ±ade por ejemplo mÃ¡s aceite de oliÂ­ termitente cada cierto tiempo.\n",
      "va y aguacate a las ensaladas. Come\n",
      "mÃ¡s frutos sec os, huevos, crema de 07 Para asegurar que la mayorÃ­a de\n",
      "almendras etc. calorÃ­as adicionales se usan para\n",
      "ganar mÃºsculo debes asegurar que\n",
      "03 Incorpora al menos un par de por- entrenas fuerza, al menos dos o tres\n",
      "ciones generosas de almidÃ³n al dÃ­a: veces a la semana.\n",
      "tubÃ©rculos, legumbres o cereales.\n",
      "04 Eleva el consumo de frutas, al\n",
      "menos 3Â­4 al dÃ­a. AdemÃ¡s, despuÃ©s\n",
      "de entrenar la fruta puede ayudar a\n",
      "recargar glucÃ³geno hepÃ¡tico.\n",
      "05 Incluye lÃ¡cteos enteros con fre-\n",
      "cuencia. Si no los toleras bien puedes\n",
      "usar bebidas vegetales.\n",
      "NutriciÃ³n El Manual Revolucionario 15\n",
      "Ejemplos de menÃºs\n",
      "para ganar volumen\n",
      "DÃ­a 1 DÃ­a 2 DÃ­a 3\n",
      "Revuelto de 3Â­4 Avena cocida con Guiso de lentejas\n",
      "desa huevos con verdura, miel, nueces y frutos â€”\n",
      "â€”yuno jamÃ³n y queso rojos CafÃ© / TÃ© con leche\n",
      "â€” â€” â€”\n",
      "CafÃ© / TÃ© con leche CafÃ© / TÃ© con leche Una fruta y un puÃ±aÂ­\n",
      "â€” â€” do de frutos secos\n",
      "Dos frutas y un puÃ±aÂ­ Tres onzas de chocoÂ­\n",
      "do de frutos secos late oscuro >80%\n",
      "Filete con ensalada y Pechuga de pollo a la Pescado a la plancha\n",
      "comida dos patatas cocidas o plancha, acompaÃ±aÂ­ con ensalada y una\n",
      "al horno da de plÃ¡tano macho taza de arroz\n",
      "â€” horneado con miel y â€”\n",
      "Pan de plÃ¡tano con canela Un yogur con\n",
      "chispas de chocolate â€” plÃ¡tano y almendras\n",
      "y nueces Yogur griego con fileteadas\n",
      "frutos rojos y nueces\n",
      "cena Ensalada Griega con Ensalada de garbanÂ­ Crema de ajo puerro\n",
      "salmÃ³n ahumado zos y atÃºn de lata, y patatas\n",
      "â€” con medio aguacate â€”\n",
      "Una fruta â€” Una fruta\n",
      "â€” Una fruta â€”\n",
      "Pan de plÃ¡tano con Tres onzas de chocoÂ­\n",
      "chispas de chocolate late oscuro >80%\n",
      "y nueces\n",
      "snack / Selecciona dos al dÃ­a: Selecciona dos al dÃ­a: Selecciona dos al dÃ­a:\n",
      "postre Queso / Fruta / Queso / Fruta / Queso / Fruta /\n",
      "adicional Yogur / PuÃ±ado de Yogur / PuÃ±ado de Yogur / PuÃ±ado de\n",
      "frutos secos / frutos secos / frutos secos /\n",
      "Chocolate negro Chocolate negro Chocolate negro\n",
      "NutriciÃ³n El Manual Revolucionario 16\n",
      "En muchos casos, tendrÃ¡s que comer\n",
      "mÃ¡s de lo que te pide el cuerpo. Si\n",
      "comiendo hasta la saciedad no subes\n",
      "de peso, tendrÃ¡s que ir mÃ¡s allÃ¡. Una\n",
      "buena opciÃ³n para ingerir mÃ¡s caloÂ­\n",
      "rÃ­as saludables con poco esfuerzo es\n",
      "un batido de proteÃ­na. Por ejemplo\n",
      "el siguiente batido es uno de mis faÂ­\n",
      "voritos, y tiene mÃ¡s de 600 calorÃ­as.\n",
      "Batido de proteÃ­na,\n",
      "plÃ¡tano y frutos\n",
      "del bosque\n",
      "Â· Un scoop (25-30g) de proteÃ­na\n",
      "de suero. Ver marcas.\n",
      "Â· Un vaso de leche entera.\n",
      "Â· Un yogur o 125g de kÃ©fir.\n",
      "Â· Dos plÃ¡tanos.\n",
      "Â· Un puÃ±ado de fresas o frutos\n",
      "rojos congelados.\n",
      "Â· Una cucharada de crema de\n",
      "almendra o cacahuete.\n",
      "Â· Canela.\n",
      "Entrenamiento El Manual Revolucionario 17\n",
      "ENTRENAMIENTO\n",
      "Conceptos de entrenamiento. Para\n",
      "nuestros ancestros, el movimiento era\n",
      "obligatorio, y la comida era la recom-\n",
      "pensa por el esfuerzo.\n",
      "AdemÃ¡s, el ejercicio no es solo una Nuestro cuerpo se beneficia de inÂ­\n",
      "forma de quemar calorÃ­as. Nuestra corporar multitud de actividades, y\n",
      "biologÃ­a estÃ¡ diseÃ±ada para realizar la siguiente pirÃ¡mide intenta reflejar\n",
      "actividad fÃ­sica, y su ausencia nos la importancia relativa de cada una\n",
      "debilita. Lo que no usas lo pierdes. de ellas.\n",
      "â€”\n",
      "MÃ¡xima\n",
      "intensidad\n",
      "â€”\n",
      "Intensidad\n",
      "media\n",
      "â€”\n",
      "Baja\n",
      "intensidad\n",
      "Entrenamiento El Manual Revolucionario 18\n",
      "En la base estÃ¡n las actividades de mejor forma de replicar este comporÂ­\n",
      "baja intensidad, que podrÃ­amos reÂ­ tamiento es con la llamada calisteÂ­\n",
      "sumir como â€˜muÃ©vete mÃ¡sâ€™. En generÂ­ nia, basada en ejercicios corporales.\n",
      "al, la mejor actividad es simplemente Es precisamente lo que detallo en el\n",
      "caminar, intentando llegar a los programa Desencadenado.\n",
      "8.000â€”10.000 pasos diarios. Multitud\n",
      "de estudios confirman que las persoÂ­ AdemÃ¡s, nuestros ancestros debÃ­an\n",
      "nas que caminan mÃ¡s, viven mÃ¡s. cargar objetos pesados y realizar\n",
      "esfuerzos mÃ¡ximos, esprintando\n",
      "Caminar es por tanto muy imporÂ­ por ejemplo de vez en cuando. Estas\n",
      "tante, pero no es suficiente. Debes son las actividades que situamos en\n",
      "trabajar todo tu cuerpo e incluir la punta de la pirÃ¡mide. Generan un\n",
      "movimientos mÃ¡s complejos. Por eso estÃ­mulo especial que fortalecen en\n",
      "incorporamos en el siguiente nivel mayor medida nuestro cuerpo. Como\n",
      "actividades de mÃ¡s intensidad, como siempre, debes empezar poco a poco\n",
      "correr de vez en cuando y, sobre todo, y aumentar la intensidad de maneÂ­\n",
      "entrenar fuerza usando nuestro ra gradual, pero te sorprenderÃ¡s de\n",
      "propio cuerpo. Nuestros ancestros los cambios que ves en tu cuerpo en\n",
      "tenÃ­an que escalar y pelear, moviendo poco tiempo.\n",
      "su cuerpo por entornos diversos. La\n",
      "Entrenamientos\n",
      "Se basan en el concepto de circuitos,\n",
      "bÃ¡sicos con el cuerpo\n",
      "donde debes realizar varias rondas\n",
      "de ciertos ejercicios. Tras finalizar\n",
      "Recomiendo empezar por el entreÂ­ las repeticiones indicadas de cada\n",
      "namiento con el propio cuerpo. No ejercicio, pasas al siguiente, sin desÂ­\n",
      "solo por su efectividad, sino tambiÃ©n canso. Descansa un par de minutos\n",
      "por su simplicidad. No necesitas entre rondas.\n",
      "equipamiento, lo puedes realizar en\n",
      "cualquier lugar y en poco tiempo.\n",
      "No importan tanto las sesiones inÂ­\n",
      "dividuales que haces como el proÂ­\n",
      "grama global que sigues, pero te\n",
      "muestro dos sesiones de ejemplo\n",
      "para distintos niveles.\n",
      "Entrenamiento El Manual Revolucionario 19\n",
      "NIVEL BÃSICO\n",
      "3 Rondas Notas\n",
      "20 sentadillas Â· En la sentadilla, baja todo lo que pueÂ­\n",
      "das, sin llegar a despegar los talones\n",
      "10 flexiones del suelo. Si lo necesitas, agÃ¡ rrate de\n",
      "una mesa.\n",
      "20 desplantes â€” 10 con cada pierna Â· Si no puedes hacer flexiones sobre el\n",
      "suelo, apoya las manos en una mesa.\n",
      "30 segundos de plancha Â· En los desplantes, intenta que ambas\n",
      "rodillas formen un Ã¡ngulo recto al\n",
      "30 segundos corriendo en el sitio final del movimiento.\n",
      "â€” o saltando comba Â· En la plancha, asegÃºrate de contraer\n",
      "al mÃ¡ximo los abdominales, evitando\n",
      "que descienda tu cadera.\n",
      "Si te resulta muy duro, haz solo dos rondas o des- â€”\n",
      "cansa mÃ¡s entre cada ronda. Si te resulta fÃ¡cil, Lee este artÃ­culo para tener mÃ¡s detalle\n",
      "aÃ±ade una ronda adicional y reduce los descansos. sobre cÃ³mo entrenar en casa.\n",
      "NIVEL INTERMEDIO\n",
      "4 Rondas Notas\n",
      "8 dominadas Â· Para hacer dominadas necesitarÃ¡s\n",
      "una barra, como Ã©sta, si entrenas en\n",
      "15 flexiones casa. Si te resulta muy difÃ­cil, coloca\n",
      "una silla bajo la barra y ayÃºdate apoÂ­\n",
      "30 sentadillas yando un pie.\n",
      "Â· Las planchas laterales trabajan esÂ­\n",
      "40 escaladores de montaÃ±a pecialmente los oblicuos, y para\n",
      "realizarlas debes apoyarte sobre el\n",
      "30 segundos de plancha lateral antebrazo con el cuerpo perpendicuÂ­\n",
      "â€” por cada lado lar al suelo. Cambia de lado tras los\n",
      "treinta segundos, antes de pasar al\n",
      "45 segundos corriendo en el sitio siguiente ejercicio.\n",
      "â€” o saltando comba\n",
      "Otros Aspectos El Manual Revolucionario 20\n",
      "OTROS ASPECTOS\n",
      "Ve mÃ¡s allÃ¡. Nos hemos centrado\n",
      "en conceptos bÃ¡sicos de nutriciÃ³n y\n",
      "entrenamiento, pero tu salud depende\n",
      "de otros muchos aspectos.\n",
      "â€”\n",
      "Pincha en cualquiera de\n",
      "los iconos siguientes para\n",
      "obtener mÃ¡s informaciÃ³n\n",
      "PÃ©rdida Ganancia SueÃ±o y GuÃ­a de\n",
      "sobre el tema que te\n",
      "de Grasa Muscular Descanso Suplementos\n",
      "interese.\n",
      "Salud Fortaleza En Vuelta a la\n",
      "Intestinal Mental Femenino Naturaleza\n",
      "Ãšnete a nuestra tribu\n",
      "Puedes mejorar tu salud por tu cuenÂ­\n",
      "ta, pero es mÃ¡s fÃ¡cil si cuentas con\n",
      "â€”\n",
      "apoyo. Las grandes cosas se conÂ­\n",
      "Nunca dudes que un\n",
      "siguen casi siempre con otros. Los\n",
      "pequeÃ±o grupo de\n",
      "programas que ofrecemos son un\n",
      "personas inteligentes y\n",
      "buen comienzo. Cada uno de ellos\n",
      "comprometidas pueden\n",
      "tiene su comunidad privada con\n",
      "cambiar el mundo. De\n",
      "miles de seguidores, que te ofrecerÃ¡n\n",
      "hecho, es lo Ãºnico capaz\n",
      "su experiencia y su ayuda. Esperamos\n",
      "de cambiarlo.\n",
      "verte allÃ­.\n",
      "â€”\n",
      "Margaret Mead Nos puedes seguir tambiÃ©n en\n",
      "Instagram, Facebook, YouTube\n",
      "y Twitter.\n",
      "Recetas El Manual Revolucionario 21\n",
      "RECETAS\n",
      "Ensalada Verde\n",
      "01\n",
      "Porciones: 1\n",
      "Ingredientes Equipo y utensilios\n",
      "Â· 20g de lechuga, 15g de rÃºcula Â· Bol grande\n",
      "Â· 20g de espinacas Â· Tenedor o pinza de cocina\n",
      "Â· 15g de kale\n",
      "Â· 15ml de aceite de oliva (1 cuch.) PreparaciÃ³n\n",
      "Â· 5ml de vinagre (opcional) Â· Lavar y cortar las hojas de lechuga,\n",
      "Â· Sal espinaca y kale (salvo que compres\n",
      "bolsas listas para servir).\n",
      "ElaboraciÃ³n Observaciones\n",
      "Â· Mezclar en un bol todas las verduras Â· Si no se va a consumir la ensala-\n",
      "verdes. Agregar el aceite de oliva, el da inmediatamente se recomienda\n",
      "vinagre y la sal. Remover todo con no ade rezarla. Se sugiere preparar\n",
      "un tenedor o pinzas. el ade rezo aparte, considerando 1\n",
      "Â· Servir. porciÃ³n de vinagre por 3 de aceite\n",
      "de oliva.\n",
      "Variantes\n",
      "1 Agregar otros tipos de verduras,\n",
      "como endivias, canÃ³nigos, berros,\n",
      "escarola, etc.\n",
      "2 Cambiar el aderezo o agregar frutos\n",
      "secos.\n",
      "Recetas El Manual Revolucionario 22\n",
      "Ensalada Griega\n",
      "02\n",
      "Porciones: 1\n",
      "Ingredientes Equipo y utensilios\n",
      "Â· 150g de tomate (uno mediano) Â· Bol pequeÃ±o\n",
      "Â· 200g de pepino (1/2 pepino) Â· Bol mediano\n",
      "Â· 25g de cebolla morada (1/4 de Â· Tenedor o pinzas\n",
      "cebolla)\n",
      "Â· 100g de pimiento verde PreparaciÃ³n\n",
      "Â· 10 aceitunas negras Â· Cortar el tomate en octavos\n",
      "Â· 30-50g de queso feta Â· Cortar el pepino en cuadros,\n",
      "Â· 1g de orÃ©gano tamaÃ±o bocado\n",
      "Â· 15ml de aceite de oliva Â· Cortar el pimiento verde en trozos\n",
      "Â· 5ml de vinagre de vino tamaÃ±o bocado\n",
      "Â· Sal y pimienta al gusto Â· Cortar finamente la cebolla\n",
      "Â· 10g de nueces (o piÃ±ones) Â· Cortar o deshacer a mano el queso\n",
      "ElaboraciÃ³n Variantes\n",
      "1 Mezclar en el bol pequeÃ±o el aceite de Â· Utilizar la variedad de tomate o acei-\n",
      "oliva, el vinagre, la sal y el orÃ©gano. tunas que prefieras. Se puede uti-\n",
      "2 Mezclar en el bol mediano el pepino, lizar otros tipos de queso, por ejem-\n",
      "la cebolla y las aceitunas. Agregar el plo, queso azul.\n",
      "aderezo y remover bien con un tene-\n",
      "dor o con pinzas.\n",
      "3 Agregar el tomate y el queso.\n",
      "4 Esparcir por encima las nueces, el\n",
      "orÃ©gano y la pimienta.\n",
      "Recetas El Manual Revolucionario 23\n",
      "Guiso de lentejas\n",
      "03\n",
      "Porciones: 2\n",
      "Ingredientes Equipo y utensilios\n",
      "Â· 200g de lentejas crudas Â· Bol\n",
      "Â· 750ml de agua Â· Olla con tapa (mediana-grande)\n",
      "Â· 2 dientes de ajo (10g) Â· SartÃ©n antiadherente\n",
      "Â· 1 hoja de laurel\n",
      "Â· 15ml de aceite de oliva PreparaciÃ³n\n",
      "Â· 200g de cebolla blanca Â· Dejar en remojo las lentejas en agua\n",
      "Â· 0.3g de comino en polvo (opcional) tibia durante varias horas y escurrir\n",
      "Â· 0.5g de pimentÃ³n dulce (opcional) Â· Lavar las lentejas en agua corriente\n",
      "Â· 100g de espinacas frescas (o kale) Â· Pelar y machacar los dientes de ajo\n",
      "Â· Sal al gusto Â· Cortar finamente la cebolla\n",
      "Â· Cortar las hojas de espinacas\n",
      "ElaboraciÃ³n\n",
      "1 Colocar las lentejas previamente remoja- tos mÃ¡s. Ajustar la sal y la cantidad de\n",
      "das y escurridas en una olla. Cubrir con el lÃ­quido al gusto.\n",
      "agua, agregar el ajo machacado, el comino, 7 Servir calientes o tibias con un chorrito de\n",
      "la hoja de laurel y un poco de sal. aceite de oliva.\n",
      "2 Llevar a hervor y luego ajustar la temperatura\n",
      "hasta que solamente burbujee ligeramente. Variantes\n",
      "3 Tapar la olla y cocinar, moviendo las lente- Â· Se puede aÃ±adir al sofrito otras verduras u\n",
      "jas ocasionalmente. AÃ±adir mÃ¡s agua si es otras especias (estragÃ³n y una cucharada\n",
      "necesario para que las lentejas permanez- de mostaza). TambiÃ©n se puede agregar\n",
      "can cubiertas. Cocinar entre 25 y 35 minu- proteÃ­na como almejas o jamÃ³n.\n",
      "tos (ver observaciones). Â· Utilizar, para finalizar, hierbas frescas\n",
      "4 Probar las lentejas y verificar que hayan como perejil, cilantro o cebollino.\n",
      "perdido su dureza pero que no estÃ©n muy Â· Se puede escurrir toda el agua en el paso 4,\n",
      "blandas para que no se deshagan. Bajar el esperar que enfrÃ­en y aÃ±adir a ensaladas.\n",
      "fuego al mÃ­nimo, sacar la hoja de laurel y el\n",
      "ajo y tapar nuevamente. Observaciones\n",
      "5 Calentar la sartÃ©n a fuego medio con el aceite Â· Cuidar la cocciÃ³n de las lentejas y confiar\n",
      "de oliva. SofreÃ­r la cebolla de 1 a 2 minutos, mÃ¡s en el tacto de la boca que en el ti-\n",
      "agregar el pimentÃ³n en polvo y remover. empo propuesto de cocciÃ³n, ya que este\n",
      "6Agregar el sofrito a las lentejas y remover. tiempo varÃ­a en funciÃ³n del tipo de lenteja\n",
      "AÃ±adir las hojas de espinacas. Subir la y la intensidad del fuego.\n",
      "temperatura y cocinar tapado por 10 minu-\n",
      "Recetas El Manual Revolucionario 24\n",
      "Crema de espinacas\n",
      "04\n",
      "Porciones: 2\n",
      "Ingredientes Equipo y utensilios\n",
      "Â· 400g de espinacas Â· Olla con tapa (mediana o grande)\n",
      "Â· 200g de calabacÃ­n (uno mediano) Â· Licuadora\n",
      "Â· 20g de mantequilla sin sal\n",
      "Â· 50g de cebolla blanca PreparaciÃ³n\n",
      "Â· 2 dientes de ajo Â· Cortar la espinaca en trozos\n",
      "Â· 350ml de caldo de pollo Â· Cortar el calabacÃ­n en trozos\n",
      "(o simplemente agua) Â· Cortar finamente la cebolla\n",
      "Â· 40ml de nata lÃ­quida Sal y pimienta Â· Cortar finamente el ajo\n",
      "al gusto\n",
      "ElaboraciÃ³n\n",
      "1 Colocar una olla grande a fuego medio y 6Retirar del fuego (si se va a usar nata lÃ­qui-\n",
      "derretir la mantequilla. da se aÃ±ade templada y en este momento).\n",
      "2 Agregar la cebolla y el ajo. Cocinar movien- 7 Servir.\n",
      "do regularmente hasta que los vegetales\n",
      "estÃ©n blandos y translÃºcidos. Agregar el Variantes\n",
      "calabacÃ­n y las espinacas. Saltear todo Â· Se puede sustituir la nata lÃ­quida por un\n",
      "junto por un minuto. poco de leche y mantequilla.\n",
      "3 AÃ±adir el caldo de pollo (o simplemente Â· Se pueden aÃ±adir otras verduras verdes\n",
      "agua). Llevar todo a hervor, luego bajar la como espÃ¡rragos y brÃ³coli para dar mÃ¡s\n",
      "temperatura del fuego hasta que el lÃ­quido consistencia.\n",
      "quede burbujeando ligeramente. Tapar y coci-\n",
      "nar por 10 minutos a fuego lento o hasta que Observaciones\n",
      "el calabacÃ­n y las espinacas estÃ©n blandos. Â· Por seguridad, evitar licuar mientras el\n",
      "4 Apagar el fuego y dejar enfriar un poco. caldo estÃ© muy caliente y no llenar el vaso\n",
      "Pasar todo a la licuadora. Licuar (ver ob- de la licuadora mÃ¡s de la mitad.\n",
      "servaciones). Â· El caldo de pollo puede ser hecho en casa\n",
      "5 Regresar la crema a la olla. Probar y ajus- o comprado. TambiÃ©n se puede reemplazar\n",
      "tar la sal. Si la crema quedÃ³ muy lÃ­quida por caldo de verduras.\n",
      "dejar hervir unos minutos y si estÃ¡ muy\n",
      "espesa agregar mÃ¡s caldo de pollo o agua\n",
      "hasta lograr la consistencia deseada.\n",
      "Recetas El Manual Revolucionario 25\n",
      "Crema de ajo puerro y patatas\n",
      "05\n",
      "Porciones: 2\n",
      "Ingredientes Equipo y utensilios\n",
      "Â· 600g de ajo puerro (2 medianos) Â· Olla con tapa\n",
      "Â· 400g de patatas Â· Licuadora\n",
      "Â· 20g de mantequilla sin sal\n",
      "Â· 50g de cebolla blanca PreparaciÃ³n\n",
      "Â· 1 diente de ajo (5g) Â· Cortar el ajo puerro en ruedas finas,\n",
      "Â· 750ml de caldo de pollo (o agua) descartando la parte verde\n",
      "Â· 1 hoja de laurel Â· Pelar y cortar las patatas en trozos\n",
      "Â· Sal y pimienta al gusto pequeÃ±os de similar tamaÃ±o\n",
      "Â· 100ml de crema de leche (opcional) Â· Cortar finamente la cebolla\n",
      "Â· 5g de perejil Â· Cortar finamente el ajo\n",
      "Â· Cortar finamente el perejil\n",
      "Â· Cortar finamente el ajo\n",
      "ElaboraciÃ³n\n",
      "1 Colocar una olla grande a fuego medio y 6Retirar del fuego, y mezclar la crema de\n",
      "derretir la mantequilla. leche templada (no frÃ­a).\n",
      "2 Agregar el ajo puerro, la cebolla y el ajo. 7 Servir y agregar por encima el perejil.\n",
      "Cocinar moviendo regularmente hasta que\n",
      "los vegetales estÃ©n blandos y translÃºcidos. Variantes\n",
      "3 Agregar las patatas, el laurel, el caldo de Â· Sustituir la crema de leche por un poco de\n",
      "pollo (o agua) y ajustar la sal. Llevar todo leche y mantequilla.\n",
      "a hervor, luego bajar la temperatura del Â· Se puede consumir como una sopa de ver-\n",
      "fuego hasta que quede burbujeando ligera- duras sin licuar.\n",
      "mente y tapar. Cocinar al menos 20 minu- Â· Utilizar otras hierbas frescas como cebollÃ­n\n",
      "tos o hasta que las patatas estÃ©n blandas. o albahaca.\n",
      "4 Apagar el fuego, dejar enfriar y sacar la hoja\n",
      "de laurel. Pasar todo a la licuadora y licuar. AcompaÃ±ar\n",
      "5 Regresar la crema a la olla. Probar y ajus- Â· Se puede servir con queso rallado o almen-\n",
      "tar la sal. Si la crema quedÃ³ muy lÃ­quida dras tostadas y cortadas.\n",
      "dejar hervir unos minutos y si estÃ¡ muy\n",
      "espesa agregar agua hasta lograr la consis-\n",
      "tencia deseada.\n",
      "Recetas El Manual Revolucionario 26\n",
      "Avena cocida con miel,\n",
      "06\n",
      "nueces y frutos rojos\n",
      "Porciones: 2\n",
      "Ingredientes Equipo y utensilios\n",
      "Â· 100g de avena en hojuelas Â· Bol o recipiente\n",
      "Â· 250ml de agua Â· Olla (pequeÃ±a o mediana)\n",
      "Â· 400ml de leche (o agua) Â· Cuchara o paleta\n",
      "Â· 60g de miel\n",
      "Â· 10ml de esencia de vainilla (opcional) PreparaciÃ³n\n",
      "Â· 1 ramita de canela o 2g en polvo Â· Dejar en remojo la avena la noche\n",
      "Â· 25g-30g de nueces picadas antes (opcional)\n",
      "Â· 120g de arÃ¡ndanos, frambuesas o Â· Cortar las nueces en trozos\n",
      "fresas Â· Cortar las fresas (si se usan)\n",
      "Â· Pizca de sal Â· Cortar finamente el ajo\n",
      "ElaboraciÃ³n Variantes\n",
      "1 Colocar la avena y el agua en un re- Â· Cambiar la leche por leche de coco,\n",
      "cipiente. Si es posible, dejar la avena almendras o simplemente agua.\n",
      "en remojo entre 7 y 12 horas en la Â· Utilizar variedad de frutos secos\n",
      "nevera. Escurrir antes de cocinar. como avellanas, almendras, coco\n",
      "2 Colocar en una olla a fuego medio- rallado, etc. Otras frutas como higos\n",
      "bajo la avena, la leche, la miel, la o plÃ¡tanos.\n",
      "canela y la pizca de sal. Â· Agregar cacao en polvo o cuadritos\n",
      "3 Remover con una paleta hasta di- de chocolate oscuro.\n",
      "solver la miel. Cocinar hasta que\n",
      "muestre un primer hervor y espese\n",
      "un poco.\n",
      "4 Agregar las gotas de vainilla. Re-\n",
      "mover bien y probar para ajustar el\n",
      "dulzor al gusto. Retirar del fuego.\n",
      "5 Servir en un bol o plato hondo y\n",
      "agregar por encima las nueces pica-\n",
      "das y los frutos rojos.\n",
      "Recetas El Manual Revolucionario 27\n",
      "PlÃ¡tano macho horneado\n",
      "07\n",
      "con miel y canela\n",
      "Porciones: 2\n",
      "Ingredientes Equipo y utensilios\n",
      "Â· 1 plÃ¡tano macho maduro Â· Bol pequeÃ±o\n",
      "Â· 5g de mantequilla Â· Bandeja para hornear\n",
      "Â· 2g de canela Â· Papel para hornear\n",
      "Â· 10g de miel (opcional) Â· Brocha de cocina (opcional)\n",
      "PreparaciÃ³n\n",
      "Â· Pelar el plÃ¡tano\n",
      "ElaboraciÃ³n Variantes\n",
      "1 Precalentar el horno a 200Â°C y Â· Omitir la miel si el plÃ¡tano estÃ¡ su-\n",
      "preparar la bandeja de horno (si no ficientemente maduro. TambiÃ©n se\n",
      "es antiadherente se sugiere colocar puede hornear cortado en ruedas.\n",
      "papel para hornear).\n",
      "2 Derretir en un bol la mantequilla e Observaciones\n",
      "inmediatamente agregar la miel y la Â· El plÃ¡tano macho estÃ¡ maduro\n",
      "canela. Mezclar todo bien. cuando la piel estÃ¡ muy amarrilla y\n",
      "3 Colocar el plÃ¡tano en la bandeja cubierta de manchas negras\n",
      "para hornear y con una brocha de\n",
      "cocina o con la mano untarlo con la\n",
      "mantequilla, la miel y la canela.\n",
      "4 Hornear por 30 minutos o hasta que\n",
      "el plÃ¡tano este suave y dorado.\n",
      "Recetas El Manual Revolucionario 28\n",
      "Pan de plÃ¡tano con chispas\n",
      "08\n",
      "de chocolate y nueces\n",
      "Porciones: 2\n",
      "Ingredientes Â· 30g de miel (tambiÃ©n se puede\n",
      "Â· 2 plÃ¡tanos maduros usar stevia o eritritol)\n",
      "Â· 2 huevos\n",
      "Â· 30g de mantequilla sin sal EÂ· quipo y utensilios\n",
      "Â· 20ml de aceite de coco Â· Molde antiadherente para pastel\n",
      "(1 Â½ cucharada sopera) (de aluminio, silicÃ³n o Pirex)\n",
      "Â· 10ml de yogur natural sin azÃºcar Â· Bol pequeÃ±o\n",
      "(opcional) Â· Licuadora\n",
      "Â· 35g de harina de coco\n",
      "Â· 2g de canela PreparaciÃ³n\n",
      "Â· 1g de bicarbonato de sodio Â· Derretir el aceite de coco y la\n",
      "Â· 1g de polvo de hornear (royal) mantequilla en el microondas\n",
      "Â· 5ml de esencia de vainilla Â· Cortar el plÃ¡tano en rodajas\n",
      "Â· 1g de sal Â· Cortar el chocolate en pedacitos\n",
      "Â· 60g de chocolate 85% - 90%. pequeÃ±os\n",
      "ElaboraciÃ³n\n",
      "1 Precalentar el horno a 200Â°C. 6Vaciar la mezcla en el molde y hornear por\n",
      "2 Preparar el molde. Colocar papel para hor- 20 minutos (ver observaciones).\n",
      "near en el fondo o engrasar el recipiente 7 Sacar del horno y dejar enfriar un poco\n",
      "con un poco de mantequilla y espolvorear antes de desmoldarla.\n",
      "un poquito de harina de coco.\n",
      "3 Licuar los plÃ¡tanos, los huevos, la mante- Variantes\n",
      "quilla, el aceite de coco, el yogur, el ex- Â· Utilizar otros frutos secos como avellanas,\n",
      "tracto de vainilla y la miel. almendras, etc.\n",
      "4 Mezclar en el bol la harina de coco, la\n",
      "canela, el bicarbonato, el polvo de hornear AcompaÃ±ar\n",
      "y la sal. Agregar a la licuadora y procesar Â· Con cafÃ© o tÃ© para el desayuno o como postre.\n",
      "nuevamente hasta que todos los ingredi-\n",
      "entes estÃ©n integrados. Observaciones\n",
      "5 Agregar el chocolate y las nueces. Remo- Â· Se puede verificar que el pan estÃ¡ listo si\n",
      "verlos con una cuchara en la mezcla (no al introducir un palillo de madera Ã©ste sale\n",
      "licuar nuevamente). limpio y sin restos de mezcla.\n",
      "El Manual Revolucionario 29\n",
      "TranscripciÃ³n de https://www.youtube.com/watch?v=L3Qf63iP4Yc guardada en transcript_L3Qf63iP4Yc.srt\n",
      "TranscripciÃ³n de https://www.youtube.com/watch?v=WT-wEIo9Ji8 guardada en transcript_WT-wEIo9Ji8.srt\n",
      "TranscripciÃ³n de https://www.youtube.com/watch?v=gaVQ0lFp_Po guardada en transcript_gaVQ0lFp_Po.srt\n",
      "TranscripciÃ³n de https://www.youtube.com/watch?v=dDaKhCTrMus guardada en transcript_dDaKhCTrMus.srt\n",
      "TranscripciÃ³n de https://www.youtube.com/watch?v=DPOLIiBcCbk guardada en transcript_DPOLIiBcCbk.srt\n"
     ]
    }
   ],
   "source": [
    "# ConfiguraciÃ³n de logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# 1ï¸âƒ£ CARGA DE DOCUMENTOS (PDF y YouTube)\n",
    "# ------------------------------------\n",
    "\n",
    "pdf_url = \"https://s3.amazonaws.com/fitnessrevolucionario.publico/Descargas/ElManualRevolucionario_MarcosVazquez.pdf\"\n",
    "\n",
    "# Cargar el PDF con pdfplumber\n",
    "def load_pdf(pdf_url):\n",
    "    try:\n",
    "        # Descargar el PDF (o leer si ya lo tienes en el sistema)\n",
    "        response = requests.get(pdf_url)\n",
    "        pdf_file = io.BytesIO(response.content)  # Usamos BytesIO para leer desde memoria\n",
    "        with pdfplumber.open(pdf_file) as pdf:\n",
    "            pdf_text = [page.extract_text() for page in pdf.pages]\n",
    "        return pdf_text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al cargar el PDF: {e}\")\n",
    "        return []\n",
    "\n",
    "pdf_pages = load_pdf(pdf_url)\n",
    "\n",
    "# Lista de URLs de YouTube\n",
    "youtube_urls = [\n",
    "    \"https://www.youtube.com/watch?v=L3Qf63iP4Yc\",\n",
    "    \"https://www.youtube.com/watch?v=WT-wEIo9Ji8\",\n",
    "    \"https://www.youtube.com/watch?v=gaVQ0lFp_Po\",\n",
    "    \"https://www.youtube.com/watch?v=dDaKhCTrMus\",\n",
    "    \"https://www.youtube.com/watch?v=DPOLIiBcCbk\"\n",
    "]\n",
    "\n",
    "# FunciÃ³n para guardar las transcripciones en formato .srt\n",
    "def save_to_srt(transcript, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for idx, entry in enumerate(transcript, 1):\n",
    "            start, duration, text = entry['start'], entry['duration'], entry['text']\n",
    "            start_min, start_sec = divmod(int(start), 60)\n",
    "            end_min, end_sec = divmod(int(start + duration), 60)\n",
    "            f.write(f\"{idx}\\n\")\n",
    "            f.write(f\"{start_min:02d}:{start_sec:02d} --> {end_min:02d}:{end_sec:02d}\\n\")\n",
    "            f.write(f\"{text}\\n\\n\")\n",
    "\n",
    "documents = [page for page in pdf_pages if page is not None]  # Eliminar pÃ¡ginas vacÃ­as\n",
    "\n",
    "# Procesar cada URL de YouTube\n",
    "for url in youtube_urls:\n",
    "    video_id = url.split('v=')[1]\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['es'])\n",
    "        transcript_filename = f\"transcript_{video_id}.srt\"\n",
    "        save_to_srt(transcript, transcript_filename)\n",
    "        documents.append(f\"TranscripciÃ³n de {url} guardada en {transcript_filename}\")\n",
    "    except (TranscriptsDisabled, NoTranscriptFound):\n",
    "        logging.warning(f\"No se encontrÃ³ transcripciÃ³n para {url}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al obtener transcripciÃ³n para {url}: {e}\")\n",
    "\n",
    "# Imprimir los documentos procesados\n",
    "for document in documents:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441,
     "referenced_widgets": [
      "72e7c491635f4e87943b2d1c98581f03",
      "1f39fe61cea141da89f117dd45d53ad4",
      "a04c82a7496042a3899a8fc276f3a4ab",
      "da3b765d7e364bc29db3de4ce3bd389a",
      "5e8b669962e24875915a839ce8d017b9",
      "1a2adefbc15640008a80b9c5439cf0f6",
      "f721ef8d935d4ffeb6270f9897131842",
      "34079ce761f643c983cb8f5c5caa4976",
      "9e23163c97c34a788765603ba5733bb9",
      "9051b37ca901451cbab7bb1909c84a08",
      "a190918cc7fe4e93949d982491a3f0e8",
      "cf273899041443ea89b2d87f7fe1f110",
      "377f35c1374541ef81a963d054357b35",
      "29aa0db535144647aedf81cb0792d95c",
      "d1789d4cfa7a47e9aca163d3146bf4a5",
      "22b3f3f420db4f68bbd635fddae4bfe1",
      "05e7de1f3783476a846d2b35d3431e1b",
      "0984299cf63246f5bbe8a94112d7c5e7",
      "97e3020ab40a48b88f9af9d911728461",
      "d925f42d15524e2f84fe371b462380f5",
      "014f9a3b1eb5492ea0a18dbb18cf9227",
      "02dd87d8d335426c9188e0555457e6cb",
      "afee96ce87d64a91b16c31df52ee8296",
      "dd7ee1f5d14f45e18d8bfc419ceb2483",
      "21db274101994c138f3a4e5490f69f4b",
      "05b953a8dcf04de78e7b5d59a74b7613",
      "d8f15f19b3b74971addbe5d74035f5b4",
      "34e020f9f9d24904b33d6b4acda3f90a",
      "b4931fd325a74d6e986f5a72c3b9a02d",
      "97bb415c99c1419a802c0ab22edca669",
      "3210dfc908be45209b0fc78b525d7f3d",
      "603adbffe2ab45f1988fab06e942d5fe",
      "680234a642b04638a2076465356ac344",
      "22eed9da8e1c4ab5991940be4e0f61da",
      "44f186d9717349f28d86a3f8c6f62e6c",
      "87f03986fc1f4f1db076783741d9c6a3",
      "30395fdfcd0c42dfb371560dfe1e1ffd",
      "4956e257669e42f1a2a13023c3b47b53",
      "bd3784d4514e41dfa447c542fbbcfc82",
      "fc49d605540845d197a68611fb650ed7",
      "01739f583c954d55b72d9cdab3271513",
      "ac9d830d7024448c82b44f655b287ec5",
      "87a8f0af6e9448eeae0572f9a2f470ef",
      "feeb57e65dcc4437afbf166a99b5e003",
      "4c44341650554294817e531a1329aedc",
      "99fcee2864fe4ef7ad0a58b5f4d880c3",
      "36b5604e86504c2287c1a76d82c76ef2",
      "31e6738accc54e2888b18e3eb0706737",
      "b2889d54fbd34fc48204db783d5f9d6a",
      "aafc1f8cad444ce9b7ec1522e907f0bf",
      "0098b732ca5c481689ef225a57d9e11f",
      "f856b6c522d546dd8d49e33bacd9f7d0",
      "6917f9dc78574353b24358df7a899625",
      "7601637ce2594e7a9204ba4c7e918650",
      "85417726891342e5b50e727e526879f7",
      "a2b5a61752c2431ab3a71645ae60c3ea",
      "1007f7d8179d4a4eaa1dd7c30e5c09bd",
      "8e73b6bf266842d1b354a438108f4cde",
      "5f3b9487f4a544899e5d0a1ff5ee8ded",
      "708e1f40594645589e3f7dc8c8485f26",
      "3c673e24ebc4416aa262c355f7fdca51",
      "6981e7e496654c8aa1dac71a2f3abe09",
      "222452a06c8b47d9a7fd2a58be7bbea1",
      "176c6fa6c97b4271b34829877b14dbe1",
      "33d1dfdaa0684c90b765b4d681a317cd",
      "e6e90e7bdeaa41d5a1ad1a0e2a44eb63",
      "e231650de1314e5394ce9d6ec83a0455",
      "a1a918dfdce447c1a586d8063ebe4ddc",
      "1b7ad22f884e43bdb7696d383185e924",
      "f730db29277544c2b29ac90771689ac9",
      "7b32e49901a64630ac8ce48d699ad71c",
      "1228debd04c24ea8861963d44da65fb5",
      "ead40e3341e04c44bf617a415308a672",
      "5bdde4adbe0446f69267b31ef1cf9125",
      "2ed4f460f0804632a2b688dce8761075",
      "ea08325fbf1a49ed8578a0716692062c",
      "049945de5bb84dddb576ab2129a0c566",
      "f37956b8904a4be2b01068cebca62f2e",
      "bdc37f45feb946c981fee30164e70a7a",
      "fcff680e3fe54d61a372e26b19775744",
      "f6ad2b3fc55b45298f27ea7916434960",
      "930e721a77e248d2a3e614c349d310fe",
      "668eb048dda84eb49126ee20a07c3aa6",
      "2b0775bd97614a50bdc8ddbb791ae673",
      "f140f4a4a43840f3b72edb61807f01c4",
      "af4c1f9d6287455ea49e41cb60dc6e31",
      "08d9c1f42f73497cbfabb8c6a421b654",
      "277d9385214745ae8101f318e2a58d72",
      "c743597e44c34cd7829c357b678e8443",
      "893f81c7c120460a8b6ced59c50497c7",
      "047e2e24c4124e79b99f4b296bae2834",
      "7cb6d6a1999a4f499e51bd50172b8d71",
      "43b5088a6750476a8fff208f52935386",
      "eee1279e4efe4298bb8835539aed235e",
      "c359b3c5405d492284d59c4c03fc98c5",
      "88a493419fd74238b04f05604ff35273",
      "79de5a1c252041e8a19c714506eb90c4",
      "4b9a236d3d054304a50175b2368ea8fa",
      "5e32c8f22c4f43f2a171de00c94554e3",
      "fc06e0ef024e489ea8f07d5c8d5ac516",
      "fb60b803a803490b95be79e81139d8ef",
      "b0b1b7cbfcbc4ff884bcb802e9dc96f0",
      "917d5990ad7a483eaeef456be0af9a71",
      "74d5ba477d9f486ca060acc5e6394bdb",
      "d0a44b0f9110453bbb4bacee48ffd004",
      "7e1866369b5845d29baf3f22278d5c60",
      "4d49b80e52ad4542a5ecd1c0e6befee2",
      "b09ecd68b3d54388a139a63ec68d37ec",
      "6b4fb67e13c14de6b135cd9f38009164",
      "b1eb877233564b4f8ade17750669295f"
     ]
    },
    "id": "-mCF1-cw94ow",
    "outputId": "cd84370f-6e49-4681-d50a-24b5e011e0a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e7c491635f4e87943b2d1c98581f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf273899041443ea89b2d87f7fe1f110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afee96ce87d64a91b16c31df52ee8296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22eed9da8e1c4ab5991940be4e0f61da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c44341650554294817e531a1329aedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b5a61752c2431ab3a71645ae60c3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e231650de1314e5394ce9d6ec83a0455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37956b8904a4be2b01068cebca62f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c743597e44c34cd7829c357b678e8443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc06e0ef024e489ea8f07d5c8d5ac516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2ï¸âƒ£ CREACIÃ“N DE EMBEDDINGS Y FAISS\n",
    "# ------------------------------------\n",
    "\n",
    "# Cargar el modelo preentrenado de SentenceTransformers\n",
    "embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Crear los embeddings a partir de los documentos\n",
    "document_embeddings = embedder.encode(documents, convert_to_numpy=True)\n",
    "\n",
    "# Crear un Ã­ndice FAISS\n",
    "index = faiss.IndexHNSWFlat(document_embeddings.shape[1], 32)\n",
    "index.add(document_embeddings)\n",
    "\n",
    "# Guardar los embeddings y el Ã­ndice FAISS\n",
    "with open(\"document_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(document_embeddings, f)\n",
    "faiss.write_index(index, \"faiss_index.faiss\")\n",
    "\n",
    "# Log para confirmar que se guardaron correctamente\n",
    "logging.info(\"Embeddings e Ã­ndice FAISS guardados correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vxVXejU6-DuI"
   },
   "outputs": [],
   "source": [
    "# 3ï¸âƒ£ FUNCIONES PARA RAG\n",
    "# ------------------------------------\n",
    "\n",
    "def retrieve_documents(query, top_k=3):\n",
    "    query_embedding = embedder.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    return [documents[i] for i in indices[0] if i < len(documents)]\n",
    "\n",
    "def answer_question_with_generation(question, context):\n",
    "    try:\n",
    "        inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            start, end = outputs.start_logits.argmax(), outputs.end_logits.argmax()\n",
    "            return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs.input_ids[0][start:end+1]))\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en la generaciÃ³n de respuesta: {e}\")\n",
    "        return \"No se pudo generar la respuesta.\"\n",
    "\n",
    "def answer_question_with_RAG(question, top_k=3):\n",
    "    try:\n",
    "        context = \" \".join(retrieve_documents(question, top_k))\n",
    "        return answer_question_with_generation(question, context)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en el proceso RAG: {e}\")\n",
    "        return \"Error en la generaciÃ³n de respuesta.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "9936155666154a1caf60fe5c10a72d87",
      "18d5e7ef64a64f038a7ae72737ceb466",
      "956510528a664169b82ca951e62ad43c",
      "fa1742fe37304b4f81711300382bd5f6",
      "bdeb4fac658a469faa6f404a745f98ce",
      "49ece187bd524ddba097dd48c6ec0bff",
      "10daaf643da04beaa6db1d2607bfed21",
      "7b7201a81c46486db1c01c7e897824b1",
      "163e5c7c99084f77bffe10955b612328",
      "fc7fe71a8acc4b83b53f655c6fc5780f",
      "cfd16484ab594c92a6f352bd50fe1cdf",
      "f88054cd611c46f1948b338704d77aa6",
      "ece95acc928340a99a508b3530949f1b",
      "6461be7b7999474bbca024298b05d252",
      "cab88015e5764e06a8acce9530301fd0",
      "f22155da3cf74ccebe5e2b9f891c9e9f",
      "2d6aad40d2a7421fb469a8a0e1eb5bff",
      "86e1df7ada8d44cf8ea9824d53b9da5e",
      "59662e3480b64eaeb6944d7f2ee1f195",
      "ef200643fc264ac58f2a639abcf21ea8",
      "9bf36baa9cc649ca82d4906a2b5ea6ba",
      "57d83a0341ac481ebb2857b8bd0eab7b",
      "07986d32744544a6ad78e28ab4f5a6cc",
      "594c6e05728e4e44adc0e56448d4d464",
      "4f48f8d824f74721b59aed3b33bca906",
      "cc7d68102f5647d3945de97e87c79a6f",
      "83df1838335e40a4beb75ba6ce3229c7",
      "32680badb2eb49469e2915512f0727f0",
      "e3d50cd2b5894d65a09b4627801069e0",
      "fd7a890232e142a1ae0e0d526767ecbc",
      "60f36bc3906e4b639f8ad9ca4870d184",
      "69939e22a2cc4718a2b56cfe2e92df89",
      "27720d7455d74fa98f0c98667bb831f0"
     ]
    },
    "id": "A5vNPNQC6gEM",
    "outputId": "9970ddb2-d61e-495d-a1e8-257d41b40a74"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9936155666154a1caf60fe5c10a72d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88054cd611c46f1948b338704d77aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07986d32744544a6ad78e28ab4f5a6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo RAG guardado y comprimido en: /content/chatbot_tribu_salud_rag.zip\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_f725f22f-f258-4aaa-8f99-bc2fceba51ee\", \"chatbot_tribu_salud_rag.zip\", 26015255)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4ï¸âƒ£ GUARDAR Y SUBIR MODELO A HUGGING FACE\n",
    "# ------------------------------------\n",
    "\n",
    "rag_model_dir = \"/content/chatbot_tribu_salud_rag\"\n",
    "os.makedirs(rag_model_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    model.save_pretrained(rag_model_dir)\n",
    "    tokenizer.save_pretrained(rag_model_dir)\n",
    "    logging.info(f\"Modelo RAG guardado en: {rag_model_dir}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error al guardar el modelo: {e}\")\n",
    "\n",
    "repo_name_rag = \"CasiAC/chatbot_tribu_salud_rag\"\n",
    "repo_dir_rag = \"/content/new_chatbot_tribu_salud_rag\"\n",
    "zip_filename = \"/content/chatbot_tribu_salud_rag.zip\"\n",
    "\n",
    "if not os.path.exists(rag_model_dir):\n",
    "    logging.error(f\"No se encontrÃ³ la carpeta {rag_model_dir}\")\n",
    "    raise FileNotFoundError(f\"No se encontrÃ³ la carpeta {rag_model_dir}\")\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "try:\n",
    "    api.create_repo(repo_name_rag, repo_type=\"model\", private=False, exist_ok=True)\n",
    "    if os.path.exists(repo_dir_rag):\n",
    "        shutil.rmtree(repo_dir_rag)\n",
    "    os.makedirs(repo_dir_rag, exist_ok=True)\n",
    "    shutil.copytree(rag_model_dir, repo_dir_rag, dirs_exist_ok=True)\n",
    "    api.upload_folder(folder_path=repo_dir_rag, repo_id=repo_name_rag, repo_type=\"model\", commit_message=\"Subida del modelo RAG\")\n",
    "    logging.info(f\"Modelo RAG subido correctamente a Hugging Face: https://huggingface.co/{repo_name_rag}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error al subir el modelo a Hugging Face: {e}\")\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, _, filenames in os.walk(rag_model_dir):\n",
    "        for file in filenames:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, rag_model_dir)\n",
    "            zipf.write(file_path, arcname)\n",
    "\n",
    "print(f\"âœ… Modelo RAG guardado y comprimido en: {zip_filename}\")\n",
    "files.download(zip_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482,
     "referenced_widgets": [
      "3d7c59282a78404a80c8360caf34d2b0",
      "d443e8464c1741d28a8d2fed4531e89f",
      "8dc882146b774190999804f40965ea49",
      "cdbf7eb65c7b4c9d8fcba519af53052c",
      "ae79998638924c458690dcef7a7a1810",
      "420d368c07aa453c946b9d00fbad2347",
      "36afdfac02e243a3beb1734cc3cb5399",
      "d400e53c621d4e7083e5dfa2186f3a7a",
      "03ef9d827ca84cfe95984aa9ddc0912d",
      "cf2003162d9c495089584cb05ef98128",
      "70c50c31d8a14ce8988c3ca4ec3ec308",
      "c0c043f4c2614b56b4e1c4696e5d4bd1",
      "2c875a1aaab9464391d395144438539a",
      "2b32a605af2444f798cf05ea3c721376",
      "abf5af89770040f5b4aa36f4cb1403fa",
      "d27400ee29274373a91e07b0c0f929ed",
      "04a92346da45454c9db23c09671340d2",
      "f3a1d5dc1b93495a8ccb9afddcf3dd97",
      "02d32cc9154b4b3cb4b7df5f5fa7e115",
      "b74e0c8e83dc48a4a423aa464c8d4348",
      "cadc830e42864457beb2efcc7f4ef7e4",
      "a1f80a5d88ff44209ca98d330f0b7f8b",
      "d2cfdb8bfb1e45d7a80f271d2d2a4849",
      "c7f6818217d6405ea05e49155e2beebf",
      "9e91e3d707c2493b9c5cbf66ccccbda4",
      "71a8a3eeef0c47f3a5d2faec1f4a795e",
      "15a0b7c3393a4868a23bc23809ddafc9",
      "3bfb5fc0eaa24650ae16fb92f092bf65",
      "44c012b05460441dbdb391e3f977fb1a",
      "95c75af647d04ec29df30a2d6445282b",
      "cf439588375f4ccb9aeec30d82e57a13",
      "e6840135fcf8427987b56bf3279b8bf0",
      "583e8cbfd4784c6299017a8d867040ae",
      "ac3ce102d05442868e206817078b5e90",
      "2074d9a269a447b2a88458ac98957e41",
      "a787e0f3353d480a8a39fbddf874c91f",
      "fc17491546d54696997a5b23c1fb6d8f",
      "859fbb674eeb4602b6216b51ff964f32",
      "1ce8f51b90804fef8c8cfe4be6a8e484",
      "dcd33c8edea94009b03b74b27036825c",
      "108b5b046bea4428be9ebe6bdf6914e7",
      "18b4f2b5c69947f4876be5e269c3fbe7",
      "6a50eb98c6914ac9aea0c3cf1c3402f9",
      "a2671f20842a4baf8954ad00d19e78ec",
      "b8e2476f8b734e9cb3716dd7c6920645",
      "9df38bb3db314c3fba1650750974d910",
      "91ee663c7dcf4aee9b9a66075ed91f69",
      "eaa0edff424f41f28a8d4ffafd1f31ca",
      "36af016d76014c5493546f334acf0d7f",
      "d1f3974f11ef4b839258b2ac98afcdea",
      "13b8290d240e4ea39a7c11928954103a",
      "cc2416a25136429e99b749c05a876345",
      "1fbc4e09ed044401858ed79f614040ea",
      "221aa40eccfd4b87a49935e2a59849f1",
      "96bed91051014527a23b3e4bff414829",
      "d23b1672d86046a0b6afcab59a4d46be",
      "239abdb13be94ae9b46a43d440c9cdff",
      "da65501903bb448f9ffc1be4dcab8fc5",
      "670a4f22a34b4454b8fce2da21096927",
      "7e3a8fe4544a449780f9e91beea64613",
      "cd33784029034a1aa47062a02af069d1",
      "74453a57697744e38d57234f966e8035",
      "17bbc091abcf48f585b2dc94acfae507",
      "a3c96fc888c94787ab31d543bcdb6b46",
      "d58d6bf93afd49f6ba18b443e8693b2f",
      "df0e5e70a7be47019df318fc4102c171",
      "9536dc411f0747bc81ad46f9afce494b",
      "821ae32fe6944d75bc9b11c4c1a6f6a8",
      "84da6593b07141d1b877776703158851",
      "011260a6c3fb42b3909230b3ed940ca2",
      "4bf76237c7634c1db3b0fd65e0511efe",
      "d31779c5e3bc4745bcab383b96971b81",
      "d8da28d3f648405abdd960b1e521c430",
      "7b494a0499f447de8e6cf846d7ad93be",
      "77cd305745934e049cd117dfeb6add8f",
      "4bf0acf5473947c480d179b674b6f407",
      "f466c6824be94412973b6e19cf6ef318",
      "c502f3c07b144520a54ab8822d6cc86b",
      "b23dd7254e284066a6d59024f7073f8d",
      "b20fbec7d0cb47e69480bcc4fbbc1d77",
      "d0070be0bf244e348a2ce56c52664796",
      "9c91e8ec06c844f8954ecfc6fb35b31b",
      "33d97d6bae7648259d044f77182e9f67",
      "db7a39b0e55a45ad8891b3b5bcdee9b5",
      "bc2b61a292114d5da77d8c2bc240c097",
      "a91931a8220f44e8b88c5aae757434c5",
      "a0bf4ca5bba54eeab927d8902de8b166",
      "c2d5d443f4174613afe5a62682a142c8",
      "5fb269bf76b44bd5b980d275388b1fed",
      "8b4c7c43efdc4c63b90448cec357a7d9",
      "a6ed1ef918d04bb9bcf8fdaa666ce850",
      "d4317ac3e6d8403f8dcfd54a5fde9045",
      "5185cf800fc044739e011464b9c968b6",
      "848d7e2bf38045608f8fd971d97744e9",
      "c1edc5897b604d97b76e3cef138b67aa",
      "8c3d40c1029c4d519e7c58274a0fd073",
      "e34a6a0dcd42439e90d21297e123c6df",
      "698ce908c4034709ac0e29c984663af0",
      "0f9e69c23e234c8b9e0739b0fa108318",
      "171d4673f77b449dab4f663fc586bdf1",
      "eb3901a4b13b4635a24137dd98411fb1",
      "487bd3bfcd6945d6a741ea595b2bdd0f",
      "2b934c5f448b43dfb9bcf357d16b4320",
      "423cf82bee7841f1a691cf3a613088a2",
      "56dfdea7245c4a88a3139b376b00c6fc",
      "fb40c59f4725464a98ea919005ba373c",
      "f2e09bb95e294fbbaa1df040100b03c5",
      "24f53edb49da433dbb5c73368f1a47c4",
      "2b5d0577f9d348ebb5dfe69ee391bf55",
      "6f95bc77a3274b18b497e99b3413ac72",
      "9947c4821da04bd19c7df223dda8efab",
      "20cfaf464ecd4b9983be89c862e69bac",
      "09b90ec98dd04609ade40f0d4c1c4497",
      "b0f1785d5c6848bba9b2a920d91ed035",
      "ee8f438b1d7043348bc5ae224e36cbf4",
      "e27febc30b634cad8d7cfaf5fe67e880",
      "b07cc14688354ccdac49fd6008902c74",
      "98b6d6e86d73406593e70316bf415fc1",
      "a4ea6d54bceb44038c9a6a0d485ba0cc",
      "9dc84eedf76c486dac609063e36400fb",
      "e332ed5bd2e349069f863d902f1b809b",
      "ba572f687efb47b4b157e32a3e5701bd",
      "33ce22f773db4b009ad64b6e6ab4e632",
      "50812d5d867549f093c18a7928a9add6",
      "813d55f658204f1598b6feb1ea65906a",
      "e447bffda60e4ac8b2a27f6da96399a0",
      "c2e23bf6b47f4e15a01453bb3de92423",
      "ecd5a57ade5a43a0beb1118e151f8480",
      "669e721705fb4a97bbf6b7266847cb76",
      "a89b76e184244128ad3bea47ab7272bf",
      "f635bcc656fb4f75b9984be72ae29736",
      "d0bc7d5f78d642d0bd7651ebcf7d3e84",
      "07177600d18940d39c64d00b1a92ca03",
      "5732b06c69dd4b77bc16c71c307fc5c7",
      "7073418b690b4f5ba05dc8e2f9974e36",
      "f6d71b54e6e64a888cfa74804b75351e",
      "b1bbac0b275242239fc8f3c6b8bd306f",
      "fbb315c228624d75a4d704fa7e8cbb83",
      "a2f7670e57a14214a72ebfc385ef7363",
      "8c3781d0cb894f599b80d89274fa777f",
      "c018849c6de74cb1b1f61915d76e6f95",
      "7f084c7570bf47bda150c2d8328bf6fc",
      "372dadfc7ff8450f97205b5edbc2b0ec",
      "1bad6d66611a4096a8224135cbeef738",
      "451ac43b573a43de9735fc3d3297c2ef",
      "ca8194025b15447d8a0dcdc62f190f34",
      "55edb5ce7d0a4e6d8c43fca2a87d0d9a",
      "9b1a6f68daa14e34b3aa0f61d6dbc077",
      "3776148edd7d449b827f8549a4487148",
      "239c0a1421614e0e87fdcb299df4f7c0",
      "8105a7fd8d424d1e8dda14e8a234ec47",
      "4d75819cb0d24c9ebca7ded0161828c3",
      "2cfcfd1e2ff74e63aaab766552cd9ca8",
      "093478d57aa646e28b9896c0e372f1e3"
     ]
    },
    "id": "wrtmtayc5Rl0",
    "outputId": "8008e275-28a2-424a-a312-df278bf8f552"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7c59282a78404a80c8360caf34d2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c043f4c2614b56b4e1c4696e5d4bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cfdb8bfb1e45d7a80f271d2d2a4849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.51M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3ce102d05442868e206817078b5e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e2476f8b734e9cb3716dd7c6920645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/731 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23b1672d86046a0b6afcab59a4d46be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9536dc411f0747bc81ad46f9afce494b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c502f3c07b144520a54ab8822d6cc86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb269bf76b44bd5b980d275388b1fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171d4673f77b449dab4f663fc586bdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9947c4821da04bd19c7df223dda8efab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba572f687efb47b4b157e32a3e5701bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07177600d18940d39c64d00b1a92ca03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bad6d66611a4096a8224135cbeef738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Nombre del modelo en Hugging Face\n",
    "MODEL_NAME = \"CasiAC/chatbot_tribu_salud_rag\"\n",
    "\n",
    "# Cargar el modelo y el tokenizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "# Crear el pipeline para generaciÃ³n de texto\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01u9nY52Bgqp"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import model_info\n",
    "\n",
    "model_name = \"CasiAC/chatbot_tribu_salud_rag\"\n",
    "\n",
    "try:\n",
    "    info = model_info(model_name)\n",
    "    print(f\"âœ… Modelo encontrado: {info.modelId}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666,
     "referenced_widgets": [
      "c36af21de7a44656b18658e6a8458611",
      "6ac60f8b86454b07bcdb6cceb3a95601",
      "c6174efcb1f74fb2a739713e307fa89a",
      "588426d21bb14ab9bbc9c8ddd29e1bea",
      "2314f60ef544461493be9f9de21a80e4",
      "fecc4b0eeb3043629b8b9a85dd79ff3b",
      "793810069936460baabcd66332c0c03e",
      "48ecc870fb06460d8c55f522ea46406f",
      "8554fb5785ce45ebb2bc16ae474174f7",
      "a06f2143cf3e4fee9b8b0ab8cd8f1f5e",
      "2b41a95a30694f8db0254a54102d6c29"
     ]
    },
    "id": "hUzoDB0k9VFF",
    "outputId": "4153147e-a43d-45cc-c99f-31d53d5c39eb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36af21de7a44656b18658e6a8458611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://be82ffc930d68ac4f7.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://be82ffc930d68ac4f7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Definir algunos documentos de ejemplo\n",
    "documents = [\n",
    "    \"Este es el primer documento con informaciÃ³n sobre salud evolutiva.\",\n",
    "    \"Este es el segundo documento con consejos de entrenamiento funcional.\",\n",
    "    \"Este es el tercer documento sobre nutriciÃ³n y estilo de vida saludable.\"\n",
    "]\n",
    "\n",
    "# Mensaje de bienvenida del chatbot\n",
    "system_message = \"\"\"\n",
    "ğŸ¦´ğŸŒ¿ Â¡Bienvenido a Tribu Salud! ğŸ‹ï¸â€â™‚ï¸ğŸ”¥\n",
    "\n",
    "Hola, soy tu asistente en salud evolutiva, aquÃ­ para ayudarte a optimizar tu bienestar con un enfoque basado en la biologÃ­a ancestral. ğŸ•ï¸ğŸ¥©\n",
    "\n",
    "ğŸ”¹ Â¿Quieres mejorar tu alimentaciÃ³n con principios evolutivos? ğŸ–ğŸ¥‘\n",
    "ğŸ”¹ Â¿Buscas consejos sobre entrenamiento funcional y movimiento natural? ğŸƒâ€â™‚ï¸ğŸ’ª\n",
    "ğŸ”¹ Â¿Te interesa mejorar tu descanso y reducir el estrÃ©s? ğŸ˜´ğŸŒ\n",
    "\n",
    "PregÃºntame lo que necesites, Â¡empecemos este viaje hacia una salud mÃ¡s alineada con nuestra naturaleza! ğŸš€ğŸ’¯\n",
    "\"\"\"\n",
    "\n",
    "# Nombre del modelo en Hugging Face (reemplaza con el tuyo)\n",
    "MODEL_NAME = \"CasiAC/chatbot_tribu_salud_rag\"\n",
    "\n",
    "# Forzar el uso de CPU (dado que la GPU estÃ¡ saturada o para facilitar la depuraciÃ³n)\n",
    "device = torch.device(\"cpu\")\n",
    "logging.info(\"Usando CPU para la inferencia.\")\n",
    "\n",
    "# Cargar el tokenizer y el modelo desde Hugging Face en CPU\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"cpu\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Crear pipeline para generaciÃ³n de texto (sin especificar 'device', ya que el modelo ya se cargÃ³ en CPU)\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, batch_size=1)\n",
    "\n",
    "# FunciÃ³n para generar respuesta en espaÃ±ol usando el mensaje de bienvenida y el prompt\n",
    "def generate_response(prompt):\n",
    "    full_prompt = f\"<s>[INST] {system_message}\\n{prompt}\\nPor favor, responde en espaÃ±ol. [/INST]\"\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=256, do_sample=True, temperature=0.7, top_p=0.9)\n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    response = response.replace(full_prompt, \"\").strip()\n",
    "    return response\n",
    "\n",
    "# FunciÃ³n para generar respuesta a partir de la pregunta y contexto\n",
    "def answer_question_with_generation(question, context, max_context_tokens=256):\n",
    "    # Truncar el contexto si es muy largo\n",
    "    context_tokens = tokenizer.encode(context, add_special_tokens=False)\n",
    "    if len(context_tokens) > max_context_tokens:\n",
    "        context_tokens = context_tokens[:max_context_tokens]\n",
    "        context = tokenizer.decode(context_tokens, skip_special_tokens=True)\n",
    "    prompt = f\"Pregunta: {question}\\nContexto: {context}\"\n",
    "    return generate_response(prompt)\n",
    "\n",
    "# FunciÃ³n para simular la recuperaciÃ³n de documentos (usa la variable 'documents' definida arriba)\n",
    "def retrieve_documents(question, top_k=3):\n",
    "    return documents[:top_k]\n",
    "\n",
    "# FunciÃ³n para probar el modelo RAG: recupera documentos y genera respuesta\n",
    "def test_rag_model(question, top_k=3):\n",
    "    try:\n",
    "        context = \" \".join(retrieve_documents(question, top_k))\n",
    "        answer = answer_question_with_generation(question, context)\n",
    "        logging.info(f\"Pregunta: {question}\\nContexto: {context}\\nRespuesta: {answer}\")\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en la prueba del modelo RAG: {e}\")\n",
    "        return \"âŒ OcurriÃ³ un error en la prueba del modelo.\"\n",
    "\n",
    "# FunciÃ³n para la interfaz del chatbot en Gradio\n",
    "def chatbot_interface(question):\n",
    "    return test_rag_model(question)\n",
    "\n",
    "# Lanzar la interfaz de Gradio\n",
    "gr.Interface(\n",
    "    fn=chatbot_interface,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Tribu Salud ğŸ¦´ğŸŒ¿ - Chatbot de Salud Evolutiva\",\n",
    "    description=\"Pregunta sobre salud evolutiva, entrenamiento funcional, nutriciÃ³n y estilo de vida saludable.\"\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj2GVfzOzkkn"
   },
   "source": [
    "## ğŸ“Œ Conclusiones y Recomendaciones para Mejorar el Chatbot Tribu Salud\n",
    "\n",
    "### ğŸ” Conclusiones\n",
    "\n",
    "1. **El mensaje de bienvenida ocupa demasiados tokens**\n",
    "   - El modelo estÃ¡ incluyendo el mensaje de bienvenida y el formato `[INST]` en cada respuesta, lo que consume muchos tokens y limita la capacidad de respuesta.\n",
    "   - Se observa que la salida repite parte del mensaje de bienvenida antes de responder a la pregunta.\n",
    "\n",
    "2. **El contexto adicional puede ser irrelevante o redundante**\n",
    "   - En la respuesta aparece un bloque de texto con \"Este es el primer documento con informaciÃ³n sobre salud evolutiva...\".\n",
    "   - Es posible que el sistema estÃ© incluyendo demasiada informaciÃ³n de contexto sin filtrar, lo que podrÃ­a reducir la precisiÃ³n de la respuesta.\n",
    "\n",
    "3. **Corte prematuro del texto generado**\n",
    "   - En algunos casos, la respuesta termina abruptamente, lo que sugiere que el modelo estÃ¡ alcanzando el lÃ­mite de tokens o que la salida se estÃ¡ truncando.\n",
    "\n",
    "4. **Formato de la respuesta mejorable**\n",
    "   - Aunque la respuesta tiene una estructura clara, podrÃ­a mejorarse con frases mÃ¡s concisas y evitando redundancias.\n",
    "   - Se podrÃ­a optimizar la claridad y la personalizaciÃ³n de la respuesta segÃºn la pregunta.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Recomendaciones de Mejora\n",
    "\n",
    "#### ğŸ”¹ Reducir el tamaÃ±o del mensaje de bienvenida\n",
    "- Eliminar emojis innecesarios y hacer el mensaje mÃ¡s corto.\n",
    "- Mostrar el mensaje solo una vez al inicio, no en cada interacciÃ³n.\n",
    "\n",
    "ğŸ“Œ **Ejemplo optimizado:**\n",
    "\n",
    "```plaintext\n",
    "Â¡Bienvenido a Tribu Salud! Soy tu asistente de salud evolutiva.  \n",
    "Pregunta sobre alimentaciÃ³n, entrenamiento y descanso. Â¡Estoy aquÃ­ para ayudarte!\n",
    "```\n",
    "\n",
    "#### ğŸ”¹ Optimizar la generaciÃ³n de respuestas\n",
    "- Modificar `max_new_tokens` a una cantidad mayor (ej. 300-400) para evitar cortes abruptos.\n",
    "- Ajustar `temperature` y `top_p` para mejorar la coherencia de las respuestas.\n",
    "- Asegurar que el modelo no repita el prompt en la salida.\n",
    "\n",
    "#### ğŸ”¹ Filtrar el contexto innecesario\n",
    "- Si estÃ¡s pasando documentos de contexto, revisa que sean realmente relevantes para cada pregunta.\n",
    "- Puedes limitar el contexto a solo las partes mÃ¡s importantes.\n",
    "\n",
    "#### ğŸ”¹ Mejorar el formato de la salida\n",
    "- Evitar listas demasiado generales y hacer respuestas mÃ¡s personalizadas segÃºn la pregunta del usuario.\n",
    "- Implementar un postprocesamiento para limpiar el texto y asegurarse de que la respuesta no estÃ© incompleta.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ Implementando estas mejoras, el chatbot Tribu Salud podrÃ¡ ofrecer respuestas mÃ¡s precisas, coherentes y Ãºtiles para los usuarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cObHHxEvqH3l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zYvbvk5qHlG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
