{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4RAc_uEg-QM"
   },
   "source": [
    "# ü¶¥üåø Chatbot \"Tribu Salud\" ‚Äì Salud Evolutiva con IA üèãÔ∏è‚Äç‚ôÇÔ∏èüî•\n",
    "\n",
    "## üéØ Objetivo  \n",
    "Desarrollar un **chatbot especializado en salud evolutiva** llamado **Tribu Salud**, utilizando **Mistral-7B-Instruct-v0.2**, con capacidades de comprensi√≥n y generaci√≥n de respuestas basadas en principios ancestrales de alimentaci√≥n, entrenamiento y bienestar.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Tecnolog√≠as y Metodolog√≠a  \n",
    "\n",
    "### üîπ 1. Modelo de Lenguaje  \n",
    "Se utiliza el modelo **Mistral-7B-Instruct-v0.2**, optimizado para respuestas conversacionales en espa√±ol y otras lenguas.\n",
    "\n",
    "### üîπ 2. Entrenamiento y Fine-Tuning  \n",
    "- Se usa el dataset **MLQA** (*MultiLingual Question Answering*) para entrenamiento inicial.  \n",
    "- Se aplica **fine-tuning** con datos espec√≠ficos de salud evolutiva.  \n",
    "\n",
    "### üîπ 3. RAG (Retrieval-Augmented Generation)  \n",
    "Para mejorar la precisi√≥n de las respuestas, se implementa **RAG**, combinando el modelo generativo con una base de conocimiento extra√≠da de:  \n",
    "- **Documentos PDF** relevantes.  \n",
    "- **Transcripciones de YouTube** de **Fitness Revolucionario**, obtenidas con `youtube-transcript-api`.  \n",
    "\n",
    "### üîπ 4. Indexado con FAISS  \n",
    "- Se mejora el **√≠ndice FAISS** para permitir **b√∫squedas r√°pidas y eficientes** en la base de conocimiento.  \n",
    "- Esto permite respuestas basadas en informaci√≥n real y verificada.  \n",
    "\n",
    "### üîπ 5. Despliegue con Gradio  \n",
    "- Se utiliza **Gradio** para desplegar el chatbot con una interfaz accesible y f√°cil de usar.  \n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Estado y Pr√≥ximos Pasos  \n",
    "‚úÖ Modelo Mixtral-8x22B cargado y configurado.  \n",
    "‚úÖ Dataset MLQA procesado y adaptado.  \n",
    "‚úÖ Implementaci√≥n de Fine-Tuning.  \n",
    "‚úÖ Extracci√≥n de informaci√≥n de PDFs y YouTube.  \n",
    "‚úÖ Optimizaci√≥n de FAISS para b√∫squeda r√°pida.  \n",
    "üîú Despliegue final y pruebas en Gradio.  \n",
    "\n",
    "---\n",
    "\n",
    "## üìå Conclusi√≥n  \n",
    "**Tribu Salud** ser√° un chatbot avanzado que proporcionar√° informaci√≥n precisa y confiable sobre **salud evolutiva, alimentaci√≥n y entrenamiento funcional**, integrando un **modelo de IA con recuperaci√≥n de informaci√≥n relevante**.  \n",
    "\n",
    "üì¢ **¬°Pronto estar√° disponible para consulta y uso!** üöÄüî•  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-m4NnYy8SQf",
    "outputId": "ddbcb54f-21b1-416a-a198-8bde4bf11495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWjSHwbG8iUu",
    "outputId": "14e9eb3f-b5e3-495d-c378-6412faf3ea05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.16 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.16)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.32)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (0.3.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading marshmallow-3.26.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.16 marshmallow-3.26.0 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ok2xo29c80n2",
    "outputId": "8d3dcedd-6885-4010-dfaf-aaf28bfbd4d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube_transcript_api\n",
      "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (0.7.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2024.12.14)\n",
      "Downloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: youtube_transcript_api\n",
      "Successfully installed youtube_transcript_api-0.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nevZXah-DnTR",
    "outputId": "c2905edf-ef93-40fb-ea2e-40909f700054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4cVDP44MwE5",
    "outputId": "65981be3-b157-4f1c-ebc8-f39cfe8b24f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.14.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.7.0 (from gradio)\n",
      "  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.9.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.9.0)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.17.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-5.14.0-py3-none-any.whl (57.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.7/57.7 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.9.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "Successfully installed aiofiles-23.2.1 fastapi-0.115.8 ffmpy-0.5.0 gradio-5.14.0 gradio-client-1.7.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.4 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6f6rZKW1pGq",
    "outputId": "6f45690f-d49f-4928-8f4a-585665c958db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: torch~=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (2024.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch~=2.0->bitsandbytes)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch~=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch~=2.0->bitsandbytes) (2.1.5)\n",
      "Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m252.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m268.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m262.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m280.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m325.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m320.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed bitsandbytes-0.45.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y bitsandbytes\n",
    "!pip install --no-cache-dir -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGs5qxQ7It0P",
    "outputId": "7e9fd76a-73a1-4f94-a955-66e4c3f79c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.5.1+cu124)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.47.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.2.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.27.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8WnSblPg0Hh",
    "outputId": "9e5934db-6eb7-4e6f-dceb-fc041e3e821c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHk6LhMYhoUt",
    "outputId": "436ea079-25a9-4470-ce44-5b080b6228a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/42.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMYNQayI-LoV",
    "outputId": "5885f6bb-4dde-4cce-cd14-7181deaa76f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45.1\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "print(bnb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lF7rEqeG-t4w",
    "outputId": "9340b6fc-d410-4814-b48a-ae9c100e92ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Debe devolver True\n",
    "print(torch.cuda.get_device_name())  # Debe listar la A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XVeg6YyMg_N9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import json\n",
    "import pdfplumber\n",
    "import requests\n",
    "import io\n",
    "import faiss\n",
    "import pickle\n",
    "import zipfile\n",
    "import gradio as gr\n",
    "from datasets import load_dataset\n",
    "from transformers import (TrainingArguments, Trainer, AutoTokenizer, AutoModelForCausalLM,\n",
    "                          DataCollatorForLanguageModeling, BitsAndBytesConfig, pipeline)\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "from google.colab import files\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "e7a7fa1f53794d19a13c821e0c364c2c",
      "c32ec26d0b684d848e983c68dd6b0f44",
      "d09e6f64a97b46b781c7ec4339e6abd6",
      "87f5015d8f484ed89c2a38d4e1aa66b4",
      "b6f9ae880b6441afa5594c77a4c4a923",
      "f4c67dc430ed4747a609488fbf836451",
      "37cbb50c77cc4f379f0376b78aa48a97",
      "a5caa46479a549aba4a03550cda037cd",
      "94f16b272ebe49129e8522fe26130207",
      "88607457723c4321a579c1fe4ea8c8ff",
      "b2a07dbddfc94431aaa49c23601d2b1c",
      "a16dd9a2ca654acb8d1d9cc6a5c979da",
      "edd73cfb50a84abfbbf8a768f801acf7",
      "f75e3b66c0e94667b8967316a2ec2b29",
      "203ba928597744d4b434bc4c51da2686",
      "4d96c9b0da5b48f3a2a4aaec038adf5d",
      "2d3c3b8a09104907b09641015b1d7811",
      "1218f8dc876142edb845680a4cd3e898",
      "ce9c64ba0a9f42b59b663b4dedacc6e9",
      "54f7d1b5b7b241ccb07c74f2183ca80a"
     ]
    },
    "id": "xTs_C9F_j1xL",
    "outputId": "29f343c5-b514-4fd6-b4e4-3af108097ce1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a7fa1f53794d19a13c821e0c364c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Autenticaci√≥n en Hugging Face\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "a8b3bbf3a9214c71895fde194787177c",
      "c47caa6a608f4c298546086761da96f4",
      "77afef2ffa4644408dbb5f7c7cb80c12",
      "2cdb14fa8b0a4e85b7c1294c7d8457e3",
      "75a5efb8abd7455abdaa7de3134c633c",
      "2b3233b5ce904b4fa7becaa768afb522",
      "a21ac5c7c1fa4f5c8e72bd78390a8864",
      "599d554c870347278ebe0ec17774540e",
      "d0728b20953e4273895fece85d5c4811",
      "76faa3bbeb4a48b8abd606eae88a3e41",
      "807212eec6df460291516d71792bac63"
     ]
    },
    "id": "hMVNXjPShEqG",
    "outputId": "0abeff88-f919-4d34-9f03-2fda3d6b7bec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b3bbf3a9214c71895fde194787177c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar modelo Mistral-7B-Instruct\n",
    "# Configuraci√≥n\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# Cuantizaci√≥n en 4-bit\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # Usa bfloat16 en A100\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Cargar modelo con offloading y LoRA\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Preparar modelo para fine-tuning en 4-bit\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Configurar LoRA (a√±adir adaptadores en capas clave)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # Tama√±o del cuello de botella de LoRA (ajustar seg√∫n RAM disponible)\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Aplicar LoRA solo en capas clave\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"  # Tipo de tarea para el modelo\n",
    ")\n",
    "\n",
    "# Aplicar LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Cargar tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Evitar errores con padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBtByHE7gm6z",
    "outputId": "212a6263-c793-424c-fa10-6554c436fab3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] \n",
      "ü¶¥üåø ¬°Bienvenido a Tribu Salud! üèãÔ∏è‚Äç‚ôÇÔ∏èüî•\n",
      "\n",
      "Hola, soy tu asistente en salud evolutiva, aqu√≠ para ayudarte a optimizar tu bienestar con un enfoque basado en la biolog√≠a ancestral. üèïÔ∏èü•©\n",
      "\n",
      "üîπ ¬øQuieres mejorar tu alimentaci√≥n con principios evolutivos? üçñü•ë\n",
      "üîπ ¬øBuscas consejos sobre entrenamiento funcional y movimiento natural? üèÉ‚Äç‚ôÇÔ∏èüí™\n",
      "üîπ ¬øTe interesa mejorar tu descanso y reducir el estr√©s? üò¥üåû\n",
      "\n",
      "Preg√∫ntame lo que necesites, ¬°empecemos este viaje hacia una salud m√°s alineada con nuestra naturaleza! üöÄüíØ\n",
      "\n",
      "¬øQu√© beneficios tiene la dieta paleo?\n",
      "Por favor, responde en espa√±ol. [/INST] La dieta paleo puede tener beneficios para la salud, como mejorar el equilibrio de macronutrientes, reducir la inflamaci√≥n, mejorar la sensibilidad al gl√∫cose y mejorar la insulina, y mejorar la calidad del sonido. Sin embargo, es importante mencionar que la dieta paleo no es una dieta balanceada por s√≠ misma y puede requerir planificar cuidadosamente para garantizar que se obtienen todos los nutrientes necesarios. Adem√°s, la evidencia cient√≠fica sobre la efectividad de la dieta paleo para mejorar la salud es limitada y m√°s investigaci√≥n es necesaria para confirmar sus beneficios.\n",
      "\n",
      "Si te interesa m√°s informaci√≥n sobre la dieta paleo y sus posibles beneficios, puedes preguntarme sobre temas espec√≠ficos. Adem√°s, puedes visitar nuestra p√°gina web en espa√±ol (tribusalud.es) para obtener m√°s informaci√≥n y recursos relacionados con la salud evolutiva.\n",
      "\n",
      "Pregunta sobre lo que necesites\n"
     ]
    }
   ],
   "source": [
    "# Mensaje de bienvenida del chatbot\n",
    "system_message = \"\"\"\n",
    "ü¶¥üåø ¬°Bienvenido a Tribu Salud! üèãÔ∏è‚Äç‚ôÇÔ∏èüî•\n",
    "\n",
    "Hola, soy tu asistente en salud evolutiva, aqu√≠ para ayudarte a optimizar tu bienestar con un enfoque basado en la biolog√≠a ancestral. üèïÔ∏èü•©\n",
    "\n",
    "üîπ ¬øQuieres mejorar tu alimentaci√≥n con principios evolutivos? üçñü•ë\n",
    "üîπ ¬øBuscas consejos sobre entrenamiento funcional y movimiento natural? üèÉ‚Äç‚ôÇÔ∏èüí™\n",
    "üîπ ¬øTe interesa mejorar tu descanso y reducir el estr√©s? üò¥üåû\n",
    "\n",
    "Preg√∫ntame lo que necesites, ¬°empecemos este viaje hacia una salud m√°s alineada con nuestra naturaleza! üöÄüíØ\n",
    "\"\"\"\n",
    "\n",
    "def generate_response(prompt):\n",
    "    \"\"\"Genera respuesta en espa√±ol usando Mistral-7B-Instruct-v0.2.\"\"\"\n",
    "    full_prompt = f\"<s>[INST] {system_message}\\n{prompt}\\nPor favor, responde en espa√±ol. [/INST]\"\n",
    "\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=256, do_sample=True, temperature=0.7, top_p=0.9)\n",
    "\n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    # Eliminar el prompt de la respuesta final\n",
    "    response = response.replace(full_prompt, \"\").strip()\n",
    "    return response\n",
    "\n",
    "# Prueba del chatbot\n",
    "pregunta = \"¬øQu√© beneficios tiene la dieta paleo?\"\n",
    "respuesta = generate_response(pregunta)\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712,
     "referenced_widgets": [
      "467b831d933540029b7dc760dbe0ef1e",
      "12099ee5841f45939f21cf6e880912cc",
      "13b4d5e7167d4d279138b51bc19f5f9c",
      "3fef6b9b1ce6417289be3ffd6ee87204",
      "507119042e8a4b5faeab73b2e7ee2f2d",
      "49e6259a846b4127adb1b3be0ef4cca0",
      "88b667c9686543318881a266bc9ae4da",
      "eb46cab7f3d5419e965d2df582b3e867",
      "f7449097458a480491f80985b6698377",
      "aecfa1490cee4f29b2dc298f5e927770",
      "e78fd97643e642ac803f6fc24d7e684e"
     ]
    },
    "id": "zDAEFLqxhNHI",
    "outputId": "c12fbbc2-99e5-4919-d772-fac14602f2b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset cargado correctamente.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467b831d933540029b7dc760dbe0ef1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Prompt generado:\n",
      "<s>[INST] \n",
      "ü¶¥üåø ¬°Bienvenido a Tribu Salud! üèãÔ∏è‚Äç‚ôÇÔ∏èüî•\n",
      "\n",
      "Hola, soy tu asistente en salud evolutiva, aqu√≠ para ayudarte a optimizar tu bienestar con un enfoque basado en la biolog√≠a ancestral. üèïÔ∏èü•©\n",
      "\n",
      "üîπ ¬øQuieres mejorar tu alimentaci√≥n con principios evolutivos? üçñü•ë\n",
      "üîπ ¬øBuscas consejos sobre entrenamiento funcional y movimiento natural? üèÉ‚Äç‚ôÇÔ∏èüí™\n",
      "üîπ ¬øTe interesa mejorar tu descanso y reducir el estr√©s? üò¥üåû\n",
      "\n",
      "Preg√∫ntame lo que necesites, ¬°empecemos este viaje hacia una salud m√°s alineada con nuestra naturaleza! üöÄüíØ\n",
      "\n",
      "Pregunta: Por qu√© raz√≥n el primer ministro passos coelho justific√≥ cortar 30000 puestos de trabajo?\n",
      "Contexto: En la primera semana de mayo de 2013, el primer ministro passos coelho anunci√≥ un plan de gobierno significativo para el sector p√∫blico, en el que se va 30,000 puestos de trabajo y el n√∫mero de horas de trabajo semanales se aumentar√° de 35 a 40 horas. Coelho reafirm√≥ el anuncio explicando que las medidas de austeridad son necesarias si Portugal busca evitar otra subvenci√≥n de rescate monetario de la Comisi√≥n Europea, banco central europeo y el fondo monetario internacional- el plan general tiene la intenci√≥n de promulgar m√°s recortes de 4.8 millones de ‚Ç¨ durante un per√≠odo de tres a√±os.\n",
      "Da una respuesta clara en espa√±ol. [/INST]\n",
      "\n",
      "ü§ñ Respuesta del modelo:\n",
      "[INST] \n",
      "ü¶¥üåø ¬°Bienvenido a Tribu Salud! üèãÔ∏è‚Äç‚ôÇÔ∏èüî•\n",
      "\n",
      "Hola, soy tu asistente en salud evolutiva, aqu√≠ para ayudarte a optimizar tu bienestar con un enfoque basado en la biolog√≠a ancestral. üèïÔ∏èü•©\n",
      "\n",
      "üîπ ¬øQuieres mejorar tu alimentaci√≥n con principios evolutivos? üçñü•ë\n",
      "üîπ ¬øBuscas consejos sobre entrenamiento funcional y movimiento natural? üèÉ‚Äç‚ôÇÔ∏èüí™\n",
      "üîπ ¬øTe interesa mejorar tu descanso y reducir el estr√©s? üò¥üåû\n",
      "\n",
      "Preg√∫ntame lo que necesites, ¬°empecemos este viaje hacia una salud m√°s alineada con nuestra naturaleza! üöÄüíØ\n",
      "\n",
      "Pregunta: Por qu√© raz√≥n el primer ministro passos coelho justific√≥ cortar 30000 puestos de trabajo?\n",
      "Contexto: En la primera semana de mayo de 2013, el primer ministro passos coelho anunci√≥ un plan de gobierno significativo para el sector p√∫blico, en el que se va 30,000 puestos de trabajo y el n√∫mero de horas de trabajo semanales se aumentar√° de 35 a 40 horas. Coelho reafirm√≥ el anuncio explicando que las medidas de austeridad son necesarias si Portugal busca evitar otra subvenci√≥n de rescate monetario de la Comisi√≥n Europea, banco central europeo y el fondo monetario internacional- el plan general tiene la intenci√≥n de promulgar m√°s recortes de 4.8 millones de ‚Ç¨ durante un per√≠odo de tres a√±os.\n",
      "Da una respuesta clara en espa√±ol. [/INST] Hola! I'm glad you're here to join Tribu Salud, your evolutionary health assistant. I'm here to help you optimize your well-being with an ancestral approach. Whether you're looking to improve your nutrition with evolutionary principles, seek advice on functional training and natural movement, or want to enhance your rest and reduce stress, I'm here for you. ü•©üèãÔ∏èüî•\n",
      "\n",
      "Regarding your question, the reason the Prime Minister of Portugal, Passos Coelho, justified cutting 30,000 public jobs was due to the need for austerity measures to avoid another bailout from the European Commission, European Central Bank, and the International Monetary Fund. Portugal aimed to save an additional ‚Ç¨4.8 million during a three-year period, and this significant government plan included job cuts and increasing weekly working hours from 35 to 40 hours. üíºüïí\n",
      "\n",
      "There you go! Let me know if you have any other questions or need assistance with anything related to your health and well-being. üòäüí™üèºüåøüå±üèïÔ∏è #Tribu\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset\n",
    "try:\n",
    "    dataset = load_dataset(\"mlqa\", \"mlqa-translate-train.es\", trust_remote_code=True)\n",
    "    train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(min(10000, len(dataset[\"train\"]))))\n",
    "    val_dataset = (\n",
    "        dataset[\"validation\"].shuffle(seed=42).select(range(min(2000, len(dataset[\"validation\"]))))\n",
    "        if \"validation\" in dataset\n",
    "        else None\n",
    "    )\n",
    "    print(\"‚úÖ Dataset cargado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error cargando dataset: {e}\")\n",
    "    train_dataset, val_dataset = None, None\n",
    "\n",
    "# Funci√≥n para generar prompt con formato Mistral\n",
    "def create_prompt(sample):\n",
    "    \"\"\"\n",
    "    Crea un prompt formateado para Mistral-7B-Instruct-v0.2 basado en un ejemplo del dataset.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"<s>[INST] {system_message}\\n\"\n",
    "        f\"Pregunta: {sample['question']}\\n\"\n",
    "        f\"Contexto: {sample['context']}\\n\"\n",
    "        \"Da una respuesta clara en espa√±ol. [/INST]\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# Funci√≥n para tokenizar el prompt y preparar los labels.\n",
    "def tokenize_prompt(sample):\n",
    "    prompt = create_prompt(sample)\n",
    "    tokenized = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    tokenized[\"prompt\"] = prompt  # Guardamos el prompt original\n",
    "    return tokenized\n",
    "\n",
    "# Aplicar la tokenizaci√≥n al dataset y eliminar columnas originales\n",
    "if train_dataset is not None:\n",
    "    train_dataset = train_dataset.map(\n",
    "        tokenize_prompt,\n",
    "        remove_columns=train_dataset.column_names,\n",
    "        batched=False  # Procesamos ejemplo a ejemplo para mayor claridad\n",
    "    )\n",
    "if val_dataset is not None:\n",
    "    val_dataset = val_dataset.map(\n",
    "        tokenize_prompt,\n",
    "        remove_columns=val_dataset.column_names,\n",
    "        batched=False\n",
    "    )\n",
    "\n",
    "# Funci√≥n para probar el modelo con una muestra del dataset tokenizado\n",
    "def test_dataset_sample(dataset, index=0):\n",
    "    \"\"\"\n",
    "    Prueba el modelo con una muestra del dataset MLQA ya tokenizado.\n",
    "    \"\"\"\n",
    "    if dataset is None or len(dataset) <= index:\n",
    "        print(\"‚ùå El dataset est√° vac√≠o o el √≠ndice es inv√°lido.\")\n",
    "        return\n",
    "\n",
    "    sample = dataset[index]\n",
    "    # Recuperamos el prompt original guardado durante la tokenizaci√≥n\n",
    "    prompt = sample.get(\"prompt\", \"No se encontr√≥ prompt en la muestra.\")\n",
    "\n",
    "    # Configurar el dispositivo (CPU/GPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Convertir los input_ids y attention_mask a tensores y agregar dimensi√≥n batch\n",
    "    inputs = {\n",
    "        \"input_ids\": torch.tensor(sample[\"input_ids\"]).unsqueeze(0).to(device),\n",
    "        \"attention_mask\": torch.tensor(sample[\"attention_mask\"]).unsqueeze(0).to(device),\n",
    "    }\n",
    "\n",
    "    # Generar respuesta\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9\n",
    "        )\n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    # Remover el prompt si aparece en la salida\n",
    "    response = response.replace(prompt, \"\").strip()\n",
    "\n",
    "    print(\"üìå Prompt generado:\")\n",
    "    print(prompt)\n",
    "    print(\"\\nü§ñ Respuesta del modelo:\")\n",
    "    print(response)\n",
    "\n",
    "# Probar con un ejemplo del dataset de entrenamiento (ya tokenizado)\n",
    "test_dataset_sample(train_dataset, index=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "DANLRwg0Och3",
    "outputId": "e3ee2d54-0d91-43a4-900f-c27e88f5e389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 34:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.880900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Entrenamiento completado.\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n de entrenamiento ajustada para reducir tiempo\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,  # Aumentar tama√±o de batch para procesar m√°s ejemplos por iteraci√≥n\n",
    "    per_device_eval_batch_size=8,  # Aumentamos tambi√©n para la evaluaci√≥n\n",
    "    eval_strategy=\"no\",  # Desactivar evaluaci√≥n para evitar sobrecargar el tiempo de entrenamiento\n",
    "    save_strategy=\"no\",  # Desactivar guardar el modelo cada √©poca para evitar tiempos adicionales\n",
    "    num_train_epochs=1,  # Reducimos a 1 √©poca para acelerar el entrenamiento\n",
    "    learning_rate=5e-5,  # Aumentamos ligeramente la tasa de aprendizaje para entrenamiento m√°s r√°pido\n",
    "    weight_decay=0.01,\n",
    "    bf16=True,  # A100 usa bfloat16 para mejorar la velocidad\n",
    "    gradient_accumulation_steps=1,  # No es necesario acumular gradientes si se usa un batch m√°s grande\n",
    "    push_to_hub=False,\n",
    "    gradient_checkpointing=False,  # Desactivamos checkpointing para acelerar\n",
    "    optim=\"adamw_torch\",  # Optimizador eficiente\n",
    "    report_to=\"none\",  # Desactiva logs en WandB\n",
    "    remove_unused_columns=False,  # Dejamos False ya que ya eliminamos columnas en el map\n",
    ")\n",
    "\n",
    "# Crear Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=None,  # No necesario para modelos de lenguaje\n",
    ")\n",
    "\n",
    "# Iniciar entrenamiento\n",
    "if train_dataset:\n",
    "    print(\"üöÄ Iniciando entrenamiento...\")\n",
    "    trainer.train()\n",
    "    print(\"‚úÖ Entrenamiento completado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "h2JCfP1B4g1n",
    "outputId": "4911a4a7-58fe-40cd-9340-0ce52b0f449a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo guardado y comprimido en: /content/trained_tribu_salud.zip\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_6f2a2920-804a-4c31-813d-bc71a6dd4298\", \"trained_tribu_salud.zip\", 26015255)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Descarga iniciada...\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo entrenado localmente\n",
    "model_dir = \"/content/trained_tribu_salud\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Guardar el modelo y el tokenizador\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "# Comprimir la carpeta del modelo en un ZIP\n",
    "zip_filename = \"/content/trained_tribu_salud.zip\"\n",
    "shutil.make_archive(zip_filename.replace(\".zip\", \"\"), 'zip', model_dir)\n",
    "print(f\"‚úÖ Modelo guardado y comprimido en: {zip_filename}\")\n",
    "\n",
    "# Descargar el archivo ZIP localmente\n",
    "files.download(zip_filename)\n",
    "print(\"üì• Descarga iniciada...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148,
     "referenced_widgets": [
      "54927ae08da44eb1a7f6f098de630bd2",
      "8ed616288bbb4afdaa7cec1a63dfd464",
      "10aaba6f8c9546b48f8550d90920c0b0",
      "07da945272374461ba39343f9b2c1011",
      "1c7f0a4c8892409d87618ed5629fd0f3",
      "e3363ce4f0ff4300936e89b91d446e4f",
      "497bc3f6183244d2b2560b54d909a70a",
      "35d00ffbe7974adb82524c59e34595ef",
      "bf8188b2fec3403eb2971a63ae9dfc74",
      "f3f35f8f6e3d4be585d782262ffb7d1a",
      "552c892711604eb6b7a8ab54f19a1e63",
      "6397702c877048de83496516691b98f8",
      "fa005ed714674373a3dd3764ed8efea5",
      "214ca22000994f088cff758b63f337fa",
      "8b53ab75a1074ea2a7de1f9807aad422",
      "dff578519d654eca9774d46b71ed9f91",
      "6c89afaaa2e144a69e0489b892b468ac",
      "fdd1514601844552bbee48e25df2976c",
      "286d0405bdbb4bb2bdb2cc516c6fbe8c",
      "1d77ed0bdd104effa1678a00d7847ac3",
      "13d5308372e04086a32fad4d7d3afe3c",
      "ff1c7323ce58488281bd903aa65af254",
      "f6a4bcfc554f42e296e58c9e9d983c70",
      "1baa7f9c5bfd46999c08145a9fbd9151",
      "8b21d191305f47978f5f1e760b3d28c5",
      "b330b775f89e49dca139e740c7610748",
      "b4b773b36ef8477f8045f3c5abb6ab0e",
      "4b91d8d7b26f4bd9b92ef14c2b20d7b5",
      "8e6100d274654153a66bb7705cc0a74e",
      "a37360df02f34e2699e40ee30368e043",
      "fc5034aa7bf04e089f763ad326b78aad",
      "a6f52be5194946c9b130f0d59e0e993e",
      "06782ee27f4b46e9832d3ffe59b84962"
     ]
    },
    "id": "EfIUE2WSp1Ra",
    "outputId": "af25cd9f-7e41-46ea-e66e-46f906a5f5b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Carpeta del modelo encontrada: /content/trained_tribu_salud\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54927ae08da44eb1a7f6f098de630bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6397702c877048de83496516691b98f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a4bcfc554f42e296e58c9e9d983c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Modelo subido correctamente a Hugging Face: https://huggingface.co/CasiAC/chatbot_tribu_salud\n"
     ]
    }
   ],
   "source": [
    "# Subir modelo a Hugging Face\n",
    "\n",
    "repo_name = \"CasiAC/chatbot_tribu_salud\"\n",
    "repo_dir = \"/content/hf_tribu_salud\"\n",
    "\n",
    "# Verificar si el modelo existe antes de subirlo\n",
    "if not os.path.exists(model_dir):\n",
    "    raise FileNotFoundError(f\"‚ö† Error: No se encontr√≥ la carpeta {model_dir}. Verifica si el entrenamiento fue exitoso.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Carpeta del modelo encontrada: {model_dir}\")\n",
    "\n",
    "# Crear repositorio en Hugging Face (si no existe)\n",
    "api = HfApi()\n",
    "create_repo(repo_name, repo_type=\"model\", private=True, exist_ok=True)\n",
    "\n",
    "# Copiar modelo a la carpeta del repositorio\n",
    "shutil.copytree(model_dir, repo_dir, dirs_exist_ok=True)\n",
    "\n",
    "# Subir modelo a Hugging Face\n",
    "api.upload_folder(\n",
    "    folder_path=repo_dir,\n",
    "    repo_id=repo_name,\n",
    "    repo_type=\"model\",\n",
    "    commit_message=\"üöÄ Subida inicial del chatbot Tribu Salud basado en Mistral 7B\"\n",
    ")\n",
    "\n",
    "print(f\"üöÄ Modelo subido correctamente a Hugging Face: https://huggingface.co/{repo_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUV_K44m9saF",
    "outputId": "b97203c8-7e33-4f0c-b9e2-07cdfb0e0f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EL MANUALEl Manual Revolucionario 1\n",
      "REVOLUCIONARIO\n",
      "El principio Fitness\n",
      "de tu revoluci√≥n Revolucionario\n",
      "√çndice El Manual Revolucionario 2\n",
      "Copyright ¬© 2021 por\n",
      "Fitness Revolucionario.\n",
      "LAS BASES 3\n",
      "NUTRICI√ìN 6\n",
      "17 ENTRENAMIENTO\n",
      "OTROS ASPECTOS 20\n",
      "21 RECETAS\n",
      "Las Bases El Manual Revolucionario 3\n",
      "LAS BASES\n",
      "Una nueva forma de entender y\n",
      "mejorar tu salud. Si este es tu primer\n",
      "contacto con Fitness Revolucionario,\n",
      "d√©jame resumirte lo que encontrar√°s\n",
      "en mi blog y podcast.\n",
      "01 02\n",
      "Explicaciones detalladas sobre c√≥mo Cuestionamientos de muchas creen-\n",
      "funciona realmente tu cuerpo. Cui¬≠ cias comunes sobre salud. Muchas\n",
      "damos m√°s aquello que conocemos, ideas que se repiten constantemente\n",
      "y la mayor√≠a desconoce los aspectos (como que hay que comer muchas\n",
      "b√°sicos del cuerpo en el que vive. veces al d√≠a o que es importante esti¬≠\n",
      "rar antes de entrenar) han sido des¬≠\n",
      "terradas por la ciencia m√°s reciente,\n",
      "pero siguen formando parte de las\n",
      "recomendaciones habituales.\n",
      "03 04\n",
      "Recomendaciones pr√°cticas para Una visi√≥n distinta del fitness y la\n",
      "mejorar tu cuerpo, basadas en evi¬≠ salud. El mundo del fitness actual\n",
      "dencia cient√≠fica pero explicadas de puede resultar sofocante y confuso,\n",
      "manera sencilla. Mejorar√°s c√≥mo te con mucha informaci√≥n contradicto¬≠\n",
      "ves y, sobre todo, c√≥mo te sientes. ria y compleja. Mi objetivo es simpli¬≠\n",
      "ficar y darte informaci√≥n de verdad,\n",
      "proponiendo un enfoque m√°s libre\n",
      "y flexible, adaptable a tu vida diaria.\n",
      "Mejorar tu salud no deber√≠a ser un\n",
      "trabajo a tiempo completo.\n",
      "Las Bases El Manual Revolucionario 4\n",
      "¬øEn qu√© se basa? Las recomendaciones\n",
      "de este Manual, as√≠ como las del blog\n",
      "en general, est√°n basadas en tres\n",
      "grandes principios.\n",
      "03 ‚Äî\n",
      "Experiencia\n",
      "Pr√°ctica\n",
      "02 ‚Äî\n",
      "Evidencia\n",
      "Cient√≠fica\n",
      "01 ‚Äî\n",
      "Biolog√≠a\n",
      "Evolutiva\n",
      "Las Bases El Manual Revolucionario 5\n",
      "Biolog√≠a Evolutiva\n",
      "el tiempo, nuestra biolog√≠a se adapt√≥\n",
      "a ciertos est√≠mulos, cuya ausencia\n",
      "‚Äî\n",
      "nos da√±a. Por otro lado, el progreso\n",
      "Nada en biolog√≠a tiene\n",
      "nos expuso a est√≠mulos nuevos, a los\n",
      "sentido si no es a luz de\n",
      "que no estamos bien adaptados.\n",
      "la evoluci√≥n.\n",
      "‚Äî\n",
      "No se trata de renunciar a ninguna de\n",
      "Theodosius Dobzhansky las comodidades del mundo moder¬≠\n",
      "no, pero debemos incluir en nuestra\n",
      "Nuestros genes se forjaron en un en¬≠ vida est√≠mulos ancestrales perdidos y\n",
      "torno salvaje. El 99% de nuestra larga limitar los nuevos que nos da√±an.\n",
      "historia como especie discurri√≥ en un\n",
      "entorno natural, sin acceso a las co¬≠ En esta p√°gina detallo m√°s qu√© es¬≠\n",
      "modidades del mundo moderno. Con t√≠mulos recuperar y cu√°les evitar.\n",
      "Evidencia cient√≠fica\n",
      "La visi√≥n evolutiva ofrece un buen\n",
      "marco te√≥rico de partida, pero todos\n",
      "‚Äî\n",
      "los supuestos que hagamos a partir\n",
      "La ciencia es el mejor\n",
      "de nuestro pasado deben estar res¬≠\n",
      "ant√≠doto contra el veneno\n",
      "paldados por la ciencia actual. Por\n",
      "de la superstici√≥n.\n",
      "ese motivo encontrar√°s decenas de\n",
      "‚Äî\n",
      "referencias cient√≠ficas en mis art√≠cu¬≠\n",
      "Adam Smith los, respaldando cada una de las\n",
      "recomendaciones.\n",
      "Experiencia pr√°ctica\n",
      "de laboratorio si tienen poca aplica¬≠\n",
      "bilidad en el mundo real.\n",
      "‚Äî\n",
      "La experiencia nos\n",
      "Dicho esto, cada persona tiene una\n",
      "guiar√° hacia las reglas.\n",
      "realidad distinta. Algunas recomen¬≠\n",
      "‚Äî\n",
      "daciones te parecer√°n sencillas de\n",
      "Antoine de Saint-Exup√©ry aplicar y otras no encajar√°n con tu\n",
      "estilo de vida actual. Podr√°s seleccio¬≠\n",
      "Por √∫ltimo, nos basamos en la expe¬≠ nar las cosas que resuenan contigo y\n",
      "riencia pr√°ctica y los buenos resulta¬≠ descartar las dem√°s, o adoptarlas de\n",
      "dos logrados por miles de personas. manera gradual. Es tu vida, y debes\n",
      "De nada sirven los mejores estudios dise√±arla a tu medida.\n",
      "El Manual Revolucionario 6\n",
      "Conceptos de nutrici√≥n. Para mejorar\n",
      "tu alimentaci√≥n y lograr tus objetivos\n",
      "debes conocer algunos principios. En\n",
      "El Plan Revolucionario profundizamos\n",
      "mucho m√°s, pero nos limitaremos aqu√≠\n",
      "a lo esencial.\n",
      "Para empezar, debes conocer la\n",
      "importancia relativa de los facto¬≠\n",
      "res, que detallamos en la siguiente\n",
      "pir√°mide.\n",
      "A continuaci√≥n exploraremos cada\n",
      "uno de sus elementos.\n",
      "ALIMENTOS\n",
      "Nutrici√≥n\n",
      "NUTRICI√ìN\n",
      "SUPLEMENTOS\n",
      "FRECUENCIA\n",
      "MACRONUTRIENTES\n",
      "CALOR√çAS\n",
      "El Manual Revolucionario 7\n",
      "Alimentos\n",
      "De manera transversal al resto de\n",
      "elementos est√°n los alimentos. No\n",
      "compramos calor√≠as o macronutrien¬≠\n",
      "tes en el supermercado, sino comida.\n",
      "Aprender a seleccionar los mejores\n",
      "alimentos es el primer paso para\n",
      "mejorar tu salud y alcanzar tu peso\n",
      "ideal.\n",
      "Aunque no existe una pir√°mide Incluimos en ella aspectos como ayu¬≠\n",
      "universal de alimentos para todo el no intermitente y recargas. No pro¬≠\n",
      "mundo, podr√≠amos plantear una ge¬≠ fundizamos en ellos en este ma nual,\n",
      "neral como la del gr√°fico inferior. pero puedes aprender m√°s sobre\n",
      "ambos en los enlaces indicados.\n",
      "ALIMENTOS\n",
      "Nutrici√≥n\n",
      "SUPLEMENTOS\n",
      "FRECUENCIA\n",
      "MACRONUTRIENTES\n",
      "CALOR√çAS\n",
      "‚Äî ‚Äî\n",
      "Chocolate 90% ¬∑ Ayuno\n",
      "Hierbas y especias ¬∑ intermitente\n",
      "Suplementos\n",
      "‚Äî ‚Äî\n",
      "Leche entera / Ciclados y\n",
      "Cereales recargas\n",
      "‚Äî\n",
      "Frutos secos ¬∑ Yogures ¬∑\n",
      "Quesos ¬∑ Aceites ¬∑ Grasas\n",
      "naturales / Tub√©rculos ¬∑\n",
      "Semillas ¬∑ Ra√≠ces\n",
      "‚Äî\n",
      "Pescado ¬∑ Pollo ¬∑\n",
      "Huevos ¬∑ Legumbres ¬∑\n",
      "Carne roja\n",
      "‚Äî\n",
      "Verduras /\n",
      "Frutas\n",
      "El Manual Revolucionario 8\n",
      "Calor√≠as\n",
      "Las calor√≠as est√°n en la base, porque\n",
      "el balance energ√©tico es lo que de¬≠\n",
      "terminar√° finalmente si pierdes o ga¬≠\n",
      "nas peso. Si comes m√°s de lo gastas\n",
      "ganar√°s peso. Si comes menos de lo\n",
      "que gastas perder√°s peso.\n",
      "Variaci√≥n de peso = Ingesta cal√≥rica ‚Äî Gasto cal√≥rico\n",
      "Esta ecuaci√≥n refleja la primera ley productos del supermercado est√°n\n",
      "de la termodin√°mica, y se cumple especialmente dise√±ados para que\n",
      "siempre. Sin embargo, la mayor√≠a de comas m√°s, salt√°ndose tu ciclo natu¬≠\n",
      "personas fracasan a la hora de perder ral de hambre¬≠saciedad.\n",
      "grasa simplemente contando calor√≠as.\n",
      "Al elegir los alimentos adecuados\n",
      "‚Äî ¬øPor qu√©? tus hormonas se regular√°n con m√°s\n",
      "facilidad. De esta manera el equili¬≠\n",
      "Generalmente, por el hambre. Cier¬≠ brio cal√≥rico ser√° el resultado natural\n",
      "tos alimentos son mucho menos sa¬≠ de comer hasta la saciedad, en vez de\n",
      "ciantes que otros, especialmente los intentar forzar ese control cal√≥rico\n",
      "m√°s procesados. Muchos de los usando apps y pasando hambre.\n",
      "Opci√≥n A (lo que la mayor√≠a intenta)\n",
      "Menos calor√≠as > P√©rdida de peso > Regulaci√≥n hormonal\n",
      "Opci√≥n B (mi recomendaci√≥n)\n",
      "Regulaci√≥n hormonal > Menos calor√≠as > P√©rdida de peso\n",
      "La opci√≥n A est√° centrada en controlar calor√≠as, y suele fracasar. La opci√≥n B prio¬≠\n",
      "riza lo importante, poniendo el √©nfasis en regular tu entorno hormonal. Al lograr\n",
      "esto tu hambre ser√° un mejor predictor de la energ√≠a que realmente necesitas.\n",
      "ALIMENTOS\n",
      "Nutrici√≥n\n",
      "SUPLEMENTOS\n",
      "FRECUENCIA\n",
      "MACRONUTRIENTES\n",
      "CALOR√çAS\n",
      "El Manual Revolucionario 9\n",
      "Esta regulaci√≥n hormonal mejo¬≠ procesados y priorizar los alimentos\n",
      "rar√° con un enfoque global. La ali¬≠ que mencionamos en la secci√≥n\n",
      "mentaci√≥n es una pieza muy impor¬≠ anterior.\n",
      "tante, pero no es la √∫nica. Incluir\n",
      "actividad f√≠sica y mejorar el descanso Eso no implica que para lograr ob¬≠\n",
      "son otros aspectos fundamentales. jetivos concretos no debas contar\n",
      "calor√≠as. Contar calor√≠as te ayudar√°\n",
      "Centr√°ndonos en la alimentaci√≥n, a lograr objetivos m√°s espec√≠ficos,\n",
      "priorizar la comida real es la mejor adem√°s de aprender algo m√°s so¬≠\n",
      "recomendaci√≥n general. La mayor√≠a bre tus alimentos. Lo detallo en este\n",
      "de personas pierden peso con facili¬≠ art√≠culo.\n",
      "dad al eliminar los productos ultra¬≠\n",
      "Macronutrientes\n",
      "Hay tres macronutrientes:\n",
      "Prote√≠na\n",
      "Carbohidrato\n",
      "Grasa\n",
      "De estos tres, debes prestar especial\n",
      "atenci√≥n a la prote√≠na. Todas tus\n",
      "comidas principales deber√≠an con¬≠\n",
      "tener una buena fuente de prote√≠na. vidad f√≠sica. Las dietas moderadas\n",
      "Si quieres m√©tricas m√°s precisas, en grasa suelen ser m√°s saciantes y\n",
      "deber√≠as apuntar a 1.5‚Äî2 g/kg. Es efectivas para perder peso que las\n",
      "decir, si pesas 70 kg, deber√≠as comer dietas bajas en grasa. Incluye m√°s\n",
      "entre 100 y 140 gramos de prote√≠na, carbohidrato si llevas una vida acti¬≠\n",
      "pero no hace falta prestar demasiada va y menos si eres principalmente\n",
      "atenci√≥n a estos detalles al principio. seden tario.\n",
      "El reparto entre grasa y carbohidra ¬≠\n",
      "to es menos relevante, y depender√°\n",
      "de tus preferencias y nivel de acti¬≠\n",
      "ALIMENTOS\n",
      "Nutrici√≥n\n",
      "SUPLEMENTOS\n",
      "FRECUENCIA\n",
      "MACRONUTRIENTES\n",
      "CALOR√çAS\n",
      "El Manual Revolucionario 10\n",
      "Frecuencia\n",
      "La frecuencia se refiere al n√∫mero\n",
      "de comidas que haces al d√≠a. Tradi¬≠\n",
      "cionalmente se recomendaba ha¬≠\n",
      "cer muchas peque√±as comidas, al\n",
      "creerse que esto reduc√≠a el hambre y\n",
      "manten√≠a el metabolismo elevado.\n",
      "La evidencia cient√≠fica m√°s reciente\n",
      "desmiente estas creencias, y hacer\n",
      "m√°s comidas suele resultar en m√°s comes a lo largo del d√≠a que el n√∫¬≠\n",
      "calor√≠as ingeridas y m√°s ganancia de mero de comidas en las que distri¬≠\n",
      "peso. De hecho, muchas personas buyes esa ingesta total. Por simpli¬≠\n",
      "logran buenos resultados al reducir cidad, recomiendo empezar por tres\n",
      "el n√∫mero de comidas, incluyendo grandes comidas al d√≠a, redu ciendo\n",
      "incluso distintos esquemas de ayuno los snacks, pero puedes adaptar la fre¬≠\n",
      "intermitente. cuencia y horarios a tus prefer encias.\n",
      "En cualquier caso, debes enten¬≠ Evidentemente, si est√°s intentando\n",
      "der que es un aspecto secunda rio. ganar peso, seguramente debas ha¬≠\n",
      "Es mucho m√°s importante lo que cer m√°s comidas la mayor√≠a de d√≠as.\n",
      "Suplementos\n",
      "La comida aporta toda la energ√≠a y\n",
      "nutrientes que necesitas. Si haces\n",
      "bien todo lo anterior, no necesitas\n",
      "ninguna suplementaci√≥n.\n",
      "Dicho esto, hay suplementos que\n",
      "pueden ayudar. La prote√≠na de suero\n",
      "y la creatina son mis favoritos, pero\n",
      "hay otros que pueden ayudarte seg√∫n\n",
      "tus objetivos principales. En esta p√°¬≠\n",
      "gina encontrar√°s los m√°s recomen¬≠\n",
      "dables y todo su detalle.\n",
      "ALIMENTOS\n",
      "SUPLEMENTOS\n",
      "FRECUENCIA\n",
      "MACRONUTRIENTES\n",
      "CALOR√çAS\n",
      "ALIMENTOS\n",
      "Nutrici√≥n\n",
      "SUPLEMENTOS\n",
      "FRECUENCIA\n",
      "MACRONUTRIENTES\n",
      "CALOR√çAS\n",
      "Nutrici√≥n El Manual Revolucionario 11\n",
      "Principios para perder peso. Antes de\n",
      "pasar a los men√∫s de ejemplo, revise-\n",
      "mos algunos principios si tu objetivo es\n",
      "perder grasa corporal.\n",
      "01 Incluye una porci√≥n de prote√≠na de 04 Las frutas son buenas, pero no de-\n",
      "calidad en cada comida. Es el macro¬≠ bes excederte si tu objetivo es perder\n",
      "nutriente m√°s saciante y m√°s dif√≠cil¬≠ grasa. Un par de porciones al d√≠a,\n",
      "mente convertible en grasa corporal. por ejemplo a modo de postre, es\n",
      "Adem√°s ayuda a minimizar la p√©rdi¬≠ suficiente. Limita los zumos aunque\n",
      "da muscular cuando est√°s en d√©ficit sean naturales.\n",
      "cal√≥rico.\n",
      "05 Reduce los almidones como ce-\n",
      "02 Come mucha verdura, idealmente reales, tub√©rculos y legumbres. Los\n",
      "en cada comida. Puede ser cruda, co¬≠ puedes usar como acompa√±antes,\n",
      "cinada o en forma de crema. Adem√°s idealmente no como plato principal.\n",
      "de aportar saciedad, su fibra mejo¬≠\n",
      "rar√° tu microbiota, importante a la 06 Elimina az√∫cares y harinas, o\n",
      "hora de regular tu entorno hormonal. lim√≠talos a ocasiones especiales.\n",
      "03 Incluye grasas saludables cada 07 Intenta hacer 3 grandes comidas\n",
      "d√≠a. Las grasas aumentan la sensa¬≠ en vez de estar picando cada pocas\n",
      "ci√≥n de saciedad entre comidas y horas.\n",
      "son necesarias para la producci√≥n de\n",
      "ciertas hormonas. Prioriza fuentes 08 Evita estar mucho tiempo en\n",
      "de grasa como los huevos (la yema), d√©ficit cal√≥rico para no ralentizar\n",
      "aguacates, pescados, frutos secos y tu meta bolismo. De vez en cuando,\n",
      "l√°cteos enteros fermentados. incluye una recarga.\n",
      "09 Eleva la actividad f√≠sica. El ejerci¬≠\n",
      "cio magnifica el efecto de la dieta.\n",
      "Nutrici√≥n El Manual Revolucionario 12\n",
      "Ejemplos de men√∫s\n",
      "para perder peso\n",
      "D√≠a 1 D√≠a 2 D√≠a 3\n",
      "desa Revuelto de dos Yogur griego con Dos huevos fritos\n",
      "‚Äîyuno huevos con verdura frutos rojos y nue c es con jam√≥n\n",
      "‚Äî ‚Äî ‚Äî\n",
      "Caf√© / T√© con un Caf√© / T√© con un Caf√© / T√© con un\n",
      "chorrito de leche chorrito de leche chorrito de leche\n",
      "‚Äî ‚Äî\n",
      "Una manzana y Una naranja y\n",
      "6 nueces * 6 avellanas *\n",
      "comida Filete con ensalada y Pechuga de pollo a la Pescado a la plancha\n",
      "media patata cocida plancha con tomate, con ensalada y un\n",
      "‚Äî pimientos asados y poco de arroz\n",
      "Dos onzas de aguacate ‚Äî\n",
      "chocolate oscuro ‚Äî Un yogur con\n",
      ">80% Una pera y almendras fileteadas\n",
      "6 almendras *\n",
      "cena Ensalada de Ensalada verde con Crema de espinacas\n",
      "espinacas, reques√≥n at√∫n de lata ‚Äî\n",
      "y salm√≥n ahumado ‚Äî Un pu√±ado de frutos\n",
      "‚Äî Dos onzas de secos\n",
      "Una fruta ** chocolate oscuro\n",
      ">80%\n",
      "* Puedes comer otra fruta que te guste m√°s, lo mismo con los frutos secos.\n",
      "** De vez en cuando puedes reemplazar la fruta o el chocolate oscuro por\n",
      "otro postre, como Pan de pl√°tano.\n",
      "Nutrici√≥n El Manual Revolucionario 13\n",
      "¬øNecesitas un\n",
      "plan de choque?\n",
      "Soy m√°s partidario de los cambios\n",
      "lentos, adoptando gradualmente\n",
      "nuevos h√°bitos de alimentaci√≥n que\n",
      "puedas mantener a lo largo del tiem¬≠\n",
      "po. Este es precisamente el enfoque\n",
      "de El Plan Revolucionario.\n",
      "Sin embargo, en ciertos casos tiene\n",
      "sentido usar un enfoque m√°s dr√°sti¬≠\n",
      "co. Adem√°s, la r√°pida p√©rdida de\n",
      "grasa inicial aumenta la motivaci√≥n,\n",
      "mejorando la adherencia posterior.\n",
      "Para estos casos propongo realizar\n",
      "un ciclo corto de dieta cetog√©nica,\n",
      "que adem√°s de potenciar la p√©rdida\n",
      "de grasa aporta distintos benefi¬≠\n",
      "cios para la salud. Si te interesa este\n",
      "tema, echa un vistazo al programa\n",
      "De Cero a Ceto.\n",
      "Nutrici√≥n El Manual Revolucionario 14\n",
      "Principios para ganar volumen.\n",
      "Si te interesa ganar volumen o eres un\n",
      "deportista con alto gasto energ√©tico,\n",
      "tendr√°s sin duda que comer m√°s. Algu-\n",
      "nas recomendaciones para este caso:\n",
      "01 Incluye una buena porci√≥n de 06 Seguramente deber√°s comer m√°s\n",
      "prote√≠na en cada comida. de tres veces al d√≠a, a√±adiendo por\n",
      "ejemplo un par de snacks. Igualmente\n",
      "02 Aumenta las grasas saludables. recomiendo realizar alg√∫n ayuno in¬≠\n",
      "A√±ade por ejemplo m√°s aceite de oli¬≠ termitente cada cierto tiempo.\n",
      "va y aguacate a las ensaladas. Come\n",
      "m√°s frutos sec os, huevos, crema de 07 Para asegurar que la mayor√≠a de\n",
      "almendras etc. calor√≠as adicionales se usan para\n",
      "ganar m√∫sculo debes asegurar que\n",
      "03 Incorpora al menos un par de por- entrenas fuerza, al menos dos o tres\n",
      "ciones generosas de almid√≥n al d√≠a: veces a la semana.\n",
      "tub√©rculos, legumbres o cereales.\n",
      "04 Eleva el consumo de frutas, al\n",
      "menos 3¬≠4 al d√≠a. Adem√°s, despu√©s\n",
      "de entrenar la fruta puede ayudar a\n",
      "recargar gluc√≥geno hep√°tico.\n",
      "05 Incluye l√°cteos enteros con fre-\n",
      "cuencia. Si no los toleras bien puedes\n",
      "usar bebidas vegetales.\n",
      "Nutrici√≥n El Manual Revolucionario 15\n",
      "Ejemplos de men√∫s\n",
      "para ganar volumen\n",
      "D√≠a 1 D√≠a 2 D√≠a 3\n",
      "Revuelto de 3¬≠4 Avena cocida con Guiso de lentejas\n",
      "desa huevos con verdura, miel, nueces y frutos ‚Äî\n",
      "‚Äîyuno jam√≥n y queso rojos Caf√© / T√© con leche\n",
      "‚Äî ‚Äî ‚Äî\n",
      "Caf√© / T√© con leche Caf√© / T√© con leche Una fruta y un pu√±a¬≠\n",
      "‚Äî ‚Äî do de frutos secos\n",
      "Dos frutas y un pu√±a¬≠ Tres onzas de choco¬≠\n",
      "do de frutos secos late oscuro >80%\n",
      "Filete con ensalada y Pechuga de pollo a la Pescado a la plancha\n",
      "comida dos patatas cocidas o plancha, acompa√±a¬≠ con ensalada y una\n",
      "al horno da de pl√°tano macho taza de arroz\n",
      "‚Äî horneado con miel y ‚Äî\n",
      "Pan de pl√°tano con canela Un yogur con\n",
      "chispas de chocolate ‚Äî pl√°tano y almendras\n",
      "y nueces Yogur griego con fileteadas\n",
      "frutos rojos y nueces\n",
      "cena Ensalada Griega con Ensalada de garban¬≠ Crema de ajo puerro\n",
      "salm√≥n ahumado zos y at√∫n de lata, y patatas\n",
      "‚Äî con medio aguacate ‚Äî\n",
      "Una fruta ‚Äî Una fruta\n",
      "‚Äî Una fruta ‚Äî\n",
      "Pan de pl√°tano con Tres onzas de choco¬≠\n",
      "chispas de chocolate late oscuro >80%\n",
      "y nueces\n",
      "snack / Selecciona dos al d√≠a: Selecciona dos al d√≠a: Selecciona dos al d√≠a:\n",
      "postre Queso / Fruta / Queso / Fruta / Queso / Fruta /\n",
      "adicional Yogur / Pu√±ado de Yogur / Pu√±ado de Yogur / Pu√±ado de\n",
      "frutos secos / frutos secos / frutos secos /\n",
      "Chocolate negro Chocolate negro Chocolate negro\n",
      "Nutrici√≥n El Manual Revolucionario 16\n",
      "En muchos casos, tendr√°s que comer\n",
      "m√°s de lo que te pide el cuerpo. Si\n",
      "comiendo hasta la saciedad no subes\n",
      "de peso, tendr√°s que ir m√°s all√°. Una\n",
      "buena opci√≥n para ingerir m√°s calo¬≠\n",
      "r√≠as saludables con poco esfuerzo es\n",
      "un batido de prote√≠na. Por ejemplo\n",
      "el siguiente batido es uno de mis fa¬≠\n",
      "voritos, y tiene m√°s de 600 calor√≠as.\n",
      "Batido de prote√≠na,\n",
      "pl√°tano y frutos\n",
      "del bosque\n",
      "¬∑ Un scoop (25-30g) de prote√≠na\n",
      "de suero. Ver marcas.\n",
      "¬∑ Un vaso de leche entera.\n",
      "¬∑ Un yogur o 125g de k√©fir.\n",
      "¬∑ Dos pl√°tanos.\n",
      "¬∑ Un pu√±ado de fresas o frutos\n",
      "rojos congelados.\n",
      "¬∑ Una cucharada de crema de\n",
      "almendra o cacahuete.\n",
      "¬∑ Canela.\n",
      "Entrenamiento El Manual Revolucionario 17\n",
      "ENTRENAMIENTO\n",
      "Conceptos de entrenamiento. Para\n",
      "nuestros ancestros, el movimiento era\n",
      "obligatorio, y la comida era la recom-\n",
      "pensa por el esfuerzo.\n",
      "Adem√°s, el ejercicio no es solo una Nuestro cuerpo se beneficia de in¬≠\n",
      "forma de quemar calor√≠as. Nuestra corporar multitud de actividades, y\n",
      "biolog√≠a est√° dise√±ada para realizar la siguiente pir√°mide intenta reflejar\n",
      "actividad f√≠sica, y su ausencia nos la importancia relativa de cada una\n",
      "debilita. Lo que no usas lo pierdes. de ellas.\n",
      "‚Äî\n",
      "M√°xima\n",
      "intensidad\n",
      "‚Äî\n",
      "Intensidad\n",
      "media\n",
      "‚Äî\n",
      "Baja\n",
      "intensidad\n",
      "Entrenamiento El Manual Revolucionario 18\n",
      "En la base est√°n las actividades de mejor forma de replicar este compor¬≠\n",
      "baja intensidad, que podr√≠amos re¬≠ tamiento es con la llamada caliste¬≠\n",
      "sumir como ‚Äòmu√©vete m√°s‚Äô. En gener¬≠ nia, basada en ejercicios corporales.\n",
      "al, la mejor actividad es simplemente Es precisamente lo que detallo en el\n",
      "caminar, intentando llegar a los programa Desencadenado.\n",
      "8.000‚Äî10.000 pasos diarios. Multitud\n",
      "de estudios confirman que las perso¬≠ Adem√°s, nuestros ancestros deb√≠an\n",
      "nas que caminan m√°s, viven m√°s. cargar objetos pesados y realizar\n",
      "esfuerzos m√°ximos, esprintando\n",
      "Caminar es por tanto muy impor¬≠ por ejemplo de vez en cuando. Estas\n",
      "tante, pero no es suficiente. Debes son las actividades que situamos en\n",
      "trabajar todo tu cuerpo e incluir la punta de la pir√°mide. Generan un\n",
      "movimientos m√°s complejos. Por eso est√≠mulo especial que fortalecen en\n",
      "incorporamos en el siguiente nivel mayor medida nuestro cuerpo. Como\n",
      "actividades de m√°s intensidad, como siempre, debes empezar poco a poco\n",
      "correr de vez en cuando y, sobre todo, y aumentar la intensidad de mane¬≠\n",
      "entrenar fuerza usando nuestro ra gradual, pero te sorprender√°s de\n",
      "propio cuerpo. Nuestros ancestros los cambios que ves en tu cuerpo en\n",
      "ten√≠an que escalar y pelear, moviendo poco tiempo.\n",
      "su cuerpo por entornos diversos. La\n",
      "Entrenamientos\n",
      "Se basan en el concepto de circuitos,\n",
      "b√°sicos con el cuerpo\n",
      "donde debes realizar varias rondas\n",
      "de ciertos ejercicios. Tras finalizar\n",
      "Recomiendo empezar por el entre¬≠ las repeticiones indicadas de cada\n",
      "namiento con el propio cuerpo. No ejercicio, pasas al siguiente, sin des¬≠\n",
      "solo por su efectividad, sino tambi√©n canso. Descansa un par de minutos\n",
      "por su simplicidad. No necesitas entre rondas.\n",
      "equipamiento, lo puedes realizar en\n",
      "cualquier lugar y en poco tiempo.\n",
      "No importan tanto las sesiones in¬≠\n",
      "dividuales que haces como el pro¬≠\n",
      "grama global que sigues, pero te\n",
      "muestro dos sesiones de ejemplo\n",
      "para distintos niveles.\n",
      "Entrenamiento El Manual Revolucionario 19\n",
      "NIVEL B√ÅSICO\n",
      "3 Rondas Notas\n",
      "20 sentadillas ¬∑ En la sentadilla, baja todo lo que pue¬≠\n",
      "das, sin llegar a despegar los talones\n",
      "10 flexiones del suelo. Si lo necesitas, ag√° rrate de\n",
      "una mesa.\n",
      "20 desplantes ‚Äî 10 con cada pierna ¬∑ Si no puedes hacer flexiones sobre el\n",
      "suelo, apoya las manos en una mesa.\n",
      "30 segundos de plancha ¬∑ En los desplantes, intenta que ambas\n",
      "rodillas formen un √°ngulo recto al\n",
      "30 segundos corriendo en el sitio final del movimiento.\n",
      "‚Äî o saltando comba ¬∑ En la plancha, aseg√∫rate de contraer\n",
      "al m√°ximo los abdominales, evitando\n",
      "que descienda tu cadera.\n",
      "Si te resulta muy duro, haz solo dos rondas o des- ‚Äî\n",
      "cansa m√°s entre cada ronda. Si te resulta f√°cil, Lee este art√≠culo para tener m√°s detalle\n",
      "a√±ade una ronda adicional y reduce los descansos. sobre c√≥mo entrenar en casa.\n",
      "NIVEL INTERMEDIO\n",
      "4 Rondas Notas\n",
      "8 dominadas ¬∑ Para hacer dominadas necesitar√°s\n",
      "una barra, como √©sta, si entrenas en\n",
      "15 flexiones casa. Si te resulta muy dif√≠cil, coloca\n",
      "una silla bajo la barra y ay√∫date apo¬≠\n",
      "30 sentadillas yando un pie.\n",
      "¬∑ Las planchas laterales trabajan es¬≠\n",
      "40 escaladores de monta√±a pecialmente los oblicuos, y para\n",
      "realizarlas debes apoyarte sobre el\n",
      "30 segundos de plancha lateral antebrazo con el cuerpo perpendicu¬≠\n",
      "‚Äî por cada lado lar al suelo. Cambia de lado tras los\n",
      "treinta segundos, antes de pasar al\n",
      "45 segundos corriendo en el sitio siguiente ejercicio.\n",
      "‚Äî o saltando comba\n",
      "Otros Aspectos El Manual Revolucionario 20\n",
      "OTROS ASPECTOS\n",
      "Ve m√°s all√°. Nos hemos centrado\n",
      "en conceptos b√°sicos de nutrici√≥n y\n",
      "entrenamiento, pero tu salud depende\n",
      "de otros muchos aspectos.\n",
      "‚Äî\n",
      "Pincha en cualquiera de\n",
      "los iconos siguientes para\n",
      "obtener m√°s informaci√≥n\n",
      "P√©rdida Ganancia Sue√±o y Gu√≠a de\n",
      "sobre el tema que te\n",
      "de Grasa Muscular Descanso Suplementos\n",
      "interese.\n",
      "Salud Fortaleza En Vuelta a la\n",
      "Intestinal Mental Femenino Naturaleza\n",
      "√önete a nuestra tribu\n",
      "Puedes mejorar tu salud por tu cuen¬≠\n",
      "ta, pero es m√°s f√°cil si cuentas con\n",
      "‚Äî\n",
      "apoyo. Las grandes cosas se con¬≠\n",
      "Nunca dudes que un\n",
      "siguen casi siempre con otros. Los\n",
      "peque√±o grupo de\n",
      "programas que ofrecemos son un\n",
      "personas inteligentes y\n",
      "buen comienzo. Cada uno de ellos\n",
      "comprometidas pueden\n",
      "tiene su comunidad privada con\n",
      "cambiar el mundo. De\n",
      "miles de seguidores, que te ofrecer√°n\n",
      "hecho, es lo √∫nico capaz\n",
      "su experiencia y su ayuda. Esperamos\n",
      "de cambiarlo.\n",
      "verte all√≠.\n",
      "‚Äî\n",
      "Margaret Mead Nos puedes seguir tambi√©n en\n",
      "Instagram, Facebook, YouTube\n",
      "y Twitter.\n",
      "Recetas El Manual Revolucionario 21\n",
      "RECETAS\n",
      "Ensalada Verde\n",
      "01\n",
      "Porciones: 1\n",
      "Ingredientes Equipo y utensilios\n",
      "¬∑ 20g de lechuga, 15g de r√∫cula ¬∑ Bol grande\n",
      "¬∑ 20g de espinacas ¬∑ Tenedor o pinza de cocina\n",
      "¬∑ 15g de kale\n",
      "¬∑ 15ml de aceite de oliva (1 cuch.) Preparaci√≥n\n",
      "¬∑ 5ml de vinagre (opcional) ¬∑ Lavar y cortar las hojas de lechuga,\n",
      "¬∑ Sal espinaca y kale (salvo que compres\n",
      "bolsas listas para servir).\n",
      "Elaboraci√≥n Observaciones\n",
      "¬∑ Mezclar en un bol todas las verduras ¬∑ Si no se va a consumir la ensala-\n",
      "verdes. Agregar el aceite de oliva, el da inmediatamente se recomienda\n",
      "vinagre y la sal. Remover todo con no ade rezarla. Se sugiere preparar\n",
      "un tenedor o pinzas. el ade rezo aparte, considerando 1\n",
      "¬∑ Servir. porci√≥n de vinagre por 3 de aceite\n",
      "de oliva.\n",
      "Variantes\n",
      "1 Agregar otros tipos de verduras,\n",
      "como endivias, can√≥nigos, berros,\n",
      "escarola, etc.\n",
      "2 Cambiar el aderezo o agregar frutos\n",
      "secos.\n",
      "Recetas El Manual Revolucionario 22\n",
      "Ensalada Griega\n",
      "02\n",
      "Porciones: 1\n",
      "Ingredientes Equipo y utensilios\n",
      "¬∑ 150g de tomate (uno mediano) ¬∑ Bol peque√±o\n",
      "¬∑ 200g de pepino (1/2 pepino) ¬∑ Bol mediano\n",
      "¬∑ 25g de cebolla morada (1/4 de ¬∑ Tenedor o pinzas\n",
      "cebolla)\n",
      "¬∑ 100g de pimiento verde Preparaci√≥n\n",
      "¬∑ 10 aceitunas negras ¬∑ Cortar el tomate en octavos\n",
      "¬∑ 30-50g de queso feta ¬∑ Cortar el pepino en cuadros,\n",
      "¬∑ 1g de or√©gano tama√±o bocado\n",
      "¬∑ 15ml de aceite de oliva ¬∑ Cortar el pimiento verde en trozos\n",
      "¬∑ 5ml de vinagre de vino tama√±o bocado\n",
      "¬∑ Sal y pimienta al gusto ¬∑ Cortar finamente la cebolla\n",
      "¬∑ 10g de nueces (o pi√±ones) ¬∑ Cortar o deshacer a mano el queso\n",
      "Elaboraci√≥n Variantes\n",
      "1 Mezclar en el bol peque√±o el aceite de ¬∑ Utilizar la variedad de tomate o acei-\n",
      "oliva, el vinagre, la sal y el or√©gano. tunas que prefieras. Se puede uti-\n",
      "2 Mezclar en el bol mediano el pepino, lizar otros tipos de queso, por ejem-\n",
      "la cebolla y las aceitunas. Agregar el plo, queso azul.\n",
      "aderezo y remover bien con un tene-\n",
      "dor o con pinzas.\n",
      "3 Agregar el tomate y el queso.\n",
      "4 Esparcir por encima las nueces, el\n",
      "or√©gano y la pimienta.\n",
      "Recetas El Manual Revolucionario 23\n",
      "Guiso de lentejas\n",
      "03\n",
      "Porciones: 2\n",
      "Ingredientes Equipo y utensilios\n",
      "¬∑ 200g de lentejas crudas ¬∑ Bol\n",
      "¬∑ 750ml de agua ¬∑ Olla con tapa (mediana-grande)\n",
      "¬∑ 2 dientes de ajo (10g) ¬∑ Sart√©n antiadherente\n",
      "¬∑ 1 hoja de laurel\n",
      "¬∑ 15ml de aceite de oliva Preparaci√≥n\n",
      "¬∑ 200g de cebolla blanca ¬∑ Dejar en remojo las lentejas en agua\n",
      "¬∑ 0.3g de comino en polvo (opcional) tibia durante varias horas y escurrir\n",
      "¬∑ 0.5g de piment√≥n dulce (opcional) ¬∑ Lavar las lentejas en agua corriente\n",
      "¬∑ 100g de espinacas frescas (o kale) ¬∑ Pelar y machacar los dientes de ajo\n",
      "¬∑ Sal al gusto ¬∑ Cortar finamente la cebolla\n",
      "¬∑ Cortar las hojas de espinacas\n",
      "Elaboraci√≥n\n",
      "1 Colocar las lentejas previamente remoja- tos m√°s. Ajustar la sal y la cantidad de\n",
      "das y escurridas en una olla. Cubrir con el l√≠quido al gusto.\n",
      "agua, agregar el ajo machacado, el comino, 7 Servir calientes o tibias con un chorrito de\n",
      "la hoja de laurel y un poco de sal. aceite de oliva.\n",
      "2 Llevar a hervor y luego ajustar la temperatura\n",
      "hasta que solamente burbujee ligeramente. Variantes\n",
      "3 Tapar la olla y cocinar, moviendo las lente- ¬∑ Se puede a√±adir al sofrito otras verduras u\n",
      "jas ocasionalmente. A√±adir m√°s agua si es otras especias (estrag√≥n y una cucharada\n",
      "necesario para que las lentejas permanez- de mostaza). Tambi√©n se puede agregar\n",
      "can cubiertas. Cocinar entre 25 y 35 minu- prote√≠na como almejas o jam√≥n.\n",
      "tos (ver observaciones). ¬∑ Utilizar, para finalizar, hierbas frescas\n",
      "4 Probar las lentejas y verificar que hayan como perejil, cilantro o cebollino.\n",
      "perdido su dureza pero que no est√©n muy ¬∑ Se puede escurrir toda el agua en el paso 4,\n",
      "blandas para que no se deshagan. Bajar el esperar que enfr√≠en y a√±adir a ensaladas.\n",
      "fuego al m√≠nimo, sacar la hoja de laurel y el\n",
      "ajo y tapar nuevamente. Observaciones\n",
      "5 Calentar la sart√©n a fuego medio con el aceite ¬∑ Cuidar la cocci√≥n de las lentejas y confiar\n",
      "de oliva. Sofre√≠r la cebolla de 1 a 2 minutos, m√°s en el tacto de la boca que en el ti-\n",
      "agregar el piment√≥n en polvo y remover. empo propuesto de cocci√≥n, ya que este\n",
      "6Agregar el sofrito a las lentejas y remover. tiempo var√≠a en funci√≥n del tipo de lenteja\n",
      "A√±adir las hojas de espinacas. Subir la y la intensidad del fuego.\n",
      "temperatura y cocinar tapado por 10 minu-\n",
      "Recetas El Manual Revolucionario 24\n",
      "Crema de espinacas\n",
      "04\n",
      "Porciones: 2\n",
      "Ingredientes Equipo y utensilios\n",
      "¬∑ 400g de espinacas ¬∑ Olla con tapa (mediana o grande)\n",
      "¬∑ 200g de calabac√≠n (uno mediano) ¬∑ Licuadora\n",
      "¬∑ 20g de mantequilla sin sal\n",
      "¬∑ 50g de cebolla blanca Preparaci√≥n\n",
      "¬∑ 2 dientes de ajo ¬∑ Cortar la espinaca en trozos\n",
      "¬∑ 350ml de caldo de pollo ¬∑ Cortar el calabac√≠n en trozos\n",
      "(o simplemente agua) ¬∑ Cortar finamente la cebolla\n",
      "¬∑ 40ml de nata l√≠quida Sal y pimienta ¬∑ Cortar finamente el ajo\n",
      "al gusto\n",
      "Elaboraci√≥n\n",
      "1 Colocar una olla grande a fuego medio y 6Retirar del fuego (si se va a usar nata l√≠qui-\n",
      "derretir la mantequilla. da se a√±ade templada y en este momento).\n",
      "2 Agregar la cebolla y el ajo. Cocinar movien- 7 Servir.\n",
      "do regularmente hasta que los vegetales\n",
      "est√©n blandos y transl√∫cidos. Agregar el Variantes\n",
      "calabac√≠n y las espinacas. Saltear todo ¬∑ Se puede sustituir la nata l√≠quida por un\n",
      "junto por un minuto. poco de leche y mantequilla.\n",
      "3 A√±adir el caldo de pollo (o simplemente ¬∑ Se pueden a√±adir otras verduras verdes\n",
      "agua). Llevar todo a hervor, luego bajar la como esp√°rragos y br√≥coli para dar m√°s\n",
      "temperatura del fuego hasta que el l√≠quido consistencia.\n",
      "quede burbujeando ligeramente. Tapar y coci-\n",
      "nar por 10 minutos a fuego lento o hasta que Observaciones\n",
      "el calabac√≠n y las espinacas est√©n blandos. ¬∑ Por seguridad, evitar licuar mientras el\n",
      "4 Apagar el fuego y dejar enfriar un poco. caldo est√© muy caliente y no llenar el vaso\n",
      "Pasar todo a la licuadora. Licuar (ver ob- de la licuadora m√°s de la mitad.\n",
      "servaciones). ¬∑ El caldo de pollo puede ser hecho en casa\n",
      "5 Regresar la crema a la olla. Probar y ajus- o comprado. Tambi√©n se puede reemplazar\n",
      "tar la sal. Si la crema qued√≥ muy l√≠quida por caldo de verduras.\n",
      "dejar hervir unos minutos y si est√° muy\n",
      "espesa agregar m√°s caldo de pollo o agua\n",
      "hasta lograr la consistencia deseada.\n",
      "Recetas El Manual Revolucionario 25\n",
      "Crema de ajo puerro y patatas\n",
      "05\n",
      "Porciones: 2\n",
      "Ingredientes Equipo y utensilios\n",
      "¬∑ 600g de ajo puerro (2 medianos) ¬∑ Olla con tapa\n",
      "¬∑ 400g de patatas ¬∑ Licuadora\n",
      "¬∑ 20g de mantequilla sin sal\n",
      "¬∑ 50g de cebolla blanca Preparaci√≥n\n",
      "¬∑ 1 diente de ajo (5g) ¬∑ Cortar el ajo puerro en ruedas finas,\n",
      "¬∑ 750ml de caldo de pollo (o agua) descartando la parte verde\n",
      "¬∑ 1 hoja de laurel ¬∑ Pelar y cortar las patatas en trozos\n",
      "¬∑ Sal y pimienta al gusto peque√±os de similar tama√±o\n",
      "¬∑ 100ml de crema de leche (opcional) ¬∑ Cortar finamente la cebolla\n",
      "¬∑ 5g de perejil ¬∑ Cortar finamente el ajo\n",
      "¬∑ Cortar finamente el perejil\n",
      "¬∑ Cortar finamente el ajo\n",
      "Elaboraci√≥n\n",
      "1 Colocar una olla grande a fuego medio y 6Retirar del fuego, y mezclar la crema de\n",
      "derretir la mantequilla. leche templada (no fr√≠a).\n",
      "2 Agregar el ajo puerro, la cebolla y el ajo. 7 Servir y agregar por encima el perejil.\n",
      "Cocinar moviendo regularmente hasta que\n",
      "los vegetales est√©n blandos y transl√∫cidos. Variantes\n",
      "3 Agregar las patatas, el laurel, el caldo de ¬∑ Sustituir la crema de leche por un poco de\n",
      "pollo (o agua) y ajustar la sal. Llevar todo leche y mantequilla.\n",
      "a hervor, luego bajar la temperatura del ¬∑ Se puede consumir como una sopa de ver-\n",
      "fuego hasta que quede burbujeando ligera- duras sin licuar.\n",
      "mente y tapar. Cocinar al menos 20 minu- ¬∑ Utilizar otras hierbas frescas como ceboll√≠n\n",
      "tos o hasta que las patatas est√©n blandas. o albahaca.\n",
      "4 Apagar el fuego, dejar enfriar y sacar la hoja\n",
      "de laurel. Pasar todo a la licuadora y licuar. Acompa√±ar\n",
      "5 Regresar la crema a la olla. Probar y ajus- ¬∑ Se puede servir con queso rallado o almen-\n",
      "tar la sal. Si la crema qued√≥ muy l√≠quida dras tostadas y cortadas.\n",
      "dejar hervir unos minutos y si est√° muy\n",
      "espesa agregar agua hasta lograr la consis-\n",
      "tencia deseada.\n",
      "Recetas El Manual Revolucionario 26\n",
      "Avena cocida con miel,\n",
      "06\n",
      "nueces y frutos rojos\n",
      "Porciones: 2\n",
      "Ingredientes Equipo y utensilios\n",
      "¬∑ 100g de avena en hojuelas ¬∑ Bol o recipiente\n",
      "¬∑ 250ml de agua ¬∑ Olla (peque√±a o mediana)\n",
      "¬∑ 400ml de leche (o agua) ¬∑ Cuchara o paleta\n",
      "¬∑ 60g de miel\n",
      "¬∑ 10ml de esencia de vainilla (opcional) Preparaci√≥n\n",
      "¬∑ 1 ramita de canela o 2g en polvo ¬∑ Dejar en remojo la avena la noche\n",
      "¬∑ 25g-30g de nueces picadas antes (opcional)\n",
      "¬∑ 120g de ar√°ndanos, frambuesas o ¬∑ Cortar las nueces en trozos\n",
      "fresas ¬∑ Cortar las fresas (si se usan)\n",
      "¬∑ Pizca de sal ¬∑ Cortar finamente el ajo\n",
      "Elaboraci√≥n Variantes\n",
      "1 Colocar la avena y el agua en un re- ¬∑ Cambiar la leche por leche de coco,\n",
      "cipiente. Si es posible, dejar la avena almendras o simplemente agua.\n",
      "en remojo entre 7 y 12 horas en la ¬∑ Utilizar variedad de frutos secos\n",
      "nevera. Escurrir antes de cocinar. como avellanas, almendras, coco\n",
      "2 Colocar en una olla a fuego medio- rallado, etc. Otras frutas como higos\n",
      "bajo la avena, la leche, la miel, la o pl√°tanos.\n",
      "canela y la pizca de sal. ¬∑ Agregar cacao en polvo o cuadritos\n",
      "3 Remover con una paleta hasta di- de chocolate oscuro.\n",
      "solver la miel. Cocinar hasta que\n",
      "muestre un primer hervor y espese\n",
      "un poco.\n",
      "4 Agregar las gotas de vainilla. Re-\n",
      "mover bien y probar para ajustar el\n",
      "dulzor al gusto. Retirar del fuego.\n",
      "5 Servir en un bol o plato hondo y\n",
      "agregar por encima las nueces pica-\n",
      "das y los frutos rojos.\n",
      "Recetas El Manual Revolucionario 27\n",
      "Pl√°tano macho horneado\n",
      "07\n",
      "con miel y canela\n",
      "Porciones: 2\n",
      "Ingredientes Equipo y utensilios\n",
      "¬∑ 1 pl√°tano macho maduro ¬∑ Bol peque√±o\n",
      "¬∑ 5g de mantequilla ¬∑ Bandeja para hornear\n",
      "¬∑ 2g de canela ¬∑ Papel para hornear\n",
      "¬∑ 10g de miel (opcional) ¬∑ Brocha de cocina (opcional)\n",
      "Preparaci√≥n\n",
      "¬∑ Pelar el pl√°tano\n",
      "Elaboraci√≥n Variantes\n",
      "1 Precalentar el horno a 200¬∞C y ¬∑ Omitir la miel si el pl√°tano est√° su-\n",
      "preparar la bandeja de horno (si no ficientemente maduro. Tambi√©n se\n",
      "es antiadherente se sugiere colocar puede hornear cortado en ruedas.\n",
      "papel para hornear).\n",
      "2 Derretir en un bol la mantequilla e Observaciones\n",
      "inmediatamente agregar la miel y la ¬∑ El pl√°tano macho est√° maduro\n",
      "canela. Mezclar todo bien. cuando la piel est√° muy amarrilla y\n",
      "3 Colocar el pl√°tano en la bandeja cubierta de manchas negras\n",
      "para hornear y con una brocha de\n",
      "cocina o con la mano untarlo con la\n",
      "mantequilla, la miel y la canela.\n",
      "4 Hornear por 30 minutos o hasta que\n",
      "el pl√°tano este suave y dorado.\n",
      "Recetas El Manual Revolucionario 28\n",
      "Pan de pl√°tano con chispas\n",
      "08\n",
      "de chocolate y nueces\n",
      "Porciones: 2\n",
      "Ingredientes ¬∑ 30g de miel (tambi√©n se puede\n",
      "¬∑ 2 pl√°tanos maduros usar stevia o eritritol)\n",
      "¬∑ 2 huevos\n",
      "¬∑ 30g de mantequilla sin sal E¬∑ quipo y utensilios\n",
      "¬∑ 20ml de aceite de coco ¬∑ Molde antiadherente para pastel\n",
      "(1 ¬Ω cucharada sopera) (de aluminio, silic√≥n o Pirex)\n",
      "¬∑ 10ml de yogur natural sin az√∫car ¬∑ Bol peque√±o\n",
      "(opcional) ¬∑ Licuadora\n",
      "¬∑ 35g de harina de coco\n",
      "¬∑ 2g de canela Preparaci√≥n\n",
      "¬∑ 1g de bicarbonato de sodio ¬∑ Derretir el aceite de coco y la\n",
      "¬∑ 1g de polvo de hornear (royal) mantequilla en el microondas\n",
      "¬∑ 5ml de esencia de vainilla ¬∑ Cortar el pl√°tano en rodajas\n",
      "¬∑ 1g de sal ¬∑ Cortar el chocolate en pedacitos\n",
      "¬∑ 60g de chocolate 85% - 90%. peque√±os\n",
      "Elaboraci√≥n\n",
      "1 Precalentar el horno a 200¬∞C. 6Vaciar la mezcla en el molde y hornear por\n",
      "2 Preparar el molde. Colocar papel para hor- 20 minutos (ver observaciones).\n",
      "near en el fondo o engrasar el recipiente 7 Sacar del horno y dejar enfriar un poco\n",
      "con un poco de mantequilla y espolvorear antes de desmoldarla.\n",
      "un poquito de harina de coco.\n",
      "3 Licuar los pl√°tanos, los huevos, la mante- Variantes\n",
      "quilla, el aceite de coco, el yogur, el ex- ¬∑ Utilizar otros frutos secos como avellanas,\n",
      "tracto de vainilla y la miel. almendras, etc.\n",
      "4 Mezclar en el bol la harina de coco, la\n",
      "canela, el bicarbonato, el polvo de hornear Acompa√±ar\n",
      "y la sal. Agregar a la licuadora y procesar ¬∑ Con caf√© o t√© para el desayuno o como postre.\n",
      "nuevamente hasta que todos los ingredi-\n",
      "entes est√©n integrados. Observaciones\n",
      "5 Agregar el chocolate y las nueces. Remo- ¬∑ Se puede verificar que el pan est√° listo si\n",
      "verlos con una cuchara en la mezcla (no al introducir un palillo de madera √©ste sale\n",
      "licuar nuevamente). limpio y sin restos de mezcla.\n",
      "El Manual Revolucionario 29\n",
      "Transcripci√≥n de https://www.youtube.com/watch?v=L3Qf63iP4Yc guardada en transcript_L3Qf63iP4Yc.srt\n",
      "Transcripci√≥n de https://www.youtube.com/watch?v=WT-wEIo9Ji8 guardada en transcript_WT-wEIo9Ji8.srt\n",
      "Transcripci√≥n de https://www.youtube.com/watch?v=gaVQ0lFp_Po guardada en transcript_gaVQ0lFp_Po.srt\n",
      "Transcripci√≥n de https://www.youtube.com/watch?v=dDaKhCTrMus guardada en transcript_dDaKhCTrMus.srt\n",
      "Transcripci√≥n de https://www.youtube.com/watch?v=DPOLIiBcCbk guardada en transcript_DPOLIiBcCbk.srt\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n de logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# 1Ô∏è‚É£ CARGA DE DOCUMENTOS (PDF y YouTube)\n",
    "# ------------------------------------\n",
    "\n",
    "pdf_url = \"https://s3.amazonaws.com/fitnessrevolucionario.publico/Descargas/ElManualRevolucionario_MarcosVazquez.pdf\"\n",
    "\n",
    "# Cargar el PDF con pdfplumber\n",
    "def load_pdf(pdf_url):\n",
    "    try:\n",
    "        # Descargar el PDF (o leer si ya lo tienes en el sistema)\n",
    "        response = requests.get(pdf_url)\n",
    "        pdf_file = io.BytesIO(response.content)  # Usamos BytesIO para leer desde memoria\n",
    "        with pdfplumber.open(pdf_file) as pdf:\n",
    "            pdf_text = [page.extract_text() for page in pdf.pages]\n",
    "        return pdf_text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al cargar el PDF: {e}\")\n",
    "        return []\n",
    "\n",
    "pdf_pages = load_pdf(pdf_url)\n",
    "\n",
    "# Lista de URLs de YouTube\n",
    "youtube_urls = [\n",
    "    \"https://www.youtube.com/watch?v=L3Qf63iP4Yc\",\n",
    "    \"https://www.youtube.com/watch?v=WT-wEIo9Ji8\",\n",
    "    \"https://www.youtube.com/watch?v=gaVQ0lFp_Po\",\n",
    "    \"https://www.youtube.com/watch?v=dDaKhCTrMus\",\n",
    "    \"https://www.youtube.com/watch?v=DPOLIiBcCbk\"\n",
    "]\n",
    "\n",
    "# Funci√≥n para guardar las transcripciones en formato .srt\n",
    "def save_to_srt(transcript, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for idx, entry in enumerate(transcript, 1):\n",
    "            start, duration, text = entry['start'], entry['duration'], entry['text']\n",
    "            start_min, start_sec = divmod(int(start), 60)\n",
    "            end_min, end_sec = divmod(int(start + duration), 60)\n",
    "            f.write(f\"{idx}\\n\")\n",
    "            f.write(f\"{start_min:02d}:{start_sec:02d} --> {end_min:02d}:{end_sec:02d}\\n\")\n",
    "            f.write(f\"{text}\\n\\n\")\n",
    "\n",
    "documents = [page for page in pdf_pages if page is not None]  # Eliminar p√°ginas vac√≠as\n",
    "\n",
    "# Procesar cada URL de YouTube\n",
    "for url in youtube_urls:\n",
    "    video_id = url.split('v=')[1]\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['es'])\n",
    "        transcript_filename = f\"transcript_{video_id}.srt\"\n",
    "        save_to_srt(transcript, transcript_filename)\n",
    "        documents.append(f\"Transcripci√≥n de {url} guardada en {transcript_filename}\")\n",
    "    except (TranscriptsDisabled, NoTranscriptFound):\n",
    "        logging.warning(f\"No se encontr√≥ transcripci√≥n para {url}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al obtener transcripci√≥n para {url}: {e}\")\n",
    "\n",
    "# Imprimir los documentos procesados\n",
    "for document in documents:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441,
     "referenced_widgets": [
      "72e7c491635f4e87943b2d1c98581f03",
      "1f39fe61cea141da89f117dd45d53ad4",
      "a04c82a7496042a3899a8fc276f3a4ab",
      "da3b765d7e364bc29db3de4ce3bd389a",
      "5e8b669962e24875915a839ce8d017b9",
      "1a2adefbc15640008a80b9c5439cf0f6",
      "f721ef8d935d4ffeb6270f9897131842",
      "34079ce761f643c983cb8f5c5caa4976",
      "9e23163c97c34a788765603ba5733bb9",
      "9051b37ca901451cbab7bb1909c84a08",
      "a190918cc7fe4e93949d982491a3f0e8",
      "cf273899041443ea89b2d87f7fe1f110",
      "377f35c1374541ef81a963d054357b35",
      "29aa0db535144647aedf81cb0792d95c",
      "d1789d4cfa7a47e9aca163d3146bf4a5",
      "22b3f3f420db4f68bbd635fddae4bfe1",
      "05e7de1f3783476a846d2b35d3431e1b",
      "0984299cf63246f5bbe8a94112d7c5e7",
      "97e3020ab40a48b88f9af9d911728461",
      "d925f42d15524e2f84fe371b462380f5",
      "014f9a3b1eb5492ea0a18dbb18cf9227",
      "02dd87d8d335426c9188e0555457e6cb",
      "afee96ce87d64a91b16c31df52ee8296",
      "dd7ee1f5d14f45e18d8bfc419ceb2483",
      "21db274101994c138f3a4e5490f69f4b",
      "05b953a8dcf04de78e7b5d59a74b7613",
      "d8f15f19b3b74971addbe5d74035f5b4",
      "34e020f9f9d24904b33d6b4acda3f90a",
      "b4931fd325a74d6e986f5a72c3b9a02d",
      "97bb415c99c1419a802c0ab22edca669",
      "3210dfc908be45209b0fc78b525d7f3d",
      "603adbffe2ab45f1988fab06e942d5fe",
      "680234a642b04638a2076465356ac344",
      "22eed9da8e1c4ab5991940be4e0f61da",
      "44f186d9717349f28d86a3f8c6f62e6c",
      "87f03986fc1f4f1db076783741d9c6a3",
      "30395fdfcd0c42dfb371560dfe1e1ffd",
      "4956e257669e42f1a2a13023c3b47b53",
      "bd3784d4514e41dfa447c542fbbcfc82",
      "fc49d605540845d197a68611fb650ed7",
      "01739f583c954d55b72d9cdab3271513",
      "ac9d830d7024448c82b44f655b287ec5",
      "87a8f0af6e9448eeae0572f9a2f470ef",
      "feeb57e65dcc4437afbf166a99b5e003",
      "4c44341650554294817e531a1329aedc",
      "99fcee2864fe4ef7ad0a58b5f4d880c3",
      "36b5604e86504c2287c1a76d82c76ef2",
      "31e6738accc54e2888b18e3eb0706737",
      "b2889d54fbd34fc48204db783d5f9d6a",
      "aafc1f8cad444ce9b7ec1522e907f0bf",
      "0098b732ca5c481689ef225a57d9e11f",
      "f856b6c522d546dd8d49e33bacd9f7d0",
      "6917f9dc78574353b24358df7a899625",
      "7601637ce2594e7a9204ba4c7e918650",
      "85417726891342e5b50e727e526879f7",
      "a2b5a61752c2431ab3a71645ae60c3ea",
      "1007f7d8179d4a4eaa1dd7c30e5c09bd",
      "8e73b6bf266842d1b354a438108f4cde",
      "5f3b9487f4a544899e5d0a1ff5ee8ded",
      "708e1f40594645589e3f7dc8c8485f26",
      "3c673e24ebc4416aa262c355f7fdca51",
      "6981e7e496654c8aa1dac71a2f3abe09",
      "222452a06c8b47d9a7fd2a58be7bbea1",
      "176c6fa6c97b4271b34829877b14dbe1",
      "33d1dfdaa0684c90b765b4d681a317cd",
      "e6e90e7bdeaa41d5a1ad1a0e2a44eb63",
      "e231650de1314e5394ce9d6ec83a0455",
      "a1a918dfdce447c1a586d8063ebe4ddc",
      "1b7ad22f884e43bdb7696d383185e924",
      "f730db29277544c2b29ac90771689ac9",
      "7b32e49901a64630ac8ce48d699ad71c",
      "1228debd04c24ea8861963d44da65fb5",
      "ead40e3341e04c44bf617a415308a672",
      "5bdde4adbe0446f69267b31ef1cf9125",
      "2ed4f460f0804632a2b688dce8761075",
      "ea08325fbf1a49ed8578a0716692062c",
      "049945de5bb84dddb576ab2129a0c566",
      "f37956b8904a4be2b01068cebca62f2e",
      "bdc37f45feb946c981fee30164e70a7a",
      "fcff680e3fe54d61a372e26b19775744",
      "f6ad2b3fc55b45298f27ea7916434960",
      "930e721a77e248d2a3e614c349d310fe",
      "668eb048dda84eb49126ee20a07c3aa6",
      "2b0775bd97614a50bdc8ddbb791ae673",
      "f140f4a4a43840f3b72edb61807f01c4",
      "af4c1f9d6287455ea49e41cb60dc6e31",
      "08d9c1f42f73497cbfabb8c6a421b654",
      "277d9385214745ae8101f318e2a58d72",
      "c743597e44c34cd7829c357b678e8443",
      "893f81c7c120460a8b6ced59c50497c7",
      "047e2e24c4124e79b99f4b296bae2834",
      "7cb6d6a1999a4f499e51bd50172b8d71",
      "43b5088a6750476a8fff208f52935386",
      "eee1279e4efe4298bb8835539aed235e",
      "c359b3c5405d492284d59c4c03fc98c5",
      "88a493419fd74238b04f05604ff35273",
      "79de5a1c252041e8a19c714506eb90c4",
      "4b9a236d3d054304a50175b2368ea8fa",
      "5e32c8f22c4f43f2a171de00c94554e3",
      "fc06e0ef024e489ea8f07d5c8d5ac516",
      "fb60b803a803490b95be79e81139d8ef",
      "b0b1b7cbfcbc4ff884bcb802e9dc96f0",
      "917d5990ad7a483eaeef456be0af9a71",
      "74d5ba477d9f486ca060acc5e6394bdb",
      "d0a44b0f9110453bbb4bacee48ffd004",
      "7e1866369b5845d29baf3f22278d5c60",
      "4d49b80e52ad4542a5ecd1c0e6befee2",
      "b09ecd68b3d54388a139a63ec68d37ec",
      "6b4fb67e13c14de6b135cd9f38009164",
      "b1eb877233564b4f8ade17750669295f"
     ]
    },
    "id": "-mCF1-cw94ow",
    "outputId": "cd84370f-6e49-4681-d50a-24b5e011e0a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e7c491635f4e87943b2d1c98581f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf273899041443ea89b2d87f7fe1f110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afee96ce87d64a91b16c31df52ee8296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22eed9da8e1c4ab5991940be4e0f61da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c44341650554294817e531a1329aedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b5a61752c2431ab3a71645ae60c3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e231650de1314e5394ce9d6ec83a0455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37956b8904a4be2b01068cebca62f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c743597e44c34cd7829c357b678e8443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc06e0ef024e489ea8f07d5c8d5ac516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2Ô∏è‚É£ CREACI√ìN DE EMBEDDINGS Y FAISS\n",
    "# ------------------------------------\n",
    "\n",
    "# Cargar el modelo preentrenado de SentenceTransformers\n",
    "embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Crear los embeddings a partir de los documentos\n",
    "document_embeddings = embedder.encode(documents, convert_to_numpy=True)\n",
    "\n",
    "# Crear un √≠ndice FAISS\n",
    "index = faiss.IndexHNSWFlat(document_embeddings.shape[1], 32)\n",
    "index.add(document_embeddings)\n",
    "\n",
    "# Guardar los embeddings y el √≠ndice FAISS\n",
    "with open(\"document_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(document_embeddings, f)\n",
    "faiss.write_index(index, \"faiss_index.faiss\")\n",
    "\n",
    "# Log para confirmar que se guardaron correctamente\n",
    "logging.info(\"Embeddings e √≠ndice FAISS guardados correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vxVXejU6-DuI"
   },
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ FUNCIONES PARA RAG\n",
    "# ------------------------------------\n",
    "\n",
    "def retrieve_documents(query, top_k=3):\n",
    "    query_embedding = embedder.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    return [documents[i] for i in indices[0] if i < len(documents)]\n",
    "\n",
    "def answer_question_with_generation(question, context):\n",
    "    try:\n",
    "        inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            start, end = outputs.start_logits.argmax(), outputs.end_logits.argmax()\n",
    "            return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs.input_ids[0][start:end+1]))\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en la generaci√≥n de respuesta: {e}\")\n",
    "        return \"No se pudo generar la respuesta.\"\n",
    "\n",
    "def answer_question_with_RAG(question, top_k=3):\n",
    "    try:\n",
    "        context = \" \".join(retrieve_documents(question, top_k))\n",
    "        return answer_question_with_generation(question, context)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en el proceso RAG: {e}\")\n",
    "        return \"Error en la generaci√≥n de respuesta.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "9936155666154a1caf60fe5c10a72d87",
      "18d5e7ef64a64f038a7ae72737ceb466",
      "956510528a664169b82ca951e62ad43c",
      "fa1742fe37304b4f81711300382bd5f6",
      "bdeb4fac658a469faa6f404a745f98ce",
      "49ece187bd524ddba097dd48c6ec0bff",
      "10daaf643da04beaa6db1d2607bfed21",
      "7b7201a81c46486db1c01c7e897824b1",
      "163e5c7c99084f77bffe10955b612328",
      "fc7fe71a8acc4b83b53f655c6fc5780f",
      "cfd16484ab594c92a6f352bd50fe1cdf",
      "f88054cd611c46f1948b338704d77aa6",
      "ece95acc928340a99a508b3530949f1b",
      "6461be7b7999474bbca024298b05d252",
      "cab88015e5764e06a8acce9530301fd0",
      "f22155da3cf74ccebe5e2b9f891c9e9f",
      "2d6aad40d2a7421fb469a8a0e1eb5bff",
      "86e1df7ada8d44cf8ea9824d53b9da5e",
      "59662e3480b64eaeb6944d7f2ee1f195",
      "ef200643fc264ac58f2a639abcf21ea8",
      "9bf36baa9cc649ca82d4906a2b5ea6ba",
      "57d83a0341ac481ebb2857b8bd0eab7b",
      "07986d32744544a6ad78e28ab4f5a6cc",
      "594c6e05728e4e44adc0e56448d4d464",
      "4f48f8d824f74721b59aed3b33bca906",
      "cc7d68102f5647d3945de97e87c79a6f",
      "83df1838335e40a4beb75ba6ce3229c7",
      "32680badb2eb49469e2915512f0727f0",
      "e3d50cd2b5894d65a09b4627801069e0",
      "fd7a890232e142a1ae0e0d526767ecbc",
      "60f36bc3906e4b639f8ad9ca4870d184",
      "69939e22a2cc4718a2b56cfe2e92df89",
      "27720d7455d74fa98f0c98667bb831f0"
     ]
    },
    "id": "A5vNPNQC6gEM",
    "outputId": "9970ddb2-d61e-495d-a1e8-257d41b40a74"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9936155666154a1caf60fe5c10a72d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88054cd611c46f1948b338704d77aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07986d32744544a6ad78e28ab4f5a6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo RAG guardado y comprimido en: /content/chatbot_tribu_salud_rag.zip\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_f725f22f-f258-4aaa-8f99-bc2fceba51ee\", \"chatbot_tribu_salud_rag.zip\", 26015255)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4Ô∏è‚É£ GUARDAR Y SUBIR MODELO A HUGGING FACE\n",
    "# ------------------------------------\n",
    "\n",
    "rag_model_dir = \"/content/chatbot_tribu_salud_rag\"\n",
    "os.makedirs(rag_model_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    model.save_pretrained(rag_model_dir)\n",
    "    tokenizer.save_pretrained(rag_model_dir)\n",
    "    logging.info(f\"Modelo RAG guardado en: {rag_model_dir}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error al guardar el modelo: {e}\")\n",
    "\n",
    "repo_name_rag = \"CasiAC/chatbot_tribu_salud_rag\"\n",
    "repo_dir_rag = \"/content/new_chatbot_tribu_salud_rag\"\n",
    "zip_filename = \"/content/chatbot_tribu_salud_rag.zip\"\n",
    "\n",
    "if not os.path.exists(rag_model_dir):\n",
    "    logging.error(f\"No se encontr√≥ la carpeta {rag_model_dir}\")\n",
    "    raise FileNotFoundError(f\"No se encontr√≥ la carpeta {rag_model_dir}\")\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "try:\n",
    "    api.create_repo(repo_name_rag, repo_type=\"model\", private=False, exist_ok=True)\n",
    "    if os.path.exists(repo_dir_rag):\n",
    "        shutil.rmtree(repo_dir_rag)\n",
    "    os.makedirs(repo_dir_rag, exist_ok=True)\n",
    "    shutil.copytree(rag_model_dir, repo_dir_rag, dirs_exist_ok=True)\n",
    "    api.upload_folder(folder_path=repo_dir_rag, repo_id=repo_name_rag, repo_type=\"model\", commit_message=\"Subida del modelo RAG\")\n",
    "    logging.info(f\"Modelo RAG subido correctamente a Hugging Face: https://huggingface.co/{repo_name_rag}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error al subir el modelo a Hugging Face: {e}\")\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, _, filenames in os.walk(rag_model_dir):\n",
    "        for file in filenames:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, rag_model_dir)\n",
    "            zipf.write(file_path, arcname)\n",
    "\n",
    "print(f\"‚úÖ Modelo RAG guardado y comprimido en: {zip_filename}\")\n",
    "files.download(zip_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482,
     "referenced_widgets": [
      "3d7c59282a78404a80c8360caf34d2b0",
      "d443e8464c1741d28a8d2fed4531e89f",
      "8dc882146b774190999804f40965ea49",
      "cdbf7eb65c7b4c9d8fcba519af53052c",
      "ae79998638924c458690dcef7a7a1810",
      "420d368c07aa453c946b9d00fbad2347",
      "36afdfac02e243a3beb1734cc3cb5399",
      "d400e53c621d4e7083e5dfa2186f3a7a",
      "03ef9d827ca84cfe95984aa9ddc0912d",
      "cf2003162d9c495089584cb05ef98128",
      "70c50c31d8a14ce8988c3ca4ec3ec308",
      "c0c043f4c2614b56b4e1c4696e5d4bd1",
      "2c875a1aaab9464391d395144438539a",
      "2b32a605af2444f798cf05ea3c721376",
      "abf5af89770040f5b4aa36f4cb1403fa",
      "d27400ee29274373a91e07b0c0f929ed",
      "04a92346da45454c9db23c09671340d2",
      "f3a1d5dc1b93495a8ccb9afddcf3dd97",
      "02d32cc9154b4b3cb4b7df5f5fa7e115",
      "b74e0c8e83dc48a4a423aa464c8d4348",
      "cadc830e42864457beb2efcc7f4ef7e4",
      "a1f80a5d88ff44209ca98d330f0b7f8b",
      "d2cfdb8bfb1e45d7a80f271d2d2a4849",
      "c7f6818217d6405ea05e49155e2beebf",
      "9e91e3d707c2493b9c5cbf66ccccbda4",
      "71a8a3eeef0c47f3a5d2faec1f4a795e",
      "15a0b7c3393a4868a23bc23809ddafc9",
      "3bfb5fc0eaa24650ae16fb92f092bf65",
      "44c012b05460441dbdb391e3f977fb1a",
      "95c75af647d04ec29df30a2d6445282b",
      "cf439588375f4ccb9aeec30d82e57a13",
      "e6840135fcf8427987b56bf3279b8bf0",
      "583e8cbfd4784c6299017a8d867040ae",
      "ac3ce102d05442868e206817078b5e90",
      "2074d9a269a447b2a88458ac98957e41",
      "a787e0f3353d480a8a39fbddf874c91f",
      "fc17491546d54696997a5b23c1fb6d8f",
      "859fbb674eeb4602b6216b51ff964f32",
      "1ce8f51b90804fef8c8cfe4be6a8e484",
      "dcd33c8edea94009b03b74b27036825c",
      "108b5b046bea4428be9ebe6bdf6914e7",
      "18b4f2b5c69947f4876be5e269c3fbe7",
      "6a50eb98c6914ac9aea0c3cf1c3402f9",
      "a2671f20842a4baf8954ad00d19e78ec",
      "b8e2476f8b734e9cb3716dd7c6920645",
      "9df38bb3db314c3fba1650750974d910",
      "91ee663c7dcf4aee9b9a66075ed91f69",
      "eaa0edff424f41f28a8d4ffafd1f31ca",
      "36af016d76014c5493546f334acf0d7f",
      "d1f3974f11ef4b839258b2ac98afcdea",
      "13b8290d240e4ea39a7c11928954103a",
      "cc2416a25136429e99b749c05a876345",
      "1fbc4e09ed044401858ed79f614040ea",
      "221aa40eccfd4b87a49935e2a59849f1",
      "96bed91051014527a23b3e4bff414829",
      "d23b1672d86046a0b6afcab59a4d46be",
      "239abdb13be94ae9b46a43d440c9cdff",
      "da65501903bb448f9ffc1be4dcab8fc5",
      "670a4f22a34b4454b8fce2da21096927",
      "7e3a8fe4544a449780f9e91beea64613",
      "cd33784029034a1aa47062a02af069d1",
      "74453a57697744e38d57234f966e8035",
      "17bbc091abcf48f585b2dc94acfae507",
      "a3c96fc888c94787ab31d543bcdb6b46",
      "d58d6bf93afd49f6ba18b443e8693b2f",
      "df0e5e70a7be47019df318fc4102c171",
      "9536dc411f0747bc81ad46f9afce494b",
      "821ae32fe6944d75bc9b11c4c1a6f6a8",
      "84da6593b07141d1b877776703158851",
      "011260a6c3fb42b3909230b3ed940ca2",
      "4bf76237c7634c1db3b0fd65e0511efe",
      "d31779c5e3bc4745bcab383b96971b81",
      "d8da28d3f648405abdd960b1e521c430",
      "7b494a0499f447de8e6cf846d7ad93be",
      "77cd305745934e049cd117dfeb6add8f",
      "4bf0acf5473947c480d179b674b6f407",
      "f466c6824be94412973b6e19cf6ef318",
      "c502f3c07b144520a54ab8822d6cc86b",
      "b23dd7254e284066a6d59024f7073f8d",
      "b20fbec7d0cb47e69480bcc4fbbc1d77",
      "d0070be0bf244e348a2ce56c52664796",
      "9c91e8ec06c844f8954ecfc6fb35b31b",
      "33d97d6bae7648259d044f77182e9f67",
      "db7a39b0e55a45ad8891b3b5bcdee9b5",
      "bc2b61a292114d5da77d8c2bc240c097",
      "a91931a8220f44e8b88c5aae757434c5",
      "a0bf4ca5bba54eeab927d8902de8b166",
      "c2d5d443f4174613afe5a62682a142c8",
      "5fb269bf76b44bd5b980d275388b1fed",
      "8b4c7c43efdc4c63b90448cec357a7d9",
      "a6ed1ef918d04bb9bcf8fdaa666ce850",
      "d4317ac3e6d8403f8dcfd54a5fde9045",
      "5185cf800fc044739e011464b9c968b6",
      "848d7e2bf38045608f8fd971d97744e9",
      "c1edc5897b604d97b76e3cef138b67aa",
      "8c3d40c1029c4d519e7c58274a0fd073",
      "e34a6a0dcd42439e90d21297e123c6df",
      "698ce908c4034709ac0e29c984663af0",
      "0f9e69c23e234c8b9e0739b0fa108318",
      "171d4673f77b449dab4f663fc586bdf1",
      "eb3901a4b13b4635a24137dd98411fb1",
      "487bd3bfcd6945d6a741ea595b2bdd0f",
      "2b934c5f448b43dfb9bcf357d16b4320",
      "423cf82bee7841f1a691cf3a613088a2",
      "56dfdea7245c4a88a3139b376b00c6fc",
      "fb40c59f4725464a98ea919005ba373c",
      "f2e09bb95e294fbbaa1df040100b03c5",
      "24f53edb49da433dbb5c73368f1a47c4",
      "2b5d0577f9d348ebb5dfe69ee391bf55",
      "6f95bc77a3274b18b497e99b3413ac72",
      "9947c4821da04bd19c7df223dda8efab",
      "20cfaf464ecd4b9983be89c862e69bac",
      "09b90ec98dd04609ade40f0d4c1c4497",
      "b0f1785d5c6848bba9b2a920d91ed035",
      "ee8f438b1d7043348bc5ae224e36cbf4",
      "e27febc30b634cad8d7cfaf5fe67e880",
      "b07cc14688354ccdac49fd6008902c74",
      "98b6d6e86d73406593e70316bf415fc1",
      "a4ea6d54bceb44038c9a6a0d485ba0cc",
      "9dc84eedf76c486dac609063e36400fb",
      "e332ed5bd2e349069f863d902f1b809b",
      "ba572f687efb47b4b157e32a3e5701bd",
      "33ce22f773db4b009ad64b6e6ab4e632",
      "50812d5d867549f093c18a7928a9add6",
      "813d55f658204f1598b6feb1ea65906a",
      "e447bffda60e4ac8b2a27f6da96399a0",
      "c2e23bf6b47f4e15a01453bb3de92423",
      "ecd5a57ade5a43a0beb1118e151f8480",
      "669e721705fb4a97bbf6b7266847cb76",
      "a89b76e184244128ad3bea47ab7272bf",
      "f635bcc656fb4f75b9984be72ae29736",
      "d0bc7d5f78d642d0bd7651ebcf7d3e84",
      "07177600d18940d39c64d00b1a92ca03",
      "5732b06c69dd4b77bc16c71c307fc5c7",
      "7073418b690b4f5ba05dc8e2f9974e36",
      "f6d71b54e6e64a888cfa74804b75351e",
      "b1bbac0b275242239fc8f3c6b8bd306f",
      "fbb315c228624d75a4d704fa7e8cbb83",
      "a2f7670e57a14214a72ebfc385ef7363",
      "8c3781d0cb894f599b80d89274fa777f",
      "c018849c6de74cb1b1f61915d76e6f95",
      "7f084c7570bf47bda150c2d8328bf6fc",
      "372dadfc7ff8450f97205b5edbc2b0ec",
      "1bad6d66611a4096a8224135cbeef738",
      "451ac43b573a43de9735fc3d3297c2ef",
      "ca8194025b15447d8a0dcdc62f190f34",
      "55edb5ce7d0a4e6d8c43fca2a87d0d9a",
      "9b1a6f68daa14e34b3aa0f61d6dbc077",
      "3776148edd7d449b827f8549a4487148",
      "239c0a1421614e0e87fdcb299df4f7c0",
      "8105a7fd8d424d1e8dda14e8a234ec47",
      "4d75819cb0d24c9ebca7ded0161828c3",
      "2cfcfd1e2ff74e63aaab766552cd9ca8",
      "093478d57aa646e28b9896c0e372f1e3"
     ]
    },
    "id": "wrtmtayc5Rl0",
    "outputId": "8008e275-28a2-424a-a312-df278bf8f552"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7c59282a78404a80c8360caf34d2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c043f4c2614b56b4e1c4696e5d4bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cfdb8bfb1e45d7a80f271d2d2a4849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.51M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3ce102d05442868e206817078b5e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e2476f8b734e9cb3716dd7c6920645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/731 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23b1672d86046a0b6afcab59a4d46be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9536dc411f0747bc81ad46f9afce494b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c502f3c07b144520a54ab8822d6cc86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb269bf76b44bd5b980d275388b1fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171d4673f77b449dab4f663fc586bdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9947c4821da04bd19c7df223dda8efab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba572f687efb47b4b157e32a3e5701bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07177600d18940d39c64d00b1a92ca03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bad6d66611a4096a8224135cbeef738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Nombre del modelo en Hugging Face\n",
    "MODEL_NAME = \"CasiAC/chatbot_tribu_salud_rag\"\n",
    "\n",
    "# Cargar el modelo y el tokenizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "# Crear el pipeline para generaci√≥n de texto\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01u9nY52Bgqp"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import model_info\n",
    "\n",
    "model_name = \"CasiAC/chatbot_tribu_salud_rag\"\n",
    "\n",
    "try:\n",
    "    info = model_info(model_name)\n",
    "    print(f\"‚úÖ Modelo encontrado: {info.modelId}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666,
     "referenced_widgets": [
      "c36af21de7a44656b18658e6a8458611",
      "6ac60f8b86454b07bcdb6cceb3a95601",
      "c6174efcb1f74fb2a739713e307fa89a",
      "588426d21bb14ab9bbc9c8ddd29e1bea",
      "2314f60ef544461493be9f9de21a80e4",
      "fecc4b0eeb3043629b8b9a85dd79ff3b",
      "793810069936460baabcd66332c0c03e",
      "48ecc870fb06460d8c55f522ea46406f",
      "8554fb5785ce45ebb2bc16ae474174f7",
      "a06f2143cf3e4fee9b8b0ab8cd8f1f5e",
      "2b41a95a30694f8db0254a54102d6c29"
     ]
    },
    "id": "hUzoDB0k9VFF",
    "outputId": "4153147e-a43d-45cc-c99f-31d53d5c39eb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36af21de7a44656b18658e6a8458611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://be82ffc930d68ac4f7.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://be82ffc930d68ac4f7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Definir algunos documentos de ejemplo\n",
    "documents = [\n",
    "    \"Este es el primer documento con informaci√≥n sobre salud evolutiva.\",\n",
    "    \"Este es el segundo documento con consejos de entrenamiento funcional.\",\n",
    "    \"Este es el tercer documento sobre nutrici√≥n y estilo de vida saludable.\"\n",
    "]\n",
    "\n",
    "# Mensaje de bienvenida del chatbot\n",
    "system_message = \"\"\"\n",
    "ü¶¥üåø ¬°Bienvenido a Tribu Salud! üèãÔ∏è‚Äç‚ôÇÔ∏èüî•\n",
    "\n",
    "Hola, soy tu asistente en salud evolutiva, aqu√≠ para ayudarte a optimizar tu bienestar con un enfoque basado en la biolog√≠a ancestral. üèïÔ∏èü•©\n",
    "\n",
    "üîπ ¬øQuieres mejorar tu alimentaci√≥n con principios evolutivos? üçñü•ë\n",
    "üîπ ¬øBuscas consejos sobre entrenamiento funcional y movimiento natural? üèÉ‚Äç‚ôÇÔ∏èüí™\n",
    "üîπ ¬øTe interesa mejorar tu descanso y reducir el estr√©s? üò¥üåû\n",
    "\n",
    "Preg√∫ntame lo que necesites, ¬°empecemos este viaje hacia una salud m√°s alineada con nuestra naturaleza! üöÄüíØ\n",
    "\"\"\"\n",
    "\n",
    "# Nombre del modelo en Hugging Face (reemplaza con el tuyo)\n",
    "MODEL_NAME = \"CasiAC/chatbot_tribu_salud_rag\"\n",
    "\n",
    "# Forzar el uso de CPU (dado que la GPU est√° saturada o para facilitar la depuraci√≥n)\n",
    "device = torch.device(\"cpu\")\n",
    "logging.info(\"Usando CPU para la inferencia.\")\n",
    "\n",
    "# Cargar el tokenizer y el modelo desde Hugging Face en CPU\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"cpu\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Crear pipeline para generaci√≥n de texto (sin especificar 'device', ya que el modelo ya se carg√≥ en CPU)\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, batch_size=1)\n",
    "\n",
    "# Funci√≥n para generar respuesta en espa√±ol usando el mensaje de bienvenida y el prompt\n",
    "def generate_response(prompt):\n",
    "    full_prompt = f\"<s>[INST] {system_message}\\n{prompt}\\nPor favor, responde en espa√±ol. [/INST]\"\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=256, do_sample=True, temperature=0.7, top_p=0.9)\n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    response = response.replace(full_prompt, \"\").strip()\n",
    "    return response\n",
    "\n",
    "# Funci√≥n para generar respuesta a partir de la pregunta y contexto\n",
    "def answer_question_with_generation(question, context, max_context_tokens=256):\n",
    "    # Truncar el contexto si es muy largo\n",
    "    context_tokens = tokenizer.encode(context, add_special_tokens=False)\n",
    "    if len(context_tokens) > max_context_tokens:\n",
    "        context_tokens = context_tokens[:max_context_tokens]\n",
    "        context = tokenizer.decode(context_tokens, skip_special_tokens=True)\n",
    "    prompt = f\"Pregunta: {question}\\nContexto: {context}\"\n",
    "    return generate_response(prompt)\n",
    "\n",
    "# Funci√≥n para simular la recuperaci√≥n de documentos (usa la variable 'documents' definida arriba)\n",
    "def retrieve_documents(question, top_k=3):\n",
    "    return documents[:top_k]\n",
    "\n",
    "# Funci√≥n para probar el modelo RAG: recupera documentos y genera respuesta\n",
    "def test_rag_model(question, top_k=3):\n",
    "    try:\n",
    "        context = \" \".join(retrieve_documents(question, top_k))\n",
    "        answer = answer_question_with_generation(question, context)\n",
    "        logging.info(f\"Pregunta: {question}\\nContexto: {context}\\nRespuesta: {answer}\")\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en la prueba del modelo RAG: {e}\")\n",
    "        return \"‚ùå Ocurri√≥ un error en la prueba del modelo.\"\n",
    "\n",
    "# Funci√≥n para la interfaz del chatbot en Gradio\n",
    "def chatbot_interface(question):\n",
    "    return test_rag_model(question)\n",
    "\n",
    "# Lanzar la interfaz de Gradio\n",
    "gr.Interface(\n",
    "    fn=chatbot_interface,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Tribu Salud ü¶¥üåø - Chatbot de Salud Evolutiva\",\n",
    "    description=\"Pregunta sobre salud evolutiva, entrenamiento funcional, nutrici√≥n y estilo de vida saludable.\"\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj2GVfzOzkkn"
   },
   "source": [
    "## üìå Conclusiones y Recomendaciones para Mejorar el Chatbot Tribu Salud\n",
    "\n",
    "### üîç Conclusiones\n",
    "\n",
    "1. **El mensaje de bienvenida ocupa demasiados tokens**\n",
    "   - El modelo est√° incluyendo el mensaje de bienvenida y el formato `[INST]` en cada respuesta, lo que consume muchos tokens y limita la capacidad de respuesta.\n",
    "   - Se observa que la salida repite parte del mensaje de bienvenida antes de responder a la pregunta.\n",
    "\n",
    "2. **El contexto adicional puede ser irrelevante o redundante**\n",
    "   - En la respuesta aparece un bloque de texto con \"Este es el primer documento con informaci√≥n sobre salud evolutiva...\".\n",
    "   - Es posible que el sistema est√© incluyendo demasiada informaci√≥n de contexto sin filtrar, lo que podr√≠a reducir la precisi√≥n de la respuesta.\n",
    "\n",
    "3. **Corte prematuro del texto generado**\n",
    "   - En algunos casos, la respuesta termina abruptamente, lo que sugiere que el modelo est√° alcanzando el l√≠mite de tokens o que la salida se est√° truncando.\n",
    "\n",
    "4. **Formato de la respuesta mejorable**\n",
    "   - Aunque la respuesta tiene una estructura clara, podr√≠a mejorarse con frases m√°s concisas y evitando redundancias.\n",
    "   - Se podr√≠a optimizar la claridad y la personalizaci√≥n de la respuesta seg√∫n la pregunta.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Recomendaciones de Mejora\n",
    "\n",
    "#### üîπ Reducir el tama√±o del mensaje de bienvenida\n",
    "- Eliminar emojis innecesarios y hacer el mensaje m√°s corto.\n",
    "- Mostrar el mensaje solo una vez al inicio, no en cada interacci√≥n.\n",
    "\n",
    "üìå **Ejemplo optimizado:**\n",
    "\n",
    "```plaintext\n",
    "¬°Bienvenido a Tribu Salud! Soy tu asistente de salud evolutiva.  \n",
    "Pregunta sobre alimentaci√≥n, entrenamiento y descanso. ¬°Estoy aqu√≠ para ayudarte!\n",
    "```\n",
    "\n",
    "#### üîπ Optimizar la generaci√≥n de respuestas\n",
    "- Modificar `max_new_tokens` a una cantidad mayor (ej. 300-400) para evitar cortes abruptos.\n",
    "- Ajustar `temperature` y `top_p` para mejorar la coherencia de las respuestas.\n",
    "- Asegurar que el modelo no repita el prompt en la salida.\n",
    "\n",
    "#### üîπ Filtrar el contexto innecesario\n",
    "- Si est√°s pasando documentos de contexto, revisa que sean realmente relevantes para cada pregunta.\n",
    "- Puedes limitar el contexto a solo las partes m√°s importantes.\n",
    "\n",
    "#### üîπ Mejorar el formato de la salida\n",
    "- Evitar listas demasiado generales y hacer respuestas m√°s personalizadas seg√∫n la pregunta del usuario.\n",
    "- Implementar un postprocesamiento para limpiar el texto y asegurarse de que la respuesta no est√© incompleta.\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Implementando estas mejoras, el chatbot Tribu Salud podr√° ofrecer respuestas m√°s precisas, coherentes y √∫tiles para los usuarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cObHHxEvqH3l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zYvbvk5qHlG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
